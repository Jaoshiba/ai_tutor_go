<!DOCTYPE html>
<html >
  <head>
    <meta charset="utf-8">
    <meta rel="search"
          type="application/opensearchdescription+xml"
          href="/open_search.xml"
          title="Academia.edu">
    <meta content="width=device-width, initial-scale=1" name="viewport">
    <meta name="google-site-verification" content="bKJMBZA7E43xhDOopFZkssMMkBRjvYERV-NaN4R6mrs">

    <meta name="csrf-param" content="authenticity_token" />
<meta name="csrf-token" content="oKo8x7J80FqVS4frM4lZAlAne8h-rppnb3N48mYnj0WX2ND5FhDWvCQZTZd99ZQ6y0TY0k-27mYvKx8YOBYCXQ" />
    <meta name="citation_title" content="AI-POWERED THESPIAN: DEVELOPING AN INNOVATIVE CONVERSATIONAL ENGINE" />
<meta name="citation_publication_date" content="2023/12/18" />
<meta name="citation_author" content="Richard A D E M O L A Ogundele" />
<meta name="twitter:card" content="summary" />
<meta name="twitter:url" content="https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE" />
<meta name="twitter:title" content="AI-POWERED THESPIAN: DEVELOPING AN INNOVATIVE CONVERSATIONAL ENGINE" />
<meta name="twitter:description" content="Academia.edu is a platform for academics to share research papers." />
<meta name="twitter:image" content="https://0.academia-photos.com/99875356/28093261/162876365/s200_richard.ogundele.jpg" />
<meta property="fb:app_id" content="2369844204" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE" />
<meta property="og:title" content="AI-POWERED THESPIAN: DEVELOPING AN INNOVATIVE CONVERSATIONAL ENGINE" />
<meta property="og:image" content="http://a.academia-assets.com/images/open-graph-icons/fb-paper.gif" />
<meta property="og:description" content="AI-POWERED THESPIAN: DEVELOPING AN INNOVATIVE CONVERSATIONAL ENGINE" />
<meta property="article:author" content="https://mmu.academia.edu/RichardOgundele" />
<meta name="description" content="AI-POWERED THESPIAN: DEVELOPING AN INNOVATIVE CONVERSATIONAL ENGINE" />


    <title>(PDF) AI-POWERED THESPIAN: DEVELOPING AN INNOVATIVE CONVERSATIONAL ENGINE</title>

      <link rel="canonical" href="https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE" />


    <script>(function(h,o,u,n,d) {
  h=h[d]=h[d]||{q:[],onReady:function(c){h.q.push(c)}}
  d=o.createElement(u);d.async=1;d.src=n
  n=o.getElementsByTagName(u)[0];n.parentNode.insertBefore(d,n)
})(window,document,'script','https://www.datadoghq-browser-agent.com/us1/v6/datadog-rum.js','DD_RUM')
window.DD_RUM.onReady(function() {
  window.DD_RUM.init({
    clientToken: 'pub43e59e1301d0f24a9e70902ee6fff7b5',
    applicationId: 'a5eb4f00-1461-43a4-b9ae-ed159a4e2fd4',
    site: 'datadoghq.com',
    service: 'academia-app',
    env: 'production',
    version: 'e37a0f586a945c40113ae5b285fac9bfc38bab4b',
    tracingSampleRate: 1,
    sessionSampleRate: 1,
    sessionReplaySampleRate: 20, // % of session sample rate
    defaultPrivacyLevel: 'mask-user-input',
    allowedTracingUrls: [
      'https://academia.edu',
      'https://www.academia.edu',
      'https://a.academia-assets.com',
    ]
  });
})</script>


    

    
<script>
  var $controller_name = 'single_work';
  var $action_name = "show";
  var $rails_env = 'production';
  var $app_rev = 'e37a0f586a945c40113ae5b285fac9bfc38bab4b';
  var $domain = 'academia.edu';
  var $app_host = "academia.edu";
  var $asset_host = "academia-assets.com";
  var $start_time = new Date().getTime();
  var $recaptcha_key = "6LdxlRMTAAAAADnu_zyLhLg0YF9uACwz78shpjJB";
  var $recaptcha_invisible_key = "6Lf3KHUUAAAAACggoMpmGJdQDtiyrjVlvGJ6BbAj";
  var $disableClientRecordHit = false;

</script>


    <script>
      window.Aedu = window.Aedu || {};
      window.Aedu.hit_data = null;
      window.Aedu.serverRenderTime = new Date(1755366854000);
      window.Aedu.timeDifference = new Date().getTime() - 1755366854000;
    </script>

      <link rel="stylesheet" href="//a.academia-assets.com/assets/simpler/logged_out_header-d1ed30cf29ad848dee03329828747c49563b910446d3d53b3e9cd31aba138166.css" media="all" />
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-5VKX33P2DS"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());
  gtag('config', 'G-5VKX33P2DS', {
    cookie_domain: 'academia.edu',
    send_page_view: false,
  });
  gtag('event', 'page_view', {
    'controller': "single_work",
    'action': "show",
    'controller_action': 'single_work#show',
    'logged_in': 'false',
    'edge': 'unknown',
    // Send nil if there is no A/B test bucket, in case some records get logged
    // with missing data - that way we can distinguish between the two cases.
    // ab_test_bucket should be of the form <ab_test_name>:<bucket>
    'ab_test_bucket': null,
  })
</script>


    <script>
      window.$feature_flags = {}
    </script>


    <script>
      window.Aedu.SiteStats = {"premium_universities_count":13720,"monthly_visitors":"31 million","monthly_visitor_count":31300000,"monthly_visitor_count_in_millions":31,"user_count":293376584,"paper_count":55203019,"paper_count_in_millions":55,"page_count":432000000,"page_count_in_millions":432,"pdf_count":16500000,"pdf_count_in_millions":16}
    </script>


    <script type="application/ld+json">{"@context":"https://schema.org","@type":"ScholarlyArticle","author":[{"@context":"https://schema.org","@type":"Person","name":"Richard A D E M O L A Ogundele","url":"https://mmu.academia.edu/RichardOgundele","image":"https://0.academia-photos.com/99875356/28093261/162876365/s200_richard.ogundele.jpg","sameAs":["https://www.linkedin.com/in/richardogundele/"]}],"contributor":[],"dateCreated":"2023-12-18","datePublished":"2023-12-18","headline":"AI-POWERED THESPIAN: DEVELOPING AN INNOVATIVE CONVERSATIONAL ENGINE","image":"https://attachments.academia-assets.com/109184332/thumbnails/1.jpg","inLanguage":"en","keywords":[],"publisher":{"@context":"https://schema.org","@type":"Organization","name":null},"sourceOrganization":[{"@context":"https://schema.org","@type":"EducationalOrganization","name":"mmu"}],"thumbnailUrl":"https://attachments.academia-assets.com/109184332/thumbnails/1.jpg","url":"https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE"}</script><style>@media(max-width: 567px){:root{--token-mode: Rebrand;--dropshadow: 0 2px 4px 0 #22223340;--primary-brand: #0645b1;--error-dark: #b60000;--success-dark: #05b01c;--inactive-fill: #ebebee;--hover: #0c3b8d;--pressed: #082f75;--button-primary-fill-inactive: #ebebee;--button-primary-fill: #0645b1;--button-primary-text: #ffffff;--button-primary-fill-hover: #0c3b8d;--button-primary-fill-press: #082f75;--button-primary-icon: #ffffff;--button-primary-fill-inverse: #ffffff;--button-primary-text-inverse: #082f75;--button-primary-icon-inverse: #0645b1;--button-primary-fill-inverse-hover: #cddaef;--button-primary-stroke-inverse-pressed: #0645b1;--button-secondary-stroke-inactive: #b1b1ba;--button-secondary-fill: #eef2f9;--button-secondary-text: #082f75;--button-secondary-fill-press: #cddaef;--button-secondary-fill-inactive: #ebebee;--button-secondary-stroke: #cddaef;--button-secondary-stroke-hover: #386ac1;--button-secondary-stroke-press: #0645b1;--button-secondary-text-inactive: #b1b1ba;--button-secondary-icon: #082f75;--button-secondary-fill-hover: #e6ecf7;--button-secondary-stroke-inverse: #ffffff;--button-secondary-fill-inverse: rgba(255, 255, 255, 0);--button-secondary-icon-inverse: #ffffff;--button-secondary-icon-hover: #082f75;--button-secondary-icon-press: #082f75;--button-secondary-text-inverse: #ffffff;--button-secondary-text-hover: #082f75;--button-secondary-text-press: #082f75;--button-secondary-fill-inverse-hover: #043059;--button-xs-stroke: #141413;--button-xs-stroke-hover: #0c3b8d;--button-xs-stroke-press: #082f75;--button-xs-stroke-inactive: #ebebee;--button-xs-text: #141413;--button-xs-text-hover: #0c3b8d;--button-xs-text-press: #082f75;--button-xs-text-inactive: #91919e;--button-xs-icon: #141413;--button-xs-icon-hover: #0c3b8d;--button-xs-icon-press: #082f75;--button-xs-icon-inactive: #91919e;--button-xs-fill: #ffffff;--button-xs-fill-hover: #f4f7fc;--button-xs-fill-press: #eef2f9;--buttons-button-text-inactive: #91919e;--buttons-button-focus: #0645b1;--buttons-button-icon-inactive: #91919e;--buttons-small-buttons-corner-radius: 16px;--buttons-small-buttons-l-r-padding: 20px;--buttons-small-buttons-height: 48px;--buttons-small-buttons-gap: 8px;--buttons-small-buttons-icon-only-width: 48px;--buttons-small-buttons-icon-size: 20px;--buttons-small-buttons-stroke-default: 1px;--buttons-small-buttons-stroke-thick: 2px;--buttons-large-buttons-l-r-padding: 32px;--buttons-large-buttons-height: 64px;--buttons-large-buttons-icon-only-width: 64px;--buttons-large-buttons-icon-size: 20px;--buttons-large-buttons-gap: 8px;--buttons-large-buttons-corner-radius: 16px;--buttons-large-buttons-stroke-default: 1px;--buttons-large-buttons-stroke-thick: 2px;--buttons-extra-small-buttons-l-r-padding: 8px;--buttons-extra-small-buttons-height: 32px;--buttons-extra-small-buttons-icon-size: 16px;--buttons-extra-small-buttons-gap: 4px;--buttons-extra-small-buttons-corner-radius: 8px;--buttons-stroke-default: 1px;--buttons-stroke-thick: 2px;--background-beige: #f9f7f4;--error-light: #fff2f2;--text-placeholder: #6d6d7d;--stroke-dark: #141413;--stroke-light: #dddde2;--stroke-medium: #535366;--accent-green: #ccffd4;--accent-turquoise: #ccf7ff;--accent-yellow: #f7ffcc;--accent-peach: #ffd4cc;--accent-violet: #f7ccff;--accent-purple: #f4f7fc;--text-primary: #141413;--secondary-brand: #141413;--text-hover: #0c3b8d;--text-white: #ffffff;--text-link: #0645b1;--text-press: #082f75;--success-light: #f0f8f1;--background-light-blue: #f4f7fc;--background-white: #ffffff;--premium-dark: #877440;--premium-light: #f9f6ed;--stroke-white: #ffffff;--inactive-content: #b1b1ba;--annotate-light: #a35dff;--annotate-dark: #824acc;--grid: #eef2f9;--inactive-stroke: #ebebee;--shadow: rgba(34, 34, 51, 0.25);--text-inactive: #6d6d7d;--text-error: #b60000;--stroke-error: #b60000;--background-error: #fff2f2;--background-black: #141413;--icon-default: #141413;--icon-blue: #0645b1;--background-grey: #dddde2;--icon-grey: #b1b1ba;--text-focus: #082f75;--brand-colors-neutral-black: #141413;--brand-colors-neutral-900: #535366;--brand-colors-neutral-800: #6d6d7d;--brand-colors-neutral-700: #91919e;--brand-colors-neutral-600: #b1b1ba;--brand-colors-neutral-500: #c8c8cf;--brand-colors-neutral-400: #dddde2;--brand-colors-neutral-300: #ebebee;--brand-colors-neutral-200: #f8f8fb;--brand-colors-neutral-100: #fafafa;--brand-colors-neutral-white: #ffffff;--brand-colors-blue-900: #043059;--brand-colors-blue-800: #082f75;--brand-colors-blue-700: #0c3b8d;--brand-colors-blue-600: #0645b1;--brand-colors-blue-500: #386ac1;--brand-colors-blue-400: #cddaef;--brand-colors-blue-300: #e6ecf7;--brand-colors-blue-200: #eef2f9;--brand-colors-blue-100: #f4f7fc;--brand-colors-gold-500: #877440;--brand-colors-gold-400: #e9e3d4;--brand-colors-gold-300: #f2efe8;--brand-colors-gold-200: #f9f6ed;--brand-colors-gold-100: #f9f7f4;--brand-colors-error-900: #920000;--brand-colors-error-500: #b60000;--brand-colors-success-900: #035c0f;--brand-colors-green: #ccffd4;--brand-colors-turquoise: #ccf7ff;--brand-colors-yellow: #f7ffcc;--brand-colors-peach: #ffd4cc;--brand-colors-violet: #f7ccff;--brand-colors-error-100: #fff2f2;--brand-colors-success-500: #05b01c;--brand-colors-success-100: #f0f8f1;--text-secondary: #535366;--icon-white: #ffffff;--background-beige-darker: #f2efe8;--icon-dark-grey: #535366;--type-font-family-sans-serif: DM Sans;--type-font-family-serif: Gupter;--type-font-family-mono: IBM Plex Mono;--type-weights-300: 300;--type-weights-400: 400;--type-weights-500: 500;--type-weights-700: 700;--type-sizes-12: 12px;--type-sizes-14: 14px;--type-sizes-16: 16px;--type-sizes-18: 18px;--type-sizes-20: 20px;--type-sizes-22: 22px;--type-sizes-24: 24px;--type-sizes-28: 28px;--type-sizes-30: 30px;--type-sizes-32: 32px;--type-sizes-40: 40px;--type-sizes-42: 42px;--type-sizes-48-2: 48px;--type-line-heights-16: 16px;--type-line-heights-20: 20px;--type-line-heights-23: 23px;--type-line-heights-24: 24px;--type-line-heights-25: 25px;--type-line-heights-26: 26px;--type-line-heights-29: 29px;--type-line-heights-30: 30px;--type-line-heights-32: 32px;--type-line-heights-34: 34px;--type-line-heights-35: 35px;--type-line-heights-36: 36px;--type-line-heights-38: 38px;--type-line-heights-40: 40px;--type-line-heights-46: 46px;--type-line-heights-48: 48px;--type-line-heights-52: 52px;--type-line-heights-58: 58px;--type-line-heights-68: 68px;--type-line-heights-74: 74px;--type-line-heights-82: 82px;--type-paragraph-spacings-0: 0px;--type-paragraph-spacings-4: 4px;--type-paragraph-spacings-8: 8px;--type-paragraph-spacings-16: 16px;--type-sans-serif-xl-font-weight: 400;--type-sans-serif-xl-size: 32px;--type-sans-serif-xl-line-height: 46px;--type-sans-serif-xl-paragraph-spacing: 16px;--type-sans-serif-lg-font-weight: 400;--type-sans-serif-lg-size: 30px;--type-sans-serif-lg-line-height: 36px;--type-sans-serif-lg-paragraph-spacing: 16px;--type-sans-serif-md-font-weight: 400;--type-sans-serif-md-line-height: 30px;--type-sans-serif-md-paragraph-spacing: 16px;--type-sans-serif-md-size: 24px;--type-sans-serif-xs-font-weight: 700;--type-sans-serif-xs-line-height: 24px;--type-sans-serif-xs-paragraph-spacing: 0px;--type-sans-serif-xs-size: 18px;--type-sans-serif-sm-font-weight: 400;--type-sans-serif-sm-line-height: 32px;--type-sans-serif-sm-paragraph-spacing: 16px;--type-sans-serif-sm-size: 20px;--type-body-xl-font-weight: 400;--type-body-xl-size: 24px;--type-body-xl-line-height: 36px;--type-body-xl-paragraph-spacing: 0px;--type-body-sm-font-weight: 400;--type-body-sm-size: 14px;--type-body-sm-line-height: 20px;--type-body-sm-paragraph-spacing: 8px;--type-body-xs-font-weight: 400;--type-body-xs-size: 12px;--type-body-xs-line-height: 16px;--type-body-xs-paragraph-spacing: 0px;--type-body-md-font-weight: 400;--type-body-md-size: 16px;--type-body-md-line-height: 20px;--type-body-md-paragraph-spacing: 4px;--type-body-lg-font-weight: 400;--type-body-lg-size: 20px;--type-body-lg-line-height: 26px;--type-body-lg-paragraph-spacing: 16px;--type-body-lg-medium-font-weight: 500;--type-body-lg-medium-size: 20px;--type-body-lg-medium-line-height: 32px;--type-body-lg-medium-paragraph-spacing: 16px;--type-body-md-medium-font-weight: 500;--type-body-md-medium-size: 16px;--type-body-md-medium-line-height: 20px;--type-body-md-medium-paragraph-spacing: 4px;--type-body-sm-bold-font-weight: 700;--type-body-sm-bold-size: 14px;--type-body-sm-bold-line-height: 20px;--type-body-sm-bold-paragraph-spacing: 8px;--type-body-sm-medium-font-weight: 500;--type-body-sm-medium-size: 14px;--type-body-sm-medium-line-height: 20px;--type-body-sm-medium-paragraph-spacing: 8px;--type-serif-md-font-weight: 400;--type-serif-md-size: 32px;--type-serif-md-paragraph-spacing: 0px;--type-serif-md-line-height: 40px;--type-serif-sm-font-weight: 400;--type-serif-sm-size: 24px;--type-serif-sm-paragraph-spacing: 0px;--type-serif-sm-line-height: 26px;--type-serif-lg-font-weight: 400;--type-serif-lg-size: 48px;--type-serif-lg-paragraph-spacing: 0px;--type-serif-lg-line-height: 52px;--type-serif-xs-font-weight: 400;--type-serif-xs-size: 18px;--type-serif-xs-line-height: 24px;--type-serif-xs-paragraph-spacing: 0px;--type-serif-xl-font-weight: 400;--type-serif-xl-size: 48px;--type-serif-xl-paragraph-spacing: 0px;--type-serif-xl-line-height: 58px;--type-mono-md-font-weight: 400;--type-mono-md-size: 22px;--type-mono-md-line-height: 24px;--type-mono-md-paragraph-spacing: 0px;--type-mono-lg-font-weight: 400;--type-mono-lg-size: 40px;--type-mono-lg-line-height: 40px;--type-mono-lg-paragraph-spacing: 0px;--type-mono-sm-font-weight: 400;--type-mono-sm-size: 14px;--type-mono-sm-line-height: 24px;--type-mono-sm-paragraph-spacing: 0px;--spacing-xs-4: 4px;--spacing-xs-8: 8px;--spacing-xs-16: 16px;--spacing-sm-24: 24px;--spacing-sm-32: 32px;--spacing-md-40: 40px;--spacing-md-48: 48px;--spacing-lg-64: 64px;--spacing-lg-80: 80px;--spacing-xlg-104: 104px;--spacing-xlg-152: 152px;--spacing-xs-12: 12px;--spacing-page-section: 80px;--spacing-card-list-spacing: 48px;--spacing-text-section-spacing: 64px;--spacing-md-xs-headings: 40px;--corner-radius-radius-lg: 16px;--corner-radius-radius-sm: 4px;--corner-radius-radius-md: 8px;--corner-radius-radius-round: 104px}}@media(min-width: 568px)and (max-width: 1279px){:root{--token-mode: Rebrand;--dropshadow: 0 2px 4px 0 #22223340;--primary-brand: #0645b1;--error-dark: #b60000;--success-dark: #05b01c;--inactive-fill: #ebebee;--hover: #0c3b8d;--pressed: #082f75;--button-primary-fill-inactive: #ebebee;--button-primary-fill: #0645b1;--button-primary-text: #ffffff;--button-primary-fill-hover: #0c3b8d;--button-primary-fill-press: #082f75;--button-primary-icon: #ffffff;--button-primary-fill-inverse: #ffffff;--button-primary-text-inverse: #082f75;--button-primary-icon-inverse: #0645b1;--button-primary-fill-inverse-hover: #cddaef;--button-primary-stroke-inverse-pressed: #0645b1;--button-secondary-stroke-inactive: #b1b1ba;--button-secondary-fill: #eef2f9;--button-secondary-text: #082f75;--button-secondary-fill-press: #cddaef;--button-secondary-fill-inactive: #ebebee;--button-secondary-stroke: #cddaef;--button-secondary-stroke-hover: #386ac1;--button-secondary-stroke-press: #0645b1;--button-secondary-text-inactive: #b1b1ba;--button-secondary-icon: #082f75;--button-secondary-fill-hover: #e6ecf7;--button-secondary-stroke-inverse: #ffffff;--button-secondary-fill-inverse: rgba(255, 255, 255, 0);--button-secondary-icon-inverse: #ffffff;--button-secondary-icon-hover: #082f75;--button-secondary-icon-press: #082f75;--button-secondary-text-inverse: #ffffff;--button-secondary-text-hover: #082f75;--button-secondary-text-press: #082f75;--button-secondary-fill-inverse-hover: #043059;--button-xs-stroke: #141413;--button-xs-stroke-hover: #0c3b8d;--button-xs-stroke-press: #082f75;--button-xs-stroke-inactive: #ebebee;--button-xs-text: #141413;--button-xs-text-hover: #0c3b8d;--button-xs-text-press: #082f75;--button-xs-text-inactive: #91919e;--button-xs-icon: #141413;--button-xs-icon-hover: #0c3b8d;--button-xs-icon-press: #082f75;--button-xs-icon-inactive: #91919e;--button-xs-fill: #ffffff;--button-xs-fill-hover: #f4f7fc;--button-xs-fill-press: #eef2f9;--buttons-button-text-inactive: #91919e;--buttons-button-focus: #0645b1;--buttons-button-icon-inactive: #91919e;--buttons-small-buttons-corner-radius: 16px;--buttons-small-buttons-l-r-padding: 20px;--buttons-small-buttons-height: 48px;--buttons-small-buttons-gap: 8px;--buttons-small-buttons-icon-only-width: 48px;--buttons-small-buttons-icon-size: 20px;--buttons-small-buttons-stroke-default: 1px;--buttons-small-buttons-stroke-thick: 2px;--buttons-large-buttons-l-r-padding: 32px;--buttons-large-buttons-height: 64px;--buttons-large-buttons-icon-only-width: 64px;--buttons-large-buttons-icon-size: 20px;--buttons-large-buttons-gap: 8px;--buttons-large-buttons-corner-radius: 16px;--buttons-large-buttons-stroke-default: 1px;--buttons-large-buttons-stroke-thick: 2px;--buttons-extra-small-buttons-l-r-padding: 8px;--buttons-extra-small-buttons-height: 32px;--buttons-extra-small-buttons-icon-size: 16px;--buttons-extra-small-buttons-gap: 4px;--buttons-extra-small-buttons-corner-radius: 8px;--buttons-stroke-default: 1px;--buttons-stroke-thick: 2px;--background-beige: #f9f7f4;--error-light: #fff2f2;--text-placeholder: #6d6d7d;--stroke-dark: #141413;--stroke-light: #dddde2;--stroke-medium: #535366;--accent-green: #ccffd4;--accent-turquoise: #ccf7ff;--accent-yellow: #f7ffcc;--accent-peach: #ffd4cc;--accent-violet: #f7ccff;--accent-purple: #f4f7fc;--text-primary: #141413;--secondary-brand: #141413;--text-hover: #0c3b8d;--text-white: #ffffff;--text-link: #0645b1;--text-press: #082f75;--success-light: #f0f8f1;--background-light-blue: #f4f7fc;--background-white: #ffffff;--premium-dark: #877440;--premium-light: #f9f6ed;--stroke-white: #ffffff;--inactive-content: #b1b1ba;--annotate-light: #a35dff;--annotate-dark: #824acc;--grid: #eef2f9;--inactive-stroke: #ebebee;--shadow: rgba(34, 34, 51, 0.25);--text-inactive: #6d6d7d;--text-error: #b60000;--stroke-error: #b60000;--background-error: #fff2f2;--background-black: #141413;--icon-default: #141413;--icon-blue: #0645b1;--background-grey: #dddde2;--icon-grey: #b1b1ba;--text-focus: #082f75;--brand-colors-neutral-black: #141413;--brand-colors-neutral-900: #535366;--brand-colors-neutral-800: #6d6d7d;--brand-colors-neutral-700: #91919e;--brand-colors-neutral-600: #b1b1ba;--brand-colors-neutral-500: #c8c8cf;--brand-colors-neutral-400: #dddde2;--brand-colors-neutral-300: #ebebee;--brand-colors-neutral-200: #f8f8fb;--brand-colors-neutral-100: #fafafa;--brand-colors-neutral-white: #ffffff;--brand-colors-blue-900: #043059;--brand-colors-blue-800: #082f75;--brand-colors-blue-700: #0c3b8d;--brand-colors-blue-600: #0645b1;--brand-colors-blue-500: #386ac1;--brand-colors-blue-400: #cddaef;--brand-colors-blue-300: #e6ecf7;--brand-colors-blue-200: #eef2f9;--brand-colors-blue-100: #f4f7fc;--brand-colors-gold-500: #877440;--brand-colors-gold-400: #e9e3d4;--brand-colors-gold-300: #f2efe8;--brand-colors-gold-200: #f9f6ed;--brand-colors-gold-100: #f9f7f4;--brand-colors-error-900: #920000;--brand-colors-error-500: #b60000;--brand-colors-success-900: #035c0f;--brand-colors-green: #ccffd4;--brand-colors-turquoise: #ccf7ff;--brand-colors-yellow: #f7ffcc;--brand-colors-peach: #ffd4cc;--brand-colors-violet: #f7ccff;--brand-colors-error-100: #fff2f2;--brand-colors-success-500: #05b01c;--brand-colors-success-100: #f0f8f1;--text-secondary: #535366;--icon-white: #ffffff;--background-beige-darker: #f2efe8;--icon-dark-grey: #535366;--type-font-family-sans-serif: DM Sans;--type-font-family-serif: Gupter;--type-font-family-mono: IBM Plex Mono;--type-weights-300: 300;--type-weights-400: 400;--type-weights-500: 500;--type-weights-700: 700;--type-sizes-12: 12px;--type-sizes-14: 14px;--type-sizes-16: 16px;--type-sizes-18: 18px;--type-sizes-20: 20px;--type-sizes-22: 22px;--type-sizes-24: 24px;--type-sizes-28: 28px;--type-sizes-30: 30px;--type-sizes-32: 32px;--type-sizes-40: 40px;--type-sizes-42: 42px;--type-sizes-48-2: 48px;--type-line-heights-16: 16px;--type-line-heights-20: 20px;--type-line-heights-23: 23px;--type-line-heights-24: 24px;--type-line-heights-25: 25px;--type-line-heights-26: 26px;--type-line-heights-29: 29px;--type-line-heights-30: 30px;--type-line-heights-32: 32px;--type-line-heights-34: 34px;--type-line-heights-35: 35px;--type-line-heights-36: 36px;--type-line-heights-38: 38px;--type-line-heights-40: 40px;--type-line-heights-46: 46px;--type-line-heights-48: 48px;--type-line-heights-52: 52px;--type-line-heights-58: 58px;--type-line-heights-68: 68px;--type-line-heights-74: 74px;--type-line-heights-82: 82px;--type-paragraph-spacings-0: 0px;--type-paragraph-spacings-4: 4px;--type-paragraph-spacings-8: 8px;--type-paragraph-spacings-16: 16px;--type-sans-serif-xl-font-weight: 400;--type-sans-serif-xl-size: 42px;--type-sans-serif-xl-line-height: 46px;--type-sans-serif-xl-paragraph-spacing: 16px;--type-sans-serif-lg-font-weight: 400;--type-sans-serif-lg-size: 32px;--type-sans-serif-lg-line-height: 36px;--type-sans-serif-lg-paragraph-spacing: 16px;--type-sans-serif-md-font-weight: 400;--type-sans-serif-md-line-height: 34px;--type-sans-serif-md-paragraph-spacing: 16px;--type-sans-serif-md-size: 28px;--type-sans-serif-xs-font-weight: 700;--type-sans-serif-xs-line-height: 25px;--type-sans-serif-xs-paragraph-spacing: 0px;--type-sans-serif-xs-size: 20px;--type-sans-serif-sm-font-weight: 400;--type-sans-serif-sm-line-height: 30px;--type-sans-serif-sm-paragraph-spacing: 16px;--type-sans-serif-sm-size: 24px;--type-body-xl-font-weight: 400;--type-body-xl-size: 24px;--type-body-xl-line-height: 36px;--type-body-xl-paragraph-spacing: 0px;--type-body-sm-font-weight: 400;--type-body-sm-size: 14px;--type-body-sm-line-height: 20px;--type-body-sm-paragraph-spacing: 8px;--type-body-xs-font-weight: 400;--type-body-xs-size: 12px;--type-body-xs-line-height: 16px;--type-body-xs-paragraph-spacing: 0px;--type-body-md-font-weight: 400;--type-body-md-size: 16px;--type-body-md-line-height: 20px;--type-body-md-paragraph-spacing: 4px;--type-body-lg-font-weight: 400;--type-body-lg-size: 20px;--type-body-lg-line-height: 26px;--type-body-lg-paragraph-spacing: 16px;--type-body-lg-medium-font-weight: 500;--type-body-lg-medium-size: 20px;--type-body-lg-medium-line-height: 32px;--type-body-lg-medium-paragraph-spacing: 16px;--type-body-md-medium-font-weight: 500;--type-body-md-medium-size: 16px;--type-body-md-medium-line-height: 20px;--type-body-md-medium-paragraph-spacing: 4px;--type-body-sm-bold-font-weight: 700;--type-body-sm-bold-size: 14px;--type-body-sm-bold-line-height: 20px;--type-body-sm-bold-paragraph-spacing: 8px;--type-body-sm-medium-font-weight: 500;--type-body-sm-medium-size: 14px;--type-body-sm-medium-line-height: 20px;--type-body-sm-medium-paragraph-spacing: 8px;--type-serif-md-font-weight: 400;--type-serif-md-size: 40px;--type-serif-md-paragraph-spacing: 0px;--type-serif-md-line-height: 48px;--type-serif-sm-font-weight: 400;--type-serif-sm-size: 28px;--type-serif-sm-paragraph-spacing: 0px;--type-serif-sm-line-height: 32px;--type-serif-lg-font-weight: 400;--type-serif-lg-size: 58px;--type-serif-lg-paragraph-spacing: 0px;--type-serif-lg-line-height: 68px;--type-serif-xs-font-weight: 400;--type-serif-xs-size: 18px;--type-serif-xs-line-height: 24px;--type-serif-xs-paragraph-spacing: 0px;--type-serif-xl-font-weight: 400;--type-serif-xl-size: 74px;--type-serif-xl-paragraph-spacing: 0px;--type-serif-xl-line-height: 82px;--type-mono-md-font-weight: 400;--type-mono-md-size: 22px;--type-mono-md-line-height: 24px;--type-mono-md-paragraph-spacing: 0px;--type-mono-lg-font-weight: 400;--type-mono-lg-size: 40px;--type-mono-lg-line-height: 40px;--type-mono-lg-paragraph-spacing: 0px;--type-mono-sm-font-weight: 400;--type-mono-sm-size: 14px;--type-mono-sm-line-height: 24px;--type-mono-sm-paragraph-spacing: 0px;--spacing-xs-4: 4px;--spacing-xs-8: 8px;--spacing-xs-16: 16px;--spacing-sm-24: 24px;--spacing-sm-32: 32px;--spacing-md-40: 40px;--spacing-md-48: 48px;--spacing-lg-64: 64px;--spacing-lg-80: 80px;--spacing-xlg-104: 104px;--spacing-xlg-152: 152px;--spacing-xs-12: 12px;--spacing-page-section: 104px;--spacing-card-list-spacing: 48px;--spacing-text-section-spacing: 80px;--spacing-md-xs-headings: 40px;--corner-radius-radius-lg: 16px;--corner-radius-radius-sm: 4px;--corner-radius-radius-md: 8px;--corner-radius-radius-round: 104px}}@media(min-width: 1280px){:root{--token-mode: Rebrand;--dropshadow: 0 2px 4px 0 #22223340;--primary-brand: #0645b1;--error-dark: #b60000;--success-dark: #05b01c;--inactive-fill: #ebebee;--hover: #0c3b8d;--pressed: #082f75;--button-primary-fill-inactive: #ebebee;--button-primary-fill: #0645b1;--button-primary-text: #ffffff;--button-primary-fill-hover: #0c3b8d;--button-primary-fill-press: #082f75;--button-primary-icon: #ffffff;--button-primary-fill-inverse: #ffffff;--button-primary-text-inverse: #082f75;--button-primary-icon-inverse: #0645b1;--button-primary-fill-inverse-hover: #cddaef;--button-primary-stroke-inverse-pressed: #0645b1;--button-secondary-stroke-inactive: #b1b1ba;--button-secondary-fill: #eef2f9;--button-secondary-text: #082f75;--button-secondary-fill-press: #cddaef;--button-secondary-fill-inactive: #ebebee;--button-secondary-stroke: #cddaef;--button-secondary-stroke-hover: #386ac1;--button-secondary-stroke-press: #0645b1;--button-secondary-text-inactive: #b1b1ba;--button-secondary-icon: #082f75;--button-secondary-fill-hover: #e6ecf7;--button-secondary-stroke-inverse: #ffffff;--button-secondary-fill-inverse: rgba(255, 255, 255, 0);--button-secondary-icon-inverse: #ffffff;--button-secondary-icon-hover: #082f75;--button-secondary-icon-press: #082f75;--button-secondary-text-inverse: #ffffff;--button-secondary-text-hover: #082f75;--button-secondary-text-press: #082f75;--button-secondary-fill-inverse-hover: #043059;--button-xs-stroke: #141413;--button-xs-stroke-hover: #0c3b8d;--button-xs-stroke-press: #082f75;--button-xs-stroke-inactive: #ebebee;--button-xs-text: #141413;--button-xs-text-hover: #0c3b8d;--button-xs-text-press: #082f75;--button-xs-text-inactive: #91919e;--button-xs-icon: #141413;--button-xs-icon-hover: #0c3b8d;--button-xs-icon-press: #082f75;--button-xs-icon-inactive: #91919e;--button-xs-fill: #ffffff;--button-xs-fill-hover: #f4f7fc;--button-xs-fill-press: #eef2f9;--buttons-button-text-inactive: #91919e;--buttons-button-focus: #0645b1;--buttons-button-icon-inactive: #91919e;--buttons-small-buttons-corner-radius: 16px;--buttons-small-buttons-l-r-padding: 20px;--buttons-small-buttons-height: 48px;--buttons-small-buttons-gap: 8px;--buttons-small-buttons-icon-only-width: 48px;--buttons-small-buttons-icon-size: 20px;--buttons-small-buttons-stroke-default: 1px;--buttons-small-buttons-stroke-thick: 2px;--buttons-large-buttons-l-r-padding: 32px;--buttons-large-buttons-height: 64px;--buttons-large-buttons-icon-only-width: 64px;--buttons-large-buttons-icon-size: 20px;--buttons-large-buttons-gap: 8px;--buttons-large-buttons-corner-radius: 16px;--buttons-large-buttons-stroke-default: 1px;--buttons-large-buttons-stroke-thick: 2px;--buttons-extra-small-buttons-l-r-padding: 8px;--buttons-extra-small-buttons-height: 32px;--buttons-extra-small-buttons-icon-size: 16px;--buttons-extra-small-buttons-gap: 4px;--buttons-extra-small-buttons-corner-radius: 8px;--buttons-stroke-default: 1px;--buttons-stroke-thick: 2px;--background-beige: #f9f7f4;--error-light: #fff2f2;--text-placeholder: #6d6d7d;--stroke-dark: #141413;--stroke-light: #dddde2;--stroke-medium: #535366;--accent-green: #ccffd4;--accent-turquoise: #ccf7ff;--accent-yellow: #f7ffcc;--accent-peach: #ffd4cc;--accent-violet: #f7ccff;--accent-purple: #f4f7fc;--text-primary: #141413;--secondary-brand: #141413;--text-hover: #0c3b8d;--text-white: #ffffff;--text-link: #0645b1;--text-press: #082f75;--success-light: #f0f8f1;--background-light-blue: #f4f7fc;--background-white: #ffffff;--premium-dark: #877440;--premium-light: #f9f6ed;--stroke-white: #ffffff;--inactive-content: #b1b1ba;--annotate-light: #a35dff;--annotate-dark: #824acc;--grid: #eef2f9;--inactive-stroke: #ebebee;--shadow: rgba(34, 34, 51, 0.25);--text-inactive: #6d6d7d;--text-error: #b60000;--stroke-error: #b60000;--background-error: #fff2f2;--background-black: #141413;--icon-default: #141413;--icon-blue: #0645b1;--background-grey: #dddde2;--icon-grey: #b1b1ba;--text-focus: #082f75;--brand-colors-neutral-black: #141413;--brand-colors-neutral-900: #535366;--brand-colors-neutral-800: #6d6d7d;--brand-colors-neutral-700: #91919e;--brand-colors-neutral-600: #b1b1ba;--brand-colors-neutral-500: #c8c8cf;--brand-colors-neutral-400: #dddde2;--brand-colors-neutral-300: #ebebee;--brand-colors-neutral-200: #f8f8fb;--brand-colors-neutral-100: #fafafa;--brand-colors-neutral-white: #ffffff;--brand-colors-blue-900: #043059;--brand-colors-blue-800: #082f75;--brand-colors-blue-700: #0c3b8d;--brand-colors-blue-600: #0645b1;--brand-colors-blue-500: #386ac1;--brand-colors-blue-400: #cddaef;--brand-colors-blue-300: #e6ecf7;--brand-colors-blue-200: #eef2f9;--brand-colors-blue-100: #f4f7fc;--brand-colors-gold-500: #877440;--brand-colors-gold-400: #e9e3d4;--brand-colors-gold-300: #f2efe8;--brand-colors-gold-200: #f9f6ed;--brand-colors-gold-100: #f9f7f4;--brand-colors-error-900: #920000;--brand-colors-error-500: #b60000;--brand-colors-success-900: #035c0f;--brand-colors-green: #ccffd4;--brand-colors-turquoise: #ccf7ff;--brand-colors-yellow: #f7ffcc;--brand-colors-peach: #ffd4cc;--brand-colors-violet: #f7ccff;--brand-colors-error-100: #fff2f2;--brand-colors-success-500: #05b01c;--brand-colors-success-100: #f0f8f1;--text-secondary: #535366;--icon-white: #ffffff;--background-beige-darker: #f2efe8;--icon-dark-grey: #535366;--type-font-family-sans-serif: DM Sans;--type-font-family-serif: Gupter;--type-font-family-mono: IBM Plex Mono;--type-weights-300: 300;--type-weights-400: 400;--type-weights-500: 500;--type-weights-700: 700;--type-sizes-12: 12px;--type-sizes-14: 14px;--type-sizes-16: 16px;--type-sizes-18: 18px;--type-sizes-20: 20px;--type-sizes-22: 22px;--type-sizes-24: 24px;--type-sizes-28: 28px;--type-sizes-30: 30px;--type-sizes-32: 32px;--type-sizes-40: 40px;--type-sizes-42: 42px;--type-sizes-48-2: 48px;--type-line-heights-16: 16px;--type-line-heights-20: 20px;--type-line-heights-23: 23px;--type-line-heights-24: 24px;--type-line-heights-25: 25px;--type-line-heights-26: 26px;--type-line-heights-29: 29px;--type-line-heights-30: 30px;--type-line-heights-32: 32px;--type-line-heights-34: 34px;--type-line-heights-35: 35px;--type-line-heights-36: 36px;--type-line-heights-38: 38px;--type-line-heights-40: 40px;--type-line-heights-46: 46px;--type-line-heights-48: 48px;--type-line-heights-52: 52px;--type-line-heights-58: 58px;--type-line-heights-68: 68px;--type-line-heights-74: 74px;--type-line-heights-82: 82px;--type-paragraph-spacings-0: 0px;--type-paragraph-spacings-4: 4px;--type-paragraph-spacings-8: 8px;--type-paragraph-spacings-16: 16px;--type-sans-serif-xl-font-weight: 400;--type-sans-serif-xl-size: 42px;--type-sans-serif-xl-line-height: 46px;--type-sans-serif-xl-paragraph-spacing: 16px;--type-sans-serif-lg-font-weight: 400;--type-sans-serif-lg-size: 32px;--type-sans-serif-lg-line-height: 38px;--type-sans-serif-lg-paragraph-spacing: 16px;--type-sans-serif-md-font-weight: 400;--type-sans-serif-md-line-height: 34px;--type-sans-serif-md-paragraph-spacing: 16px;--type-sans-serif-md-size: 28px;--type-sans-serif-xs-font-weight: 700;--type-sans-serif-xs-line-height: 25px;--type-sans-serif-xs-paragraph-spacing: 0px;--type-sans-serif-xs-size: 20px;--type-sans-serif-sm-font-weight: 400;--type-sans-serif-sm-line-height: 30px;--type-sans-serif-sm-paragraph-spacing: 16px;--type-sans-serif-sm-size: 24px;--type-body-xl-font-weight: 400;--type-body-xl-size: 24px;--type-body-xl-line-height: 36px;--type-body-xl-paragraph-spacing: 0px;--type-body-sm-font-weight: 400;--type-body-sm-size: 14px;--type-body-sm-line-height: 20px;--type-body-sm-paragraph-spacing: 8px;--type-body-xs-font-weight: 400;--type-body-xs-size: 12px;--type-body-xs-line-height: 16px;--type-body-xs-paragraph-spacing: 0px;--type-body-md-font-weight: 400;--type-body-md-size: 16px;--type-body-md-line-height: 20px;--type-body-md-paragraph-spacing: 4px;--type-body-lg-font-weight: 400;--type-body-lg-size: 20px;--type-body-lg-line-height: 26px;--type-body-lg-paragraph-spacing: 16px;--type-body-lg-medium-font-weight: 500;--type-body-lg-medium-size: 20px;--type-body-lg-medium-line-height: 32px;--type-body-lg-medium-paragraph-spacing: 16px;--type-body-md-medium-font-weight: 500;--type-body-md-medium-size: 16px;--type-body-md-medium-line-height: 20px;--type-body-md-medium-paragraph-spacing: 4px;--type-body-sm-bold-font-weight: 700;--type-body-sm-bold-size: 14px;--type-body-sm-bold-line-height: 20px;--type-body-sm-bold-paragraph-spacing: 8px;--type-body-sm-medium-font-weight: 500;--type-body-sm-medium-size: 14px;--type-body-sm-medium-line-height: 20px;--type-body-sm-medium-paragraph-spacing: 8px;--type-serif-md-font-weight: 400;--type-serif-md-size: 40px;--type-serif-md-paragraph-spacing: 0px;--type-serif-md-line-height: 48px;--type-serif-sm-font-weight: 400;--type-serif-sm-size: 28px;--type-serif-sm-paragraph-spacing: 0px;--type-serif-sm-line-height: 32px;--type-serif-lg-font-weight: 400;--type-serif-lg-size: 58px;--type-serif-lg-paragraph-spacing: 0px;--type-serif-lg-line-height: 68px;--type-serif-xs-font-weight: 400;--type-serif-xs-size: 18px;--type-serif-xs-line-height: 24px;--type-serif-xs-paragraph-spacing: 0px;--type-serif-xl-font-weight: 400;--type-serif-xl-size: 74px;--type-serif-xl-paragraph-spacing: 0px;--type-serif-xl-line-height: 82px;--type-mono-md-font-weight: 400;--type-mono-md-size: 22px;--type-mono-md-line-height: 24px;--type-mono-md-paragraph-spacing: 0px;--type-mono-lg-font-weight: 400;--type-mono-lg-size: 40px;--type-mono-lg-line-height: 40px;--type-mono-lg-paragraph-spacing: 0px;--type-mono-sm-font-weight: 400;--type-mono-sm-size: 14px;--type-mono-sm-line-height: 24px;--type-mono-sm-paragraph-spacing: 0px;--spacing-xs-4: 4px;--spacing-xs-8: 8px;--spacing-xs-16: 16px;--spacing-sm-24: 24px;--spacing-sm-32: 32px;--spacing-md-40: 40px;--spacing-md-48: 48px;--spacing-lg-64: 64px;--spacing-lg-80: 80px;--spacing-xlg-104: 104px;--spacing-xlg-152: 152px;--spacing-xs-12: 12px;--spacing-page-section: 152px;--spacing-card-list-spacing: 48px;--spacing-text-section-spacing: 80px;--spacing-md-xs-headings: 40px;--corner-radius-radius-lg: 16px;--corner-radius-radius-sm: 4px;--corner-radius-radius-md: 8px;--corner-radius-radius-round: 104px}}</style><link rel="stylesheet" href="//a.academia-assets.com/assets/single_work_page/loswp_redesigns/outline_variant-b5f899f4ac239d914d04c9babc001d20602fa1525b7f7d8a04fa5418503b767f.css" media="all" /><link rel="stylesheet" href="//a.academia-assets.com/assets/single_work_page/outline-81167b90d0109620221d366e55ca8f498a621752df59ae26b6678cf0870d7f37.css" media="all" /><link rel="stylesheet" href="//a.academia-assets.com/assets/design_system/body-c50f5ab98832f511df8842993148351135752147645352dc0b07c369bcb29ab7.css" media="all" /><link rel="stylesheet" href="//a.academia-assets.com/assets/design_system/button-71718c8dba3ea0db0a554a601dbc5855a002afaefa44dbf4215a94ca1560cb81.css" media="all" /><link rel="stylesheet" href="//a.academia-assets.com/assets/design_system/heading-95367dc03b794f6737f30123738a886cf53b7a65cdef98a922a98591d60063e3.css" media="all" /><link rel="stylesheet" href="//a.academia-assets.com/assets/design_system/text_button-d1941ab08e91e29ee143084c4749da4aaffa350a2ac6eec2306b1d7a352d911a.css" media="all" /><link rel="stylesheet" href="//a.academia-assets.com/assets/single_work_page/ai_label-529f80fc4bfd876bcf14704d39f2468fffef86fe603e426ab9a313e3abd3ac37.css" media="all" /><link rel="stylesheet" href="//a.academia-assets.com/assets/single_work_page/figure_carousel-1795bc7b8565cd8537405a7fe0e2e1917953e373c4a174c78c8745c366b9620d.css" media="all" /><link rel="stylesheet" href="//a.academia-assets.com/assets/single_work_page/ordered_list-9123030494f589694fc98dd7b689a70398eb527516b541b1c648dce5ab690c12.css" media="all" /><link rel="stylesheet" href="//a.academia-assets.com/assets/about_hiring/footer-4b1d1471325a90ac5ba51422db929bc292e3d4469d0fabb80d93ab2310ff2719.css" media="all" /><link rel="preload" href="//a.academia-assets.com/fonts/design_system/DM-Sans_100-1000_normal_latin.woff2" as="font" type="font/woff2" crossorigin="anonymous"><link rel="preload" href="//a.academia-assets.com/fonts/design_system/Gupter_400_normal_latin.woff2" as="font" type="font/woff2" crossorigin="anonymous"><link rel="preload" href="//a.academia-assets.com/fonts/design_system/Material-Symbols-Outlined.woff2" as="font" type="font/woff2" crossorigin="anonymous"><link rel="preload" href="//a.academia-assets.com/fonts/design_system/Roboto_100-900_normal_latin.woff2" as="font" type="font/woff2" crossorigin="anonymous"><link rel="stylesheet" href="//a.academia-assets.com/assets/design_system/font-faces-efad2d03062f07fc8ad9218be9cffc066b9dcb4118790653009961988e50304c.css" media="all" /><link rel="stylesheet" href="//a.academia-assets.com/assets/design_system/common-3c00d3ae0a9cc0bf1476231d85efc602ef73468a39e42dc5dd2bb62d223c4005.css" media="all" />
  </head>

  <body>
    <div id='react-modal'></div>




    <div class="js-upgrade-ie-banner" style="display: none; text-align: center; padding: 8px 0; background-color: #ebe480;"><p style="color: #000; font-size: 12px; margin: 0 0 4px;">Academia.edu no longer supports Internet Explorer.</p><p style="color: #000; font-size: 12px; margin: 0;">To browse Academia.edu and the wider internet faster and more securely, please take a few seconds to&nbsp;<a href="https://www.academia.edu/upgrade-browser">upgrade your browser</a>.</p></div><script>// Show this banner for all versions of IE
if (!!window.MSInputMethodContext || /(MSIE)/.test(navigator.userAgent)) {
  document.querySelector('.js-upgrade-ie-banner').style.display = 'block';
}</script>

      <div id="fb-root"></div><script>window.fbAsyncInit = function() {
  FB.init({
    appId: "2369844204",
    version: "v8.0",
    status: true,
    cookie: true,
    xfbml: true
  });

  // Additional initialization code.
  if (window.InitFacebook) {
    // facebook.ts already loaded, set it up.
    window.InitFacebook();
  } else {
    // Set a flag for facebook.ts to find when it loads.
    window.academiaAuthReadyFacebook = true;
  }
};</script>
      <div id="google-root"></div><script>window.loadGoogle = function() {
  if (window.InitGoogle) {
    // google.ts already loaded, set it up.
    window.InitGoogle("331998490334-rsn3chp12mbkiqhl6e7lu2q0mlbu0f1b");
  } else {
    // Set a flag for google.ts to use when it loads.
    window.GoogleClientID = "331998490334-rsn3chp12mbkiqhl6e7lu2q0mlbu0f1b";
  }
};</script>

      <div class="header--container" id="main-header-container"><div class="header--inner-container header--inner-container-ds2"><div class="header-ds2--left-wrapper"><div class="header-ds2--left-wrapper-inner"><a data-main-header-link-target="logo_home" href="https://www.academia.edu/"><img class="hide-on-desktop-redesign" style="height: 24px; width: 24px;" alt="Academia.edu" src="//a.academia-assets.com/images/academia-logo-redesign-2015-A.svg" width="24" height="24" /><img width="145.2" height="18" class="hide-on-mobile-redesign" style="height: 24px;" alt="Academia.edu" src="//a.academia-assets.com/images/academia-logo-redesign-2015.svg" /></a><div class="header--search-container header--search-container-ds2"><form class="js-SiteSearch-form select2-no-default-pills" action="https://www.academia.edu/search" accept-charset="UTF-8" method="get"><svg style="width: 14px; height: 14px;" aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="header--search-icon svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"></path></svg><input class="header--search-input header--search-input-ds2 js-SiteSearch-form-input" data-main-header-click-target="search_input" name="q" placeholder="Search" type="text" /></form></div></div></div><nav class="header--nav-buttons header--nav-buttons-ds2 js-main-nav"><button class="ds2-5-button ds2-5-button--secondary js-header-login-url header-button-ds2 header-login-ds2 hide-on-mobile-redesign react-login-modal-opener" data-signup-modal="{&quot;location&quot;:&quot;login-button--header&quot;}" rel="nofollow">Log In</button><button class="ds2-5-button ds2-5-button--secondary header-button-ds2 hide-on-mobile-redesign react-login-modal-opener" data-signup-modal="{&quot;location&quot;:&quot;signup-button--header&quot;}" rel="nofollow">Sign Up</button><button class="header--hamburger-button header--hamburger-button-ds2 hide-on-desktop-redesign js-header-hamburger-button"><div class="icon-bar"></div><div class="icon-bar" style="margin-top: 4px;"></div><div class="icon-bar" style="margin-top: 4px;"></div></button></nav></div><ul class="header--dropdown-container js-header-dropdown"><li class="header--dropdown-row"><a class="header--dropdown-link" href="https://www.academia.edu/login" rel="nofollow">Log In</a></li><li class="header--dropdown-row"><a class="header--dropdown-link" href="https://www.academia.edu/signup" rel="nofollow">Sign Up</a></li><li class="header--dropdown-row js-header-dropdown-expand-button"><button class="header--dropdown-button">more<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="caret-down" class="header--dropdown-button-icon svg-inline--fa fa-caret-down fa-w-10" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M31.3 192h257.3c17.8 0 26.7 21.5 14.1 34.1L174.1 354.8c-7.8 7.8-20.5 7.8-28.3 0L17.2 226.1C4.6 213.5 13.5 192 31.3 192z"></path></svg></button></li><li><ul class="header--expanded-dropdown-container"><li class="header--dropdown-row"><a class="header--dropdown-link" href="https://www.academia.edu/about">About</a></li><li class="header--dropdown-row"><a class="header--dropdown-link" href="https://www.academia.edu/press">Press</a></li><li class="header--dropdown-row"><a class="header--dropdown-link" href="https://www.academia.edu/documents">Papers</a></li><li class="header--dropdown-row"><a class="header--dropdown-link" href="https://www.academia.edu/terms">Terms</a></li><li class="header--dropdown-row"><a class="header--dropdown-link" href="https://www.academia.edu/privacy">Privacy</a></li><li class="header--dropdown-row"><a class="header--dropdown-link" href="https://www.academia.edu/copyright">Copyright</a></li><li class="header--dropdown-row"><a class="header--dropdown-link" href="https://www.academia.edu/hiring"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="briefcase" class="header--dropdown-row-icon svg-inline--fa fa-briefcase fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M320 336c0 8.84-7.16 16-16 16h-96c-8.84 0-16-7.16-16-16v-48H0v144c0 25.6 22.4 48 48 48h416c25.6 0 48-22.4 48-48V288H320v48zm144-208h-80V80c0-25.6-22.4-48-48-48H176c-25.6 0-48 22.4-48 48v48H48c-25.6 0-48 22.4-48 48v80h512v-80c0-25.6-22.4-48-48-48zm-144 0H192V96h128v32z"></path></svg>We&#39;re Hiring!</a></li><li class="header--dropdown-row"><a class="header--dropdown-link" href="https://support.academia.edu/hc/en-us"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="question-circle" class="header--dropdown-row-icon svg-inline--fa fa-question-circle fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zM262.655 90c-54.497 0-89.255 22.957-116.549 63.758-3.536 5.286-2.353 12.415 2.715 16.258l34.699 26.31c5.205 3.947 12.621 3.008 16.665-2.122 17.864-22.658 30.113-35.797 57.303-35.797 20.429 0 45.698 13.148 45.698 32.958 0 14.976-12.363 22.667-32.534 33.976C247.128 238.528 216 254.941 216 296v4c0 6.627 5.373 12 12 12h56c6.627 0 12-5.373 12-12v-1.333c0-28.462 83.186-29.647 83.186-106.667 0-58.002-60.165-102-116.531-102zM256 338c-25.365 0-46 20.635-46 46 0 25.364 20.635 46 46 46s46-20.636 46-46c0-25.365-20.635-46-46-46z"></path></svg>Help Center</a></li><li class="header--dropdown-row js-header-dropdown-collapse-button"><button class="header--dropdown-button">less<svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="caret-up" class="header--dropdown-button-icon svg-inline--fa fa-caret-up fa-w-10" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M288.662 352H31.338c-17.818 0-26.741-21.543-14.142-34.142l128.662-128.662c7.81-7.81 20.474-7.81 28.284 0l128.662 128.662c12.6 12.599 3.676 34.142-14.142 34.142z"></path></svg></button></li></ul></li></ul></div>

    

    <script>window.pageData = {
  real_authors: [],
  license: "",
  attribution: ""
}</script><script src="//a.academia-assets.com/assets/webpack_bundles/runtime-modern-bundle-5a0793c38c53136ba6311f20acbafb2f543ccae5a8cace90557fca4ec9a6458d.js" defer="defer"></script>
<script src="//a.academia-assets.com/assets/webpack_bundles/vendor-react-bundle-e04232e750586a09d402fd1a4aa8b8c7d0f1000e1d7f0cfdb9007bf2370d0e9a.js" defer="defer"></script>
<script src="//a.academia-assets.com/assets/webpack_bundles/fast_loswp-bundle-c6234a6d6cea589ae15b5914e0f9f146dfc95683655c92405ee4a8c1dd81954c.js" defer="defer"></script><script>window.loswp = {};
window.loswp.shouldDetectTimezone = true;
window.loswp.work = {"work":{"id":111735900,"created_at":"2023-12-18T06:26:36.733-08:00","from_world_paper_id":null,"updated_at":"2025-05-13T09:00:22.489-07:00","_data":{"ai_abstract":"This dissertation project delves into the burgeoning realm of conversational AI, with a specific focus on its application in creative AI and storytelling. It centres around the development of a conversational theatrical engine and explores the latest advancements in conversational AI architecture. While acknowledging the resource-intensive nature of building conversational engines, including meticulous preparation, user testing, and technical expertise, this study underscores the potential of conversational agents as efficient learning tools that offer both accessibility and privacy assurances. The project showcases the development of a mobile application utilizing the waterfall methodology and harnessing the capabilities of the latest GPT model, GPT-4, boasting an impressive 1.76 trillion parameters. This development leverages Python programming and the FastAPI framework for the backend, while the frontend is crafted using the React Native framework. Rigorous testing, conducted through Postman and feedback collection from diverse users, has revealed insightful statistics. Notably, 69.7% of users had never previously encountered a similar storytelling app, indicating a unique offering. Moreover, a substantial 67.8% of users expressed comfort in interacting with an AI tool, with 16.1% holding a neutral stance. The application itself is designed for creative AI, functioning as a thespian, and facilitating interactive storytelling experiences. User feedback revealed diverse usage patterns, with 39.4% utilizing it for learning and seeking answers, 36.4% for storytelling purposes, and 24.2% employing the app to generate scripts for acting. This project not only highlights the potential of conversational AI in creative contexts but also provides valuable insights into user perceptions and adoption, paving the way for future advancements in the field.","markdown_attachment_ids":"109184332"},"document_type":"paper","pre_hit_view_count_baseline":null,"quality":"high","language":"en","title":"AI-POWERED THESPIAN: DEVELOPING AN INNOVATIVE CONVERSATIONAL ENGINE","broadcastable":true,"draft":null,"has_indexable_attachment":true,"indexable":true,"seo_quality":4}}["work"];
window.loswp.previewableAttachments = [{"id":109184332,"identifier":"Attachment_109184332","shouldShowBulkDownload":false}];
window.loswp.hasViewableAttachments = true;
window.loswp.cwvAbTestBucket = "";
window.loswp.designVariant = "outline";
window.loswp.useOptimizedScribd4genScript = false;

window.loginModal = {};
window.loginModal.appleClientId = 'edu.academia.applesignon';
window.userInChina = "false";</script><script defer="" src="https://accounts.google.com/gsi/client"></script><div class="safe-loswp--grid-container"><div class="left-rail--container"><div class="outline--wrapper  outline-variant--outline"><div class="outline--heading"><p class="ds2-5-body-md-bold">Outline</p><button aria-controls="outline" aria-expanded="false" aria-label="Expand outline" class="ds2-5-button ds2-5-button--inverse js-tc-loswp--outline-toggle outline--toggle js-outline-toggle"><span class="material-symbols-outlined" style="font-size: 20px" translate="no">keyboard_arrow_down</span></button><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--outline-toggle"};
  const button = document.querySelector('.js-tc-loswp--outline-toggle');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script></div><div class="outline--container js-outline-container" id="outline"><div class="outline--progress-container"><div class="outline--progress-line js-outline-progress-line"></div></div><div class="outline--elements-container"><div class="outline--element js-outline-element-title primary" data-target-id="title"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#title">Title</a></div><div class="outline--element js-outline-element-abstract " data-target-id="abstract"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#abstract">Abstract</a></div><div class="outline--element js-outline-element-figures " data-target-id="figures"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#figures">Figures</a></div><div class="outline--element js-outline-element-outer_page_10 " data-target-id="outer_page_10"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#outer_page_10">Chapter One -Introduction</a></div><div class="outline--element js-outline-element-outer_page_10 " data-target-id="outer_page_10"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#outer_page_10">Background of the Study</a></div><div class="outline--element js-outline-element-outer_page_10 " data-target-id="outer_page_10"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#outer_page_10">Research Objectives</a></div><div class="outline--element js-outline-element-outer_page_11 " data-target-id="outer_page_11"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#outer_page_11">Justification of the Study</a></div><div class="outline--element js-outline-element-outer_page_11 " data-target-id="outer_page_11"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#outer_page_11">Scope of the Study</a></div><div class="outline--element js-outline-element-outer_page_47 " data-target-id="outer_page_47"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#outer_page_47">Chapter Six -Conclusion and Recommendation</a></div><div class="outline--element js-outline-element-outer_page_47 " data-target-id="outer_page_47"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#outer_page_47">Conclusion</a></div><div class="outline--element js-outline-element-outer_page_48 " data-target-id="outer_page_48"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#outer_page_48">Recommendation</a></div><div class="outline--element js-outline-element-outer_page_49 " data-target-id="outer_page_49"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#outer_page_49">Database Connection Challenges</a></div><div class="outline--element js-outline-element-references " data-target-id="references"><div class="outline--progress-dot"></div><a class="outline--element-label js-tc-loswp--outline-navigation" href="#references">References</a></div></div></div></div><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const outlineElements = {"Title":"title","Abstract":"abstract","Figures":"figures","Chapter One -Introduction":"outer_page_10","Background of the Study":"outer_page_10","Research Objectives":"outer_page_10","Justification of the Study":"outer_page_11","Scope of the Study":"outer_page_11","Chapter Six -Conclusion and Recommendation":"outer_page_47","Conclusion":"outer_page_47","Recommendation":"outer_page_48","Database Connection Challenges":"outer_page_49","References":"references"};
  Object.entries(outlineElements).forEach(([elementName, elementId]) => {
    const button = document.querySelector(`.js-outline-element-${elementId} .js-tc-loswp--outline-navigation`);
    if (!button) return;
    button.addEventListener('click', () => {
      fetch('/v0/clicks?subdomain_param=api', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'X-CSRF-Token': csrfToken,
        },
        keepalive: true,
        mode: 'same-origin',
        body: JSON.stringify({
          source: 'loswp--outline-navigation',
          extra: { element_name: elementName },
          occurred_at: new Date(),
          hit_id: window.Aedu?.hit_data?.id,
        }),
      });
    });
  });
});</script></div><div class="main-content--container"><div class="safe-work-card--container js-loswp-work-card" id="loswp-work-card"><div class="safe-work-card--cover"><div class="ds-work-cover--wrapper"><div class="ds-work-cover--container"><style>.login-ghost-button {
  background: none;
  border: none;
  padding: 0;
  width: 100%;

  display: block;
  cursor: pointer;
  position: relative;
}</style><button class="js-login-button--acd6bd6a login-ghost-button ds-work-cover--clickable"><img alt="First page of AI-POWERED THESPIAN: DEVELOPING AN INNOVATIVE CONVERSATIONAL ENGINE" class="ds-work-cover--cover-thumbnail" src="https://0.academia-photos.com/attachment_thumbnails/109184332/mini_magick20231218-1-dvvtbz.png?1702909655" /><img alt="PDF Icon" class="ds-work-cover--file-icon" src="//a.academia-assets.com/images/single_work_splash/adobe_icon.svg" /><div class="ds-work-cover--hover-container"><span class="material-symbols-outlined" style="font-size: 20px" translate="no">download</span><p>Download Free PDF</p></div><div class="ds-work-cover--ribbon-container">Download Free PDF</div><div class="ds-work-cover--ribbon-triangle"></div></button><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--acd6bd6a'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE","clickTrackingContext":{"source":"loswp--swp-splash-paper-cover","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":109184332}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script></div></div></div><div class="safe-work-card--work-information"><h1 class="ds-work-card--work-title ds2-5-heading-sans-serif-lg" id="title">AI-POWERED THESPIAN: DEVELOPING AN INNOVATIVE CONVERSATIONAL ENGINE</h1><div class="ds-work-card--work-authors ds-work-card--detail"><a class="ds-work-card--author js-wsj-grid-card-author ds2-5-body-md ds2-5-body-link" data-author-id="99875356" href="https://mmu.academia.edu/RichardOgundele"><img alt="Profile image of Richard A D E M O L A Ogundele" class="ds-work-card--author-avatar" src="https://0.academia-photos.com/99875356/28093261/162876365/s65_richard.ogundele.jpg" />Richard A D E M O L A Ogundele</a></div><div class="ds-work-card--detail"><div class="work-publishing-metadata"><strong>Uploaded&nbsp;</strong>(2023)</div></div><div class="ds-work-card--work-metadata"><div class="ds-work-card--work-metadata__stat"><span class="material-symbols-outlined" style="font-size: 20px" translate="no">visibility</span><p class="ds2-5-body-sm" id="work-metadata-view-count"></p></div><div class="ds-work-card--work-metadata__stat"><span class="material-symbols-outlined" style="font-size: 20px" translate="no">description</span><p class="ds2-5-body-sm">72 pages</p></div><div class="ds-work-card--work-metadata__stat"><span class="material-symbols-outlined" style="font-size: 20px" translate="no">link</span><p class="ds2-5-body-sm">1 file</p></div></div><script>(async () => {
  const workId = 111735900;
  const worksViewsPath = "/v0/works/views?subdomain_param=api&amp;work_ids%5B%5D=111735900";

  const getWorkViews = async (workId) => {
    const response = await fetch(worksViewsPath);

    if (!response.ok) {
      throw new Error('Failed to load work views');
    }

    const data = await response.json();

    return data.views[workId];
  };
  // Get the view count for the work - we send this immediately rather than waiting for
  // the DOM to load, so it can be available as soon as possible (but without holding up
  // the backend or other resource requests, because it's a bit expensive and not critical).
  const viewCount = await getWorkViews(workId);

  const updateViewCount = (viewCount) => {
    try {
      const viewCountNumber = parseInt(viewCount, 10);
      if (viewCountNumber === 0) {
        // Remove the whole views element if there are zero views.
        document.getElementById('work-metadata-view-count')?.parentNode?.remove();
        return;
      }

      const commaizedViewCount = viewCountNumber.toLocaleString();

      const viewCountBody = document.getElementById('work-metadata-view-count');

      if (!viewCountBody) {
        throw new Error('Failed to find work views element');
      }

      viewCountBody.textContent = `${commaizedViewCount} views`;
    } catch (error) {
      // Remove the whole views element if there was some issue parsing.
      document.getElementById('work-metadata-view-count')?.parentNode?.remove();
      throw new Error(`Failed to parse view count: ${viewCount}`, error);
    }
  };

  // If the DOM is still loading, wait for it to be ready before updating the view count.
  if (document.readyState === "loading") {
    document.addEventListener('DOMContentLoaded', () => {
      updateViewCount(viewCount);
    });
  // Otherwise, just update it immediately.
  } else {
    updateViewCount(viewCount);
  }
})();</script><div class="ds-work-card--button-container"><div class="primary-buttons"><button class="ds2-5-button js-tc-loswp--continue-reading-button--work-card js-login-button--d185ef85"><span class="material-symbols-outlined" style="font-size: 20px" translate="no">description</span>See full PDF</button><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--continue-reading-button--work-card","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}};
  const button = document.querySelector('.js-tc-loswp--continue-reading-button--work-card');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--d185ef85'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE","clickTrackingContext":{"source":"loswp--continue-reading-button--work-card","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":109184332}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><button class="ds2-5-button ds2-5-button--secondary js-tc-loswp--download-pdf-button--work-card js-login-button--e1cf6e73"><span class="material-symbols-outlined" style="font-size: 20px" translate="no">download</span>Download PDF</button><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--download-pdf-button--work-card","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}};
  const button = document.querySelector('.js-tc-loswp--download-pdf-button--work-card');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--e1cf6e73'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE?auto=download","clickTrackingContext":{"source":"loswp--download-pdf-button--work-card","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}},"configuredText":{"buttonsPage":{"header":"Download your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue with your free download."},"emailLoginPage":{"subheader":"Log in to continue with your free download."},"emailRegistrationPage":{"subheader":"Sign up to continue with your free download.","submit":"Start Download"}},"registrationParams":{"user_source":"download","doc_id":109184332,"auto":"download"}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><div id="js-react-on-rails-context" style="display:none" data-rails-context="{&quot;inMailer&quot;:false,&quot;i18nLocale&quot;:&quot;en&quot;,&quot;i18nDefaultLocale&quot;:&quot;en&quot;,&quot;href&quot;:&quot;https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE&quot;,&quot;location&quot;:&quot;/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE&quot;,&quot;scheme&quot;:&quot;https&quot;,&quot;host&quot;:&quot;www.academia.edu&quot;,&quot;port&quot;:null,&quot;pathname&quot;:&quot;/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE&quot;,&quot;search&quot;:null,&quot;httpAcceptLanguage&quot;:null,&quot;serverSide&quot;:false}"></div>
<div class="js-react-on-rails-component" style="display:none" data-component-name="CitationButton" data-props="{&quot;workId&quot;:111735900,&quot;source&quot;:&quot;swp_citation_modal&quot;,&quot;buttonClassName&quot;:&quot;ds-work-card--citation-button&quot;}" data-trace="false" data-dom-id="CitationButton-react-component-737158b3-d809-42ea-9f66-1830edbbc5db"></div>
    <div id="CitationButton-react-component-737158b3-d809-42ea-9f66-1830edbbc5db"></div>
    
</div><div class="share-and-save-buttons"><button class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--bookmark-button--work-card js-login-button--0291c35c"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">bookmark</span><span class="ds2-5-text-link__content">Save to Library</span></button><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--bookmark-button--work-card","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}};
  const button = document.querySelector('.js-tc-loswp--bookmark-button--work-card');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--0291c35c'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE","clickTrackingContext":{"source":"loswp--bookmark-button--work-card","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":109184332}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><button class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--share-button--work-card js-login-button--820059f9"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">share</span><span class="ds2-5-text-link__content">Share</span></button><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--share-button--work-card","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}};
  const button = document.querySelector('.js-tc-loswp--share-button--work-card');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--820059f9'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE","clickTrackingContext":{"source":"loswp--share-button--work-card","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":109184332}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script></div></div><div class="ds-signup-banner-trigger-container"><div class="ds-signup-banner-trigger ds-signup-banner-trigger-control"></div></div><div class="ds-signup-banner ds-signup-banner-control"><div id="ds-signup-banner-close-button"><button class="ds2-5-button ds2-5-button--secondary ds2-5-button--inverse"><span class="material-symbols-outlined" style="font-size: 20px" translate="no">close</span></button></div><div class="ds-signup-banner-ctas" data-impression-entity-id="111735900" data-impression-entity-type="2" data-impression-source="signup-banner"><img src="//a.academia-assets.com/images/academia-logo-capital-white.svg" /><h4 class="ds2-5-heading-serif-sm">Sign up for access to the world's latest research</h4><button class="ds2-5-button ds2-5-button--inverse ds2-5-button--full-width js-tc-loswp--signup-banner js-login-button--c2abe791">Sign up for free<span class="material-symbols-outlined" style="font-size: 20px" translate="no">arrow_forward</span></button><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--signup-banner","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}};
  const button = document.querySelector('.js-tc-loswp--signup-banner');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--c2abe791'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE","clickTrackingContext":{"source":"loswp--signup-banner","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":109184332}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script></div><div class="ds-signup-banner-divider"></div><div class="ds-signup-banner-reasons"><div class="ds-signup-banner-reasons-item"><span class="material-symbols-outlined" style="font-size: 24px" translate="no">check</span><span>Get notified about relevant papers</span></div><div class="ds-signup-banner-reasons-item"><span class="material-symbols-outlined" style="font-size: 24px" translate="no">check</span><span>Save papers to use in your research</span></div><div class="ds-signup-banner-reasons-item"><span class="material-symbols-outlined" style="font-size: 24px" translate="no">check</span><span>Join the discussion with peers</span></div><div class="ds-signup-banner-reasons-item"><span class="material-symbols-outlined" style="font-size: 24px" translate="no">check</span><span>Track your impact</span></div></div></div><script>(() => {
  // Set up signup banner show/hide behavior:
  // 1. If the signup banner trigger (a 242px-high* invisible div underneath the 'See Full PDF' / 'Download PDF' buttons)
  //    is already fully scrolled above the viewport, show the banner by default
  // 2. If the signup banner trigger is fully visible, show the banner
  // 3. If the signup banner trigger has even a few pixels scrolled below the viewport, hide the banner
  //
  // * 242px is the empirically determined height of the signup banner. It's better to be a bit taller than
  //   necessary than too short, so it's fine that the mobile (small breakpoint) banner is shorter.

  // First check session storage for the signup banner's visibility state
  const signupBannerHidden = sessionStorage.getItem('ds-signup-banner-hidden');
  if (signupBannerHidden === 'true') {
    return;
  }

  const signupBanner = document.querySelector('.ds-signup-banner');
  const signupBannerTrigger = document.querySelector('.ds-signup-banner-trigger');

  let footerShown = false;

  window.addEventListener('load', () => {
    const rect = signupBannerTrigger.getBoundingClientRect();
    // If page loaded up already scrolled below the trigger (via scroll restoration), show the banner by default
    if (rect.bottom < 0) {
      footerShown = true;
      signupBanner.classList.add('ds-signup-banner-visible');
    }
  });

  // Wait for trigger to fully enter viewport before showing banner (ensures PDF CTAs are never covered by banner)
  const observer = new IntersectionObserver((entries) => {
    entries.forEach(entry => {
      if (entry.isIntersecting && !footerShown) {
        footerShown = true;
        signupBanner.classList.add('ds-signup-banner-visible');
      } else if (!entry.isIntersecting && footerShown) {
        if (signupBannerTrigger.getBoundingClientRect().bottom > 0) {
          footerShown = false;
          signupBanner.classList.remove('ds-signup-banner-visible');
        }
      }
    });
  });
  observer.observe(signupBannerTrigger);

  // Set up signup banner close button event handler:
  const signupBannerCloseButton = document.querySelector('#ds-signup-banner-close-button');
  signupBannerCloseButton.addEventListener('click', () => {
    signupBanner.classList.remove('ds-signup-banner-visible');
    observer.unobserve(signupBannerTrigger);

    // Store the signup banner's visibility state in session storage
    sessionStorage.setItem('ds-signup-banner-hidden', 'true');
  });
})();</script></div></div><style>@media screen and (min-width: 568px) and (max-width: 621px) {  .ds-work-card--button-container .primary-buttons .ds2-5-button, .ds-work-card--citation-button {    font-size: var(--font-size-small);    line-height: var(--line-height-small);    padding: 0 var(--buttons-small-buttons-l-r-padding, 12px);    height: var(--buttons-small-buttons-height, 44px);    gap: var(--buttons-small-buttons-gap, 8px);    border-radius: var(--buttons-small-buttons-corner-radius, 8px);  }}@media screen and (min-width: 1280px) and (max-width: 1515px) {  .ds-work-card--button-container .primary-buttons .ds2-5-button, .ds-work-card--citation-button {    font-size: var(--font-size-small);    line-height: var(--line-height-small);    padding: 0 var(--buttons-small-buttons-l-r-padding, 12px);    height: var(--buttons-small-buttons-height, 44px);    gap: var(--buttons-small-buttons-gap, 8px);    border-radius: var(--buttons-small-buttons-corner-radius, 8px);  } .ds-work-card--button-container {   flex-direction: column !important; } .ds-work-card--button-container .share-and-save-buttons {   align-self: start; }}</style><div data-auto_select="false" data-client_id="331998490334-rsn3chp12mbkiqhl6e7lu2q0mlbu0f1b" data-doc_id="109184332" data-landing_url="https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE" data-login_uri="https://www.academia.edu/registrations/google_one_tap" data-use_fedcm_for_prompt="true" id="g_id_onload"></div><div class="safe-abstract--container"><h2 class="safe-abstract--heading ds2-5-heading-sans-serif-lg" id="abstract">Abstract<div class="ai-label"><img alt="sparkles" src="//a.academia-assets.com/images/icons/sparkle.svg" width="16" height="16" /><p class="ds2-5-body-xs">AI</p></div></h2><div class="safe-abstract--body"><style>.truncate-component {
  position: relative;

  overflow: hidden;
  display: -webkit-box;
  line-clamp: 16;
  -webkit-line-clamp: 16;
  -webkit-box-orient: vertical;
}

.toggle-truncation-button {
  display: none;
  position: absolute;
  bottom: 0;
  right: 0;
}</style><div class="truncate-component js-truncate-component--abstract"><p class="ds2-5-body-md">This dissertation project delves into the burgeoning realm of conversational AI, with a specific focus on its application in creative AI and storytelling. It centres around the development of a conversational theatrical engine and explores the latest advancements in conversational AI architecture. While acknowledging the resource-intensive nature of building conversational engines, including meticulous preparation, user testing, and technical expertise, this study underscores the potential of conversational agents as efficient learning tools that offer both accessibility and privacy assurances. The project showcases the development of a mobile application utilizing the waterfall methodology and harnessing the capabilities of the latest GPT model, GPT-4, boasting an impressive 1.76 trillion parameters. This development leverages Python programming and the FastAPI framework for the backend, while the frontend is crafted using the React Native framework. Rigorous testing, conducted through Postman and feedback collection from diverse users, has revealed insightful statistics. Notably, 69.7% of users had never previously encountered a similar storytelling app, indicating a unique offering. Moreover, a substantial 67.8% of users expressed comfort in interacting with an AI tool, with 16.1% holding a neutral stance. The application itself is designed for creative AI, functioning as a thespian, and facilitating interactive storytelling experiences. User feedback revealed diverse usage patterns, with 39.4% utilizing it for learning and seeking answers, 36.4% for storytelling purposes, and 24.2% employing the app to generate scripts for acting. This project not only highlights the potential of conversational AI in creative contexts but also provides valuable insights into user perceptions and adoption, paving the way for future advancements in the field.</p><div class="toggle-truncation-button js-toggle-truncation-button--abstract"><button class="safe-abstract--toggle-truncation-button"><span>... </span><span class="safe-abstract--toggle-truncation-button-text">Read more</span></button></div></div></div></div><div class="safe-figure-carousel-section--container"><div class="safe-figure-carousel-section--heading" id="figures">Figures (22)</div><div class="safe-figure-carousel--container"><div class="carousel-container js-figure-carousel carousel-container--md" id="loswp-figures"><div class="prev-slide-container js-prev-button-container"><button aria-label="Previous" class="carousel-navigation-button js-loswp-figures-prev"><span class="material-symbols-outlined" style="font-size: 24px" translate="no">arrow_back_ios</span></button></div><div class="slides-container js-slides-container"><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10054976/figure-1-ai-powered-thespian-developing-an-innovative"><img alt="" class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_001.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs"></figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055190/table-1-ai-powered-thespian-developing-an-innovative"><img alt="" class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/table_001.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs"></figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055199/table-2-ai-powered-thespian-developing-an-innovative"><img alt="" class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/table_002.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs"></figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10054992/figure-2-dealt-with-through-entity-extraction-dong-et-al-and"><img alt="dealt with through entity extraction. (X. Dong et al., 2016).  and requesting a prescription for medication. (J. Chen et al, 2018). The What of the input is " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_002.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">dealt with through entity extraction. (X. Dong et al., 2016).  and requesting a prescription for medication. (J. Chen et al, 2018). The What of the input is </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10054996/figure-3-large-language-models-gpt-gpt-neo-gpt-neox-gpt-palm"><img alt="3.3 Large Language Models  GPT-3, GPT-Neo, GPT-NeoX, GPT-J, PaLM, Galactica, and LLaMA, which are trained on vast " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_003.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">3.3 Large Language Models  GPT-3, GPT-Neo, GPT-NeoX, GPT-J, PaLM, Galactica, and LLaMA, which are trained on vast </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055010/figure-3-timeline-of-recently-developed-big-language-models"><img alt="Figure 3.2: a timeline of recently developed big language models (greater than 10B in size).  In the context of large language models and machine learning there are learning approaches " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_004.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">Figure 3.2: a timeline of recently developed big language models (greater than 10B in size).  In the context of large language models and machine learning there are learning approaches </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055021/figure-3-zero-shot-one-shot-and-few-shot-learning-on-llms"><img alt="Figure 3.3  Zero shot, one shot and few shot learning on LLMs. " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_005.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">Figure 3.3  Zero shot, one shot and few shot learning on LLMs. </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055212/table-3-entertainment-where-particular-tone-or-style-is"><img alt="entertainment where a particular tone or style is sought.  helpful when creating content for industries like medical, education, marketing, or art and " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/table_003.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">entertainment where a particular tone or style is sought.  helpful when creating content for industries like medical, education, marketing, or art and </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055227/figure-3-and-balanced-examples-when-training-gpt-for"><img alt="and balanced examples when training GPT for sentiment classification, covering all desired  Figure 3.6  Few shots learning through sentiment analysis using GPT 3.5 Turbo " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/table_004.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">and balanced examples when training GPT for sentiment classification, covering all desired  Figure 3.6  Few shots learning through sentiment analysis using GPT 3.5 Turbo </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055032/figure-3-high-level-architecture-for-voice-based"><img alt="Figure 3.7: High level architecture for voice-based conversational AI agents  conducting a specific task. (Ibrahim &amp; Varol, 2020) " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_006.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">Figure 3.7: High level architecture for voice-based conversational AI agents  conducting a specific task. (Ibrahim &amp; Varol, 2020) </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055038/figure-4-system-architecture-for-software-development"><img alt="Figure 4.1: System Architecture for Software Development  4.4 Backend Development " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_007.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">Figure 4.1: System Architecture for Software Development  4.4 Backend Development </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055253/table-5-the-api-test-was-conducted-using-the-postman"><img alt="The API test was conducted using the Postman software found in appendix B1 which s used to evaluate routes and returned responses for each route using 200, 400,501 where: " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/table_005.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">The API test was conducted using the Postman software found in appendix B1 which s used to evaluate routes and returned responses for each route using 200, 400,501 where: </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055048/figure-8-ai-powered-thespian-developing-an-innovative"><img alt="" class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_008.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs"></figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055273/table-6-collaborate-with-users-in-acting-and-directing"><img alt="collaborate with users in acting and directing, assist with preparation of auditions, research. " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/table_006.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">collaborate with users in acting and directing, assist with preparation of auditions, research. </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055068/figure-9-ai-powered-thespian-developing-an-innovative"><img alt="" class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_009.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs"></figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055075/figure-10-the-app-can-serve-as-great-tutor-and-coach-around"><img alt="The app can serve as a great tutor and coach around topics in theatre, film making, jrama, acting and other related talks to educators and professionals. " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_010.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">The app can serve as a great tutor and coach around topics in theatre, film making, jrama, acting and other related talks to educators and professionals. </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055100/figure-11-ai-powered-thespian-developing-an-innovative"><img alt="" class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_011.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs"></figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055287/table-7-this-sheet-should-be-attached-to-the-front-of-the"><img alt="This sheet should be attached to the front of the completed ToR and uploaded with it to Moodle. " class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/table_007.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs">This sheet should be attached to the front of the completed ToR and uploaded with it to Moodle. </figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055124/figure-12-ai-powered-thespian-developing-an-innovative"><img alt="" class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_012.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs"></figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055141/figure-13-ai-powered-thespian-developing-an-innovative"><img alt="" class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_013.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs"></figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055168/figure-14-ai-powered-thespian-developing-an-innovative"><img alt="" class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_014.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs"></figcaption></figure><figure class="figure-slide-container"><a href="https://www.academia.edu/figures/10055176/figure-15-ai-powered-thespian-developing-an-innovative"><img alt="" class="figure-slide-image" loading="eager" src="https://figures.academia-assets.com/109184332/figure_015.jpg" width="236" height="141" /></a><figcaption class="figure-slide-caption ds2-5-body-xs"></figcaption></figure></div><div class="next-slide-container js-next-button-container"><button aria-label="Next" class="carousel-navigation-button js-loswp-figures-next"><span class="material-symbols-outlined" style="font-size: 24px" translate="no">arrow_forward_ios</span></button></div></div></div></div><div class="safe-below-fold--related-works"><h2 class="safe-related-content--heading">Related papers</h2><div class="safe-related-content--container" data-nosnippet=""><div class="ds-related-work--container js-wsj-grid-card js-safe-related-work-wsj " data-collection-position="0" data-entity-id="105619759" data-sort-order="default"><a class="ds-related-work--title js-wsj-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/105619759/The_rise_of_generative_AI_and_enculturating_AI_writing_in_postsecondary_education">The rise of generative AI and enculturating AI writing in postsecondary education</a><div class="ds-related-work--metadata"><a class="js-wsj-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="41964162" href="https://uoit.academia.edu/IsabelPedersen">Isabel Pedersen</a></div><p class="ds-related-work--metadata ds2-5-body-xs">Frontiers in Artificial Intelligence, 2023</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--38951282"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":105619759,"extra":{"source_work_id":105619759}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--38951282'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/105619759/The_rise_of_generative_AI_and_enculturating_AI_writing_in_postsecondary_education","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":105619759,"extra":{"source_work_id":105619759}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":120214067}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-wsj-grid-card-view-pdf" href="https://www.academia.edu/105619759/The_rise_of_generative_AI_and_enculturating_AI_writing_in_postsecondary_education"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-wsj-grid-card js-safe-related-work-wsj " data-collection-position="1" data-entity-id="111215333" data-sort-order="default"><a class="ds-related-work--title js-wsj-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/111215333/Artificial_Intelligence_and_amp_amp_Creativity_A_manifesto_for_collaboration">Artificial Intelligence &amp;amp;amp; Creativity: A manifesto for collaboration</a><div class="ds-related-work--metadata"><a class="js-wsj-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="32274156" href="https://univ-paris5.academia.edu/MarionBotella">Marion Botella</a></div><p class="ds-related-work--metadata ds2-5-body-xs">2023</p><p class="ds2-5-body-sm ds-related-work--abstract ">Creativity is a phenomenon that emerges in the human-sociocultural and machine-artificial layers. With the advent of Artificial Intelligence (AI), the field of creativity faces new opportunities and challenges. This manifesto explores several scenarios of human-machine collaboration on creative tasks and proposes &quot;fundamental laws of generative AI&quot; to reinforce the responsible and ethical use of AI in the creativity field. Four scenarios are proposed and discussed: &quot;Co-Cre-AI-tion&quot;, &quot;Organic&quot;, &quot;Plagiarism 3.0&quot;, and &quot;Shut down&quot;, each illustrating different possible futures based on the collaboration between humans and machines. In addition, we have incorporated an AI-generated manifesto that also highlights important themes, ranging from accessibility and ethics to cultural sensitivity. The fundamental laws proposed aim to prevent AIs from generating harmful content and competing directly with humans. Creating labels and laws are also highlighted to ensure responsible use of AIs. The positive future of creativity and AI lies in a harmonious collaboration that can benefit everyone, potentially leading to a new level of creative productivity respecting ethical considerations and human values during the creative process. Manifesto This manifesto, written by a team of creativity researchers, aims to promote a collaborative vision of creativity involving Artificial Intelligences (AI) and humans. In this context, although most of this article has been written by researchers, some contributions were provided by generative AI, and these are directly acknowledged following the latest recommendations from various publishers, ethics committees and journals (</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--7ae04e64"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":111215333,"extra":{"source_work_id":111215333}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--7ae04e64'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/111215333/Artificial_Intelligence_and_amp_amp_Creativity_A_manifesto_for_collaboration","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":111215333,"extra":{"source_work_id":111215333}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":108811515}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-wsj-grid-card-view-pdf" href="https://www.academia.edu/111215333/Artificial_Intelligence_and_amp_amp_Creativity_A_manifesto_for_collaboration"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-wsj-grid-card js-safe-related-work-wsj " data-collection-position="2" data-entity-id="103478587" data-sort-order="default"><a class="ds-related-work--title js-wsj-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/103478587/DIGITAL_STORYTELLING_FOR_PEOPLE_WITH_INTELLECTUAL_DISABILITIES_AN_INTERMEDIATE_LANGUAGE_FOR_EXECUTABLE_REPRESENTATIONS">DIGITAL STORYTELLING FOR PEOPLE WITH INTELLECTUAL DISABILITIES: AN INTERMEDIATE LANGUAGE FOR EXECUTABLE REPRESENTATIONS</a><div class="ds-related-work--metadata"><a class="js-wsj-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="36756807" href="https://independent.academia.edu/RobertoTedesco7">Roberto Tedesco</a><span>, </span><a class="js-wsj-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="276362457" href="https://independent.academia.edu/SaraFiori4">Sara Fiori</a></div><p class="ds-related-work--metadata ds2-5-body-xs">Proceedings of the 16th International Technology, Education and Development Conference, 2022</p><p class="ds2-5-body-sm ds-related-work--abstract ">Many approaches to the definition of animated story exist, but a good &quot;one size fits all&quot; solution is difficult to adopt and implement. Software for the creation of simple animated stories is often more complex than necessary. Moreover, usually, it is not possible to personalize the functionalities provided by the User Interface to the specific users&#39; needs. This, in turn, affects the effectiveness of such software. To address these problems, we defined, implemented, and tested a methodology to simplify the process of designing software for animated stories. We defined an Intermediate Language (IL) that abstracts basic concepts useful for the description of a story. The components and concepts of the IL were inspired by the Business Process Model and Notation (BPMN) and the Scratch language. To validate our approach, we applied it to the design and implementation of an app for storytelling. The app we created permits to define the story by means of a simple graphical language; then, a first translation module generates an IL representation; finally, a second translation module produces a Scratch executable file. We tested our app with subjects with intellectual disability. Psychologists supervised the experiments and observed improvements in subjects&#39; vocal expression, attention level and narration quality.</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--c72413fe"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":103478587,"extra":{"source_work_id":103478587}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--c72413fe'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/103478587/DIGITAL_STORYTELLING_FOR_PEOPLE_WITH_INTELLECTUAL_DISABILITIES_AN_INTERMEDIATE_LANGUAGE_FOR_EXECUTABLE_REPRESENTATIONS","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":103478587,"extra":{"source_work_id":103478587}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":103475601}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-wsj-grid-card-view-pdf" href="https://www.academia.edu/103478587/DIGITAL_STORYTELLING_FOR_PEOPLE_WITH_INTELLECTUAL_DISABILITIES_AN_INTERMEDIATE_LANGUAGE_FOR_EXECUTABLE_REPRESENTATIONS"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-wsj-grid-card js-safe-related-work-wsj " data-collection-position="3" data-entity-id="120706550" data-sort-order="default"><a class="ds-related-work--title js-wsj-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/120706550/The_Art_of_Co_Creation_Writing_and_Designing_with_ChatGPT">The Art of Co-Creation: Writing and Designing with ChatGPT</a><div class="ds-related-work--metadata"><a class="js-wsj-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="2214631" href="https://ocms.academia.edu/RobertOh">Robert Oh</a></div><p class="ds-related-work--metadata ds2-5-body-xs">The Art of Co-Creation: Writing and Designing with ChatGPT, 2024</p><p class="ds2-5-body-sm ds-related-work--abstract ">Dear Readers, Writing this book was a collaborative effort between myself and my AI assistant, ChatGPT, whom I affectionately call &#39;Charley&#39;. Throughout the process, Charley served as a supportive tool, helping to organize thoughts, generate drafts, and refine content based on my ideas and research. The journey began with conceptualizing themes and conducting thorough research. Charley assisted in compiling data, creating initial outlines, and generating drafts. My role involved providing direction, making revisions, and ensuring the final content reflected my vision. This partnership illustrates how AI can effectively support human creativity and scholarly work. I invite you to delve into this book with an open heart and mind. May the partnership that created these pages serve as a testament to the endless possibilities that await at the crossroads of technology and human creativity. Sincerely, Robert &amp; Charley</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--018cd226"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":120706550,"extra":{"source_work_id":120706550}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--018cd226'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/120706550/The_Art_of_Co_Creation_Writing_and_Designing_with_ChatGPT","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":120706550,"extra":{"source_work_id":120706550}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":115771277}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-wsj-grid-card-view-pdf" href="https://www.academia.edu/120706550/The_Art_of_Co_Creation_Writing_and_Designing_with_ChatGPT"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-wsj-grid-card js-safe-related-work-wsj " data-collection-position="4" data-entity-id="143177303" data-sort-order="default"><a class="ds-related-work--title js-wsj-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/143177303/The_Use_of_AI_In_Arts_Education_A_Didactic_Tool_for_Sensitising_Students_and_for_the_Detection_of_Technology_Assisted_Writing_in_the_Humanities">The Use of AI In Arts Education: A Didactic Tool for Sensitising Students and for the Detection of Technology Assisted Writing in the Humanities</a><div class="ds-related-work--metadata"><a class="js-wsj-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="319068384" href="https://independent.academia.edu/RunetteKruger">Runette Kruger</a></div><p class="ds-related-work--metadata ds2-5-body-xs">Journal of the Kenya National Commission for UNESCO, 2025</p><p class="ds2-5-body-sm ds-related-work--abstract ">The disruption caused by the launch of generative AI such as ChatGPT in 2022 has impacted strategies for effective knowledge transfer and assessment across the higher education sector. This essay presents a model or rubric that can be used by educators in the humanities to detect the probable use of AI and to sensitise students to the unoriginality and generic nature of the generated output. The rubric was compiled by coding the artist&#39;s statements of ninety-three art students and graduates from five countries and two continents, participating in the same exhibition. Coding of the data revealed the presence of five defining characteristics that point to the probable use of AI. These are the prevalence and repetition of identified terms as well as phrases; the excessive use of flattering adjectives; hyperbolic statements; and, lastly, tortured phrases. Findings include the widespread reliance on technology in samples from all institutions in the study, across five countries on different continents. Recommendations include a focus on the development of adequate writing skills at school as well as university level combined with centring the importance of ethical conduct in research (and more broadly) as a guiding principle that goes beyond compliance. The source of the data is in the public domain. However, no students or institutions are identified in the presentation, analysis or discussion of the data.</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--cdb5dde0"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":143177303,"extra":{"source_work_id":143177303}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--cdb5dde0'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/143177303/The_Use_of_AI_In_Arts_Education_A_Didactic_Tool_for_Sensitising_Students_and_for_the_Detection_of_Technology_Assisted_Writing_in_the_Humanities","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":143177303,"extra":{"source_work_id":143177303}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":124010050}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-wsj-grid-card-view-pdf" href="https://www.academia.edu/143177303/The_Use_of_AI_In_Arts_Education_A_Didactic_Tool_for_Sensitising_Students_and_for_the_Detection_of_Technology_Assisted_Writing_in_the_Humanities"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-wsj-grid-card js-safe-related-work-wsj " data-collection-position="5" data-entity-id="104068814" data-sort-order="default"><a class="ds-related-work--title js-wsj-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/104068814/All_Rise_for_the_AI_Director">All Rise for the AI Director</a><div class="ds-related-work--metadata"><a class="js-wsj-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="275378923" href="https://independent.academia.edu/ChinmayKulkarni86">Chinmay Kulkarni</a></div><p class="ds-related-work--metadata ds2-5-body-xs">Proceedings of the 2020 ACM Designing Interactive Systems Conference, 2020</p><p class="ds2-5-body-sm ds-related-work--abstract ">How might the capabilities of voice assistants several decades in the future shape human society? To anticipate the space of possible futures for voice assistants, we asked 149 participants to each complete a story based on a brief story stem set in the year 2050 in one of five different contexts: the home, doctor&#39;s office, school, workplace, and public transit. Story completion as a method elicits participants&#39; visions of possible futures, unconstrained by their understanding of current technological capabilities, but still reflective of current sociocultural values. Through a thematic analysis, we find these stories reveal the extremes of the capabilities and concerns of today&#39;s voice assistants-and artificial intelligence-such as improving efficiency and offering instantaneous support, but also replacing human jobs, eroding human agency, and causing harm through malfunction. We conclude by discussing how these speculative visions might inform and inspire the design of voice assistants and other artificial intelligence.</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--75c12b8d"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":104068814,"extra":{"source_work_id":104068814}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--75c12b8d'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/104068814/All_Rise_for_the_AI_Director","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":104068814,"extra":{"source_work_id":104068814}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":103894861}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-wsj-grid-card-view-pdf" href="https://www.academia.edu/104068814/All_Rise_for_the_AI_Director"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-wsj-grid-card js-safe-related-work-wsj " data-collection-position="6" data-entity-id="34947165" data-sort-order="default"><a class="ds-related-work--title js-wsj-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/34947165/INITIAL_PROPOSAL_D1_FOR_THE_FINAL_PROJECT">INITIAL PROPOSAL (D1) FOR THE FINAL PROJECT</a><div class="ds-related-work--metadata"><a class="js-wsj-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="70407445" href="https://independent.academia.edu/KatiaMarleniLeon">Katia Marleni Leon</a></div><p class="ds2-5-body-sm ds-related-work--abstract ">This research is about the use of movies in order to improve listening skills</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--a93d1c07"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":34947165,"extra":{"source_work_id":34947165}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--a93d1c07'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/34947165/INITIAL_PROPOSAL_D1_FOR_THE_FINAL_PROJECT","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":34947165,"extra":{"source_work_id":34947165}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":54809515}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-wsj-grid-card-view-pdf" href="https://www.academia.edu/34947165/INITIAL_PROPOSAL_D1_FOR_THE_FINAL_PROJECT"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-wsj-grid-card js-safe-related-work-wsj " data-collection-position="7" data-entity-id="75348972" data-sort-order="default"><a class="ds-related-work--title js-wsj-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/75348972/Declaration">Declaration</a><div class="ds-related-work--metadata"><a class="js-wsj-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="215559744" href="https://independent.academia.edu/BezuidenhoutCarel">Carel Bezuidenhout</a></div><p class="ds-related-work--metadata ds2-5-body-xs">2011</p><p class="ds2-5-body-sm ds-related-work--abstract ">As the candidates Supervisor I agree/do not agree to the submission of this thesis.</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--46e0715a"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":75348972,"extra":{"source_work_id":75348972}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--46e0715a'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/75348972/Declaration","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":75348972,"extra":{"source_work_id":75348972}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":83152446}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-wsj-grid-card-view-pdf" href="https://www.academia.edu/75348972/Declaration"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-wsj-grid-card js-safe-related-work-wsj " data-collection-position="8" data-entity-id="130187999" data-sort-order="default"><a class="ds-related-work--title js-wsj-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/130187999/Communicator_LX_1_Jan_March_2025_Gauri_Joshi_Anshula_Garg_1_">Communicator LX 1 Jan March 2025 Gauri Joshi Anshula Garg (1)</a><div class="ds-related-work--metadata"><a class="js-wsj-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="332449533" href="https://sgtuniversity.academia.edu/GauriJoshi">Gauri Joshi</a></div><p class="ds-related-work--metadata ds2-5-body-xs">2025</p><p class="ds2-5-body-sm ds-related-work--abstract ">The rapid progress in AI technology offers an opportunity to bridge the communication gap for people with disabilities. This research paper explores how AI can promote inclusivity, improve communication and ensure access to information. It examines AI tools like speech recognition, natural language processing and predictive text features that enhance the interaction experience for individuals with auditory, cognitive and physical disabilities. The study also looks at real world examples such as AI powered technologies and captioning tools that have transformed how people with disabilities engage with media. This paper also discusses challenges in applying AI, including data privacy concerns, technological disparities and the need for an user centered approach. It concludes by suggesting solutions and future recommendations such as integration of AI, innovation in assistive technology, robust policy frameworks and collaborative strategies.</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--fd9ac275"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":130187999,"extra":{"source_work_id":130187999}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--fd9ac275'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/130187999/Communicator_LX_1_Jan_March_2025_Gauri_Joshi_Anshula_Garg_1_","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":130187999,"extra":{"source_work_id":130187999}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":123478726}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-wsj-grid-card-view-pdf" href="https://www.academia.edu/130187999/Communicator_LX_1_Jan_March_2025_Gauri_Joshi_Anshula_Garg_1_"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-wsj-grid-card js-safe-related-work-wsj " data-collection-position="9" data-entity-id="107694793" data-sort-order="default"><a class="ds-related-work--title js-wsj-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/107694793/CIAESA_How_to_address_artificial_intelligence_in_the_classroom_English">CIAESA How to address artificial intelligence in the classroom English</a><div class="ds-related-work--metadata"><a class="js-wsj-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="2041747" href="https://uba.academia.edu/MarianaFerrarelli">Mariana Ferrarelli</a></div><p class="ds-related-work--metadata ds2-5-body-xs">UdeSA - Las Preguntas Educativas , 2023</p><p class="ds2-5-body-sm ds-related-work--abstract ">AI-based generative technologies,such as ChatGPT, are revolutionising the way we live, work and consume content and products, and education is no exception. Because of their ability to generate coherent text in seconds, several educational institutions around the world have banned their use. In other areas, on the other hand, their incorporation is encouraged as a way of opening up the creative horizons of both teachers and students (Atlas, 2023; Sabzalieva and Valentini, 2023). Is it possible to know if a student really learned from writing a reflective piece when it is so difficult to know if he or she wrote it autonomously and with no other support than his or her knowledge of the subject? How important is it to know these AI tools for textual generation beyond whether or not we will use them in the classroom and in our daily lives? How can we approach their responsible and critical use in the classroom? In the following pages we will try to think of possible ways in which these technologies can be incorporated into teaching proposals at secondary and higher education levels.</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--0122a11d"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":107694793,"extra":{"source_work_id":107694793}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--0122a11d'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/107694793/CIAESA_How_to_address_artificial_intelligence_in_the_classroom_English","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":107694793,"extra":{"source_work_id":107694793}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":106289489}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-wsj-grid-card-view-pdf" href="https://www.academia.edu/107694793/CIAESA_How_to_address_artificial_intelligence_in_the_classroom_English"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div></div></div><div class="safe-sticky-ctas--container js-loswp-sticky-ctas hidden"><button class="ds2-5-button js-tc-loswp--continue-reading-button--sticky-ctas js-login-button--3024e762">See full PDF</button><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--continue-reading-button--sticky-ctas","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}};
  const button = document.querySelector('.js-tc-loswp--continue-reading-button--sticky-ctas');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--3024e762'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE","clickTrackingContext":{"source":"loswp--continue-reading-button--sticky-ctas","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":109184332}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><button class="ds2-5-button ds2-5-button--secondary js-tc-loswp--download-pdf-button--sticky-ctas js-login-button--f4ce821e"><span class="material-symbols-outlined" style="font-size: 20px" translate="no">download</span>Download PDF</button><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--download-pdf-button--sticky-ctas","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}};
  const button = document.querySelector('.js-tc-loswp--download-pdf-button--sticky-ctas');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--f4ce821e'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE?auto=download","clickTrackingContext":{"source":"loswp--download-pdf-button--sticky-ctas","bucket":"outline","entity_id":111735900,"extra":{"source_work_id":111735900}},"configuredText":{"buttonsPage":{"header":"Download your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue with your free download."},"emailLoginPage":{"subheader":"Log in to continue with your free download."},"emailRegistrationPage":{"subheader":"Sign up to continue with your free download.","submit":"Start Download"}},"registrationParams":{"user_source":"download","doc_id":109184332,"auto":"download"}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script></div><div class="ds-work--container js-loswp-embedded-document" id="loswp-embedded-document"><div class="attachment_preview" data-attachment="Attachment_109184332" style="display: none"><div><div class="markdown-body" style="--page-number: 1; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="1" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>AI-POWERED THESPIAN: DEVELOPING AN INNOVATIVE CONVERSATIONAL ENGINE</h1>
<h3>A DISSERTATION SUBMITTED TO MANCHESTER METROPOLITAN UNIVERSITY</h2>
<p>FOR THE DEGREE OF MASTER OF SCIENCE<br>
IN THE FACULTY OF SCIENCE AND ENGINEERING<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-0.jpeg" alt="img-0.jpeg" data-image-width-px="504" data-image-height-px="510" style="--image-width-px: 504; --image-height-px: 510;"></p>
<p>2023</p>
<p>By<br>Richard Ademola Ogundele<br>Department of Computing and Mathematics</p>
<p>Supervisors:</p>
<p>Prof YongHong Peng, Dr David Jackson</p>
</div>
<div class="markdown-body" style="--page-number: 2; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="2" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>Contents<br>
Title Page  1<br>
List of Figures  4<br>
List of Tables  5<br>
Abstract  6<br>
Declaration  7<br>
Acknowledgments  8<br>
Abbreviations  9<br>
Chapter One - Introduction  10<br>
1.1 Background of the Study  10<br>
1.1 Research Objectives  10<br>
1.2 Problem Statement  11<br>
1.3 Justification of the Study  11<br>
1.4 Scope of the Study  11<br>
1.5 Report Structure  12<br>
Chapter Two - Literature Review  13<br>
2.1 Overview  13<br>
2.2 Conversational AI Agents  13<br>
2.2.1 Natural Language Understanding  15<br>
2.1.2 Natural Language Generation  16<br>
2. 1. 3 Dialogue management  17<br>
2.3 Ethical Considerations Towards Conversational AI  18<br>
2.4 Role and Integration of conversational AI in Theatre  20<br>
Chapter Three - Theoretical Framework  22<br>
3.1 Natural Language Processing  22<br>
3.2 Foundation Models  23<br>
3.3 Large Language Models  25<br>
3.2.1 Machine Learning and Deep Learning Processes  27<br>
3.2.2 Fine Tuning and Instruction Tuning  28<br>
3.2.3 Prompt Engineering  28<br>
3.4 Speech Recognition  32<br>
Chapter Four - Design and Methodology  33<br>
4.1 Problem Definition and Target Audience  33<br>
4.1.1 Problem Definition  33<br>
4.1.2 Target Audience  33<br>
4.2 Programming Languages  34<br>
4.3 Software Development Process  34</p>
</div>
<div class="markdown-body" style="--page-number: 3; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="3" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>4.4 Backend Development  35<br>
4.4.1 Application Programming Interface  35<br>
4.4.2 OpenAI GPT  36<br>
4.4.3 Fast API  37<br>
4.4.4 OpenAI Whisper  38<br>
4.4.5 API Testing  39<br>
4.5 Frontend Development  40<br>
4.6 Integrated Development Environment  40<br>
4.7 Mobile Application  40<br>
4.8 Hosting Platform  41<br>
4.9 Integration of Real-Time Conversations and Anecdote Sharing  41<br>
Chapter Five - Implementation and Results  42<br>
5.1 Software Testing  42<br>
5.2 Performance evaluation and User Feedback  42<br>
5.3 Analysis of Results  43<br>
5.3.1 Use Case (1) - Storytelling  44<br>
5.4.2 Use Case (2) - Script Writer  45<br>
5.4.3 Use Case (3) - Content Creation  46<br>
5.4.4 Use Case (4) - Tutor  46<br>
Chapter Six - Conclusion and Recommendation  47<br>
6.1 Conclusion  47<br>
6.2 Recommendation  48<br>
6.3 Limitation and Challenges  49<br>
References  51<br>
Appendices  54<br>
Appendix A - Terms of Reference  54<br>
Appendix B - All Experimentation Code  65<br>
Appendix B1 - Postman API Testing  65<br>
Appendix B2 - MongoDB Database  67<br>
Appendix B3 - Deployed Backend Codes  68<br>
Appendix B4 - Render Hosting Platform  68<br>
Appendix C -App Survey  69<br>
Appendix D - GitHub Codes  72</p>
</div>
<div class="markdown-body" style="--page-number: 4; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="4" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>List of Figures<br>
Figure 1.1 - Conversational Engine Architecture<br>
Figure 3.1 - foundation models showing all the data from various modalities.<br>
Figure 3.2 - A timeline of recently developed big language models.<br>
Figure 3.3 - Zero shot, one shot, and few-shot learning on LLMs.<br>
Figure 3.4 - Branches of Machine Learning<br>
Figure 3.5 - Think step by step using GPT 3.5 Turbo<br>
Figure 3.6 - Role Prompting using GPT 3.5 Turbo<br>
Figure 3.7 - Few shots learning through sentiment analysis using GPT 3.5 Turbo<br>
Figure 3.8 - High-level architecture for voice-based conversational AI agents<br>
Figure 4.1 - System Architecture of the Software Development<br>
Figure 4.2 - User Interface of the Mobile App Design<br>
Figure 4.2 Uvicorn on Terminal<br>
Figure 4.3 Uvicorn Interface<br>
Figure 4.4 User Interface of the Mobile App Design<br>
Figure 5.1: storytelling prompt from user<br>
Figure 5.2: Script generation from the application<br>
Figure 5.3: content generation<br>
Figure 5.4: Asking questions.<br>
Figure 6.1: Future of the Web/Mobile Application</p>
</div>
<div class="markdown-body" style="--page-number: 5; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="5" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>List of Tables<br>
Table 4.1 Requests and Backend Routes<br>
Table 5.1: Performance of User Feedback</p>
</div>
<div class="markdown-body" style="--page-number: 6; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="6" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h5>Abstract</h4>
<p>This dissertation project delves into the burgeoning realm of conversational AI, with a specific focus on its application in creative AI and storytelling. It centres around the development of a conversational theatrical engine and explores the latest advancements in conversational AI architecture. While acknowledging the resource-intensive nature of building conversational engines, including meticulous preparation, user testing, and technical expertise, this study underscores the potential of conversational agents as efficient learning tools that offer both accessibility and privacy assurances. The project showcases the development of a mobile application utilizing the waterfall methodology and harnessing the capabilities of the latest GPT model, GPT-4, boasting an impressive 1.76 trillion parameters. This development leverages Python programming and the FastAPI framework for the backend, while the frontend is crafted using the React Native framework. Rigorous testing, conducted through Postman and feedback collection from diverse users, has revealed insightful statistics. Notably, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>69.7</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">69.7 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">69.7%</span></span></span></span> of users had never previously encountered a similar storytelling app, indicating a unique offering. Moreover, a substantial <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>67.8</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">67.8 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">67.8%</span></span></span></span> of users expressed comfort in interacting with an AI tool, with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16.1</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">16.1 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">16.1%</span></span></span></span> holding a neutral stance. The application itself is designed for creative AI, functioning as a thespian, and facilitating interactive storytelling experiences. User feedback revealed diverse usage patterns, with <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>39.4</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">39.4 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">39.4%</span></span></span></span> utilizing it for learning and seeking answers, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>36.4</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">36.4 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">36.4%</span></span></span></span> for storytelling purposes, and <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>24.2</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">24.2 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">24.2%</span></span></span></span> employing the app to generate scripts for acting. This project not only highlights the potential of conversational AI in creative contexts but also provides valuable insights into user perceptions and adoption, paving the way for future advancements in the field.</p>
</div>
<div class="markdown-body" style="--page-number: 7; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="7" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>Declaration</h1>
<p>No part of this project has been submitted in support of an application for any other degree or qualification at this or any other institute of learning. Apart from those parts of the project containing citations to the work of others, this project is my own unaided work. It has been undertaken in accordance with the University research ethics standards, by the terms of permit number 57156 .</p>
<p>Signed</p>
</div>
<div class="markdown-body" style="--page-number: 8; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="8" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>Acknowledgments</h1>
<p>I want to thank God for trusting me to represent him in artificial intelligence. I also appreciate my parents, Mr. and Mrs. Alexander Ogundele, for their full sponsorship of my masters programme academic pursuit.</p>
<p>My special appreciation goes to Professor YongHong Peng and Dr. David Jackson for holding my hands and giving me clarity at every junction of confusion in this project. Thank you for your constant support and guidance towards the success of the project.</p>
<p>I want to express my appreciation to Manchester Metropolitan University for providing me with the personal laptop computer I needed to begin my project with the crisis support team. I also want to thank my classmates for their assistance in providing me with the answers to my project-related queries.</p>
</div>
<div class="markdown-body" style="--page-number: 9; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="9" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>Abbreviations<br>
AI. Artificial Intelligence<br>
NL. Natural Language Processing<br>
NLU. Natural Language Understanding<br>
LLM. Large Language Models<br>
CA. Conversational Agents<br>
LSTM. Long Short-Term Memory<br>
BERT. Bidirectional Encoder Representations from Transformers<br>
GPT. Generative Pre-Trained Transformers<br>
BART. Bidirectional and Auto-Regressive Transformer</p>
</div>
<div class="markdown-body" style="--page-number: 10; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="10" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>Chapter One - Introduction</h1>
<h4>1.1 Background of the Study</h3>
<p>Conversational AI agents have become widely used in various domains such as business, healthcare, e-commerce, customer service, fintech, tourism, and education. This widespread adoption can be attributed to significant advancements in machine learning, natural language processing, and Generative AI techniques, which enable the development of highly accurate models. Given the heavy reliance on conversations with natural languages in daily operations within these domains, conversational AI agents are seen as a natural fit. The increasing demand for conversational AI has sparked a rapid pace of research and development, resulting in daily innovations. However, this surge of interest in the field has also highlighted exciting yet volatile research opportunities. (Kulkarni, P. et al, 2020)</p>
<p>Conversational agents are agents that can hold human-like conversations with humans with the use of natural language processing and machine learning to analyse users input and generate responses based on the context of the conversation. The user experience will be enhanced, and dialogues will be more engaging when the agent can give anecdotes, stories, and experiences related to its persona. This software engine has the potential to be used as a collaborative storytelling tool, author story scripts, and analyse monologues, and enable it users to actively participate to the storys development. Players and viewers can engage in dialogue with the conversational agent powered by AI to help shape and advance the plot. The interactive story can be advanced by users having back-and-forth discussions, asking questions, offering prompts, or making decisions.</p>
<h4>1.2 Research Objectives</h3>
<p>The Project Aim is to be able to provide a platform to demonstrate a system for creative AI and storytelling and hold real-time conversations with users leveraging on the latest GPT-style API which is to also be used in a variety of settings and applications, including those related to health, art, and entertainment.</p>
<p>The Product is a Mobile based application that leverages the latest GPT API. It will be able to interact with users through text and speech to create interactive stories and dialogues.</p>
</div>
<div class="markdown-body" style="--page-number: 11; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="11" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>To achieve the aims identified Objectives need to be met:</p>
<ul>
<li>Develop a software system that effectively manages the entire process of conversation process and can perform speech to speech operation.</li>
<li>Effective natural language prompts for GPT that portrays character and narrative while also testing for effectiveness in terms of coherence and latency.</li>
<li>Ability to have the potential to store conversational exchanges for future fine-tuning purposes.</li>
<li>To evaluate the products by stakeholders and compile their response.</li>
</ul>
<h2>1.3 Problem Statement</h1>
<p>Ensuring that the conversational engine generate responses that are natural and consistent might be a significant challenge and it can be difficult to manage nuances, humour, ambiguity and keeping a consistent character depiction.</p>
<p>Generative AI and conversational engine systems can unintentionally pick up prejudices from training data, which could result in responses that are biased or unsuitable. A key component of this AI development creating plans to reduce biases and keep the systems replies fair which might be a challenge.</p>
<h4>1.4 Justification of the Study</h3>
<p>The work is important because it develops conversational AI, improves user experiences, and has widespread industry implications. It advances the understanding of natural language, entertainment innovation, theatre arts, human-AI cooperation, and AI community research. It also raises questions about the ethical and societal implications of conversational AI.</p>
<h4>1.5 Scope of the Study</h3>
<p>The scope includes many different goals and concentration zones. Its main objective is to develop a sophisticated conversational AI system that is powered by the most recent large language model which is the GPT-4. The project looks at novel theatrical and entertainment applications, with the goal of producing AI actors or characters for original theatrical and entertainment experiences. The system is put to the test with actual users, and its performance is evaluated by looking at important criteria like accuracy, reaction time, and user happiness. The project also intends to share knowledge and ideas regarding the creation of the conversational engine with the academic and scientific community. Additionally, it considers</p>
</div>
<div class="markdown-body" style="--page-number: 12; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="12" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>the potential ramifications for society and the broader societal impact of conversational engines driven by AI.</p>
<h2>1.6 Report Structure</h1>
<p>The reports content would be divided into several distinct chapters. Every chapter will focus on the project is in various stages, which are detailed below:</p>
<ul>
<li>Chapter 1 will discuss the projects fundamental structure, potential issues that might arise, and the projects main goals and objectives.</li>
<li>Chapter 2 will discuss the many methods and suggestions that can be used to achieve this projects goals. There will also be a review of earlier, relevant research that was done by others.</li>
<li>Chapter 3 will cover the methodology and the framework applied all through the projects development phase.</li>
<li>Chapter 4 will cover the Development and design of the AI Powered Thespian and the timeline is showed in the terms of reference in appendix A</li>
<li>Chapter 5 will provide the discussion of Implementation and Result.</li>
<li>Chapter 6 will provide a conclusion to the overall report</li>
</ul>
</div>
<div class="markdown-body" style="--page-number: 13; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="13" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>Chapter Two - Literature Review</h1>
<h4>2.1 Overview</h3>
<p>In the twenty-first century, artificial intelligence (AI) has expanded significantly and is becoming increasingly institutionalised. The definition of Artificial intelligence has come under close check in this period of interdisciplinary science, which includes automation, computer science, cybersecurity, mathematical logic, and linguistics. Researchers in the fields of computer science, mathematics, and engineering, began investigating the possibilities of artificial brains and attempting to characterise the intelligence of the machine as early as the 1940s and 1950s. Turing introduced the renowned Turing Test in 1950, which established the definition of Machine Intelligence. Considering this, the workshop held on the campus of Dartmouth College in 1965 is where the roots of artificial intelligence can be found. McCarthy won participants over to his belief in the idea of artificial intelligence in this discussion. Additionally, it marks the start of the first Golden age of AI. With the ultimate objective of realising a world where humans and machines dwell peacefully, artificial intelligence (AI) strives to extend and enhance the capability and efficiency of mankind in activities including changing nature and regulating society through intelligent machines. (Xue et al., 2022) Since the 1980s, AI has been used in a few important fields, including natural language processing, computer vision, robotics, game theory, the science of cognition, machine learning and reason. This is due to the historical growth of AI. These topics evolved separately from one another. However, these fields had given up on the heuristic search-based techniques and logical reasoning that had been presented thirty years before. Rather, most of them were based on statistical methods. (J. Liu et al, 2018)</p>
<h4>2.2 Conversational AI Agents</h3>
<p>The study of artificial intelligence involves teaching computers to mimic intelligent human conduct by using them to imitate human learning, judgement, and decision-making processes. The goal of artificial intelligence (AI) is to emulate human intellectual activity by using knowledge as its purpose, knowledge acquisition, examination, and research of knowledges ways of expression. In applications including speech recognition, image processing, natural language processing, the automatic demonstration of theorems, and intelligent robotics, AI has achieved outstanding accomplishments. AI combines several</p>
</div>
<div class="markdown-body" style="--page-number: 14; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="14" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>different academic fields, including biology, psychology, philosophy, computer science, and logic, (Zhang and Lu, 2021).</p>
<p>The study of conversational AI has been ongoing for many years. Organisations from both academia and industry have a strong interest in these kinds of systems. The conversational AI system has significant commercial value and raises several intriguing issues, including those related to knowledge base reasoning, speech recognition, natural language processing, and designing human-computer interactions, among other things. Many large-scale conversational AI systems, including Siri, Xia ice, Alexa, and Google Assistant, have been developed.( (Xue et al., 2022) Software agents known as conversational agents (CAs) enable human-computer interaction through natural language conversation. they are supported by an advanced engine that incorporates dialogue management techniques and natural language processing (OShea, Bandar, &amp; Crockett, 2011).</p>
<p>Guidelines for ethical AI vary among organizations, illustrating the complexity of formulating guidelines for AI systems with societal impact. Disadvantaged users may experience disproportionate harm due to bias in various conversational AI applications. Critical analysis of social impact in publicly deployed conversational AI systems is hindered by the absence of cross-collaboration and the publication of proprietary training datasets and system architectures. In designing conversational AI,</p>
<p>Ruane et al. suggested that it crucial to consider linguistic elements, social and contextual factors, and the potential encoding of societal values and assumptions. Language and conversation nuances, often overlooked, should be regarded with equal importance as technical challenges in conversational AI development. Design choices in conversational AI development reflect specific worldviews and can influence the perception and handling of socially sensitive issues. While conversational AI in mental health services may seem appealing, it can carry potential harm due to limited capacity and inadequate ongoing evaluation of risks and benefits. Although ethical considerations are often mentioned in the evaluation of conversational AI, they are not consistently addressed explicitly. Addressing ethical concerns in conversational AI can be approached through safety engineering or machine ethics, but it necessitates a shift in mindset to consider the social context. Therefore, designers and developers must cultivate awareness of ethical issues and their impact on end users. This summary focuses on specific concerns for discussion and the clarification of implicit assumptions in conversational AI but does not cover all related concerns. (Ruane et al, 2019)</p>
</div>
<div class="markdown-body" style="--page-number: 15; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="15" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>The Conversational AI architecture is composed of three (3) main components, each of which is further divided into more basic sections that conduct more basic functions. The first section deals with understanding user inputs made in natural language. The two NLU activities that comprise this activity are Entity Extraction and Intent classification. Intent classification aids the agent in comprehending the motivation behind the input. (Qiu et al, 2018). Request, inform, and place orders are a few examples of chatbot intentions in the food ordering space. In the healthcare space, similar examples include reporting a diagnosis, reporting a symptom, and requesting a prescription for medication. (J. Chen et al, 2018). The What of the input is dealt with through entity extraction. (X. Dong et al., 2016).<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-1.jpeg" alt="img-1.jpeg" data-image-width-px="1264" data-image-height-px="800" style="--image-width-px: 1264; --image-height-px: 800;"></p>
<p>Figure 1.1: Conversational Engine Architecture</p>
<h2>2.2.1 Natural Language Understanding</h1>
<p>NLU enables the agent to identify the distinct informational units supplied by the user, which when combined with the users purpose allows the agent to understand and comprehend the users input. Thanks to newer, more effective methods of encoding natural language in a computer-understandable format while simultaneously defining relations between various entities, such as Word Embeddings, NLU has increased in accuracy over</p>
</div>
<div class="markdown-body" style="--page-number: 16; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="16" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>some of its previous equivalents. Word embeddings is a word representation used in text analysis to take the form of a real-number vector, which captures the words meaning in a manner that positions words with similar meanings closer together within the vector space. (J. Devlin et al., 2018). To correctly continue the discussion and avoid being stuck without the information it needs or in an incomplete circumstance, the Conversational Agent must decide on its own course of action after understanding the users input. (Kulkarni, P et al, (2019).</p>
<h2>2.1.2 Natural Language Generation</h1>
<p>NLG concentrates on techniques for generating natural voice and language responses. In the context of conversational AI, natural language creation is essential for making the interaction seem more approachable and natural for the human user, which is a major element when evaluating the efficacy of conversational agents. According to Albert &amp; Emiels discussion (Albert. G. &amp; Emiel. K., 2018), the Management system delivers data to the NLG module in a structured fashion depending on the history of the conversation and the present context. Therefore, the NLG component output is an NLP text or sentence, which also acts as the final output of the Conversational AI framework for each dialogue occurrence. The Natural Language Understanding and Dialogue Management Systems processing and results form the basis for the NLG components output. The promising techniques and the state-of-the-art techniques for NLG are as follows:</p>
<h3>I. Sequence-To-Sequence (Seq2Seq):</h2>
<p>Seq2Seq models have grown in prominence recently and are advertised as offering innovative performance in a range of tasks, including Conversational engines. The Seq2Seq models sequentially forecast tokens based on the previously acquired representation after translating a vector representation from an input sequence using LSTM models. The model uses a SoftMax function in equation (1.1) to successively predict tokens given inputs (X) and defines a distribution over outputs (Y). However, these Seq2Seq models have two common issues: between the train and test runs, there is measurement bias and inconsistency. (J. Li et al, 2015).</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi></mi><mo stretchy="false">(</mo><mi>z</mi><msub><mo stretchy="false">)</mo><mi>i</mi></msub><mo>=</mo><mfrac><msup><mi>e</mi><msub><mi>z</mi><mi>i</mi></msub></msup><mrow><munderover><mo></mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msup><mi>e</mi><msub><mi>z</mi><mi>j</mi></msub></msup></mrow></mfrac><mtext>for</mtext><mi>i</mi><mo>=</mo><mn>1</mn><mo separator="true">,</mo><mo></mo><mo separator="true">,</mo><mi>K</mi><mtext>and</mtext><mi>z</mi><mo>=</mo><mrow><mo fence="true">(</mo><msub><mi>z</mi><mn>1</mn></msub><mo separator="true">,</mo><mo></mo><mo separator="true">,</mo><msub><mi>z</mi><mi>k</mi></msub><mo fence="true">)</mo></mrow><mo></mo><msup><mi mathvariant="double-struck">R</mi><mi>K</mi></msup></mrow><annotation encoding="application/x-tex">\sigma(z)_{i}=\frac{e^{z_{i}}}{\sum_{j=1}^{K} e^{z_{j}}} \text { for } i=1, \ldots, K \text { and } z=\left(z_{1}, \ldots, z_{k}\right) \in \mathbb{R}^{K}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:2.6484em;vertical-align:-1.307em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3414em;"><span style="top:-2.1288em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop"><span class="mop op-symbol small-op" style="position:relative;top:0em;"></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9812em;"><span style="top:-2.4003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.2029em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.4358em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6065em;"><span style="top:-3.0051em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.044em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.2819em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">e</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:-0.044em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:1.307em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord text"><span class="mord">for</span></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class="mord text"><span class="mord">and</span></span><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:-0.044em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0em;">)</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8913em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8913em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span></span></span></span></span></span></span></span></span></span></p>
</div>
<div class="markdown-body" style="--page-number: 17; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="17" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>The standard unit SoftMax function <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi></mi><mo>:</mo><msup><mi mathvariant="double-struck">R</mi><mi mathvariant="normal">K</mi></msup><mi mathvariant="normal"></mi><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><msup><mo stretchy="false">)</mo><mi mathvariant="normal">K</mi></msup></mrow><annotation encoding="application/x-tex">\sigma: \mathbb{R}^{\mathrm{K}} \square(0,1)^{\mathrm{K}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.03588em;"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.0913em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathbb">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">K</span></span></span></span></span></span></span></span></span><span class="mord amsrm"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">1</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathrm mtight">K</span></span></span></span></span></span></span></span></span></span></span></span> where <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">K</mi><mo></mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\mathrm{K} \geq 1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8193em;vertical-align:-0.136em;"></span><span class="mord mathrm">K</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"></span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">1</span></span></span></span> is defined by the formula in equation 1.1 (Wikipedia Contributors, 2019)<br>
II. Sequence-To-Sequence and Reinforcement Learning</p>
<p>Yaser Kenshoo et al created a framework model for text summarization that combines the strength of reinforcement learning techniques with sequence-to-sequence models in natural language creation. They noticed that the reinforcement learning model needed only a short amount of time for training and that their work had an extremely high ROUGE score. Actor-Critic, Self-Critic, Policy Generator, E2E, and Argmax were the suggested models employed in the experimentation. The ROUGE (1, 2, L) scores for the Actor-Critic (Q-Learning) approach were (40.88,17.80,38.54), which is significantly higher than the average score for the other methods of (35.09,38.43,16.64). In a Seq2Seq and Reinforcement Learning method, the Seq2Seq model generates a collection of potential results that serve as the RL agents action space, and the conversation history and context serve as the agents state space or environment. (Y, Keneshloo et al, 2018).</p>
<h2>2. 1. 3 Dialogue management</h1>
<p>There has been lot of scholarly interest in a key element of the Conversational AI architecture that governs how the CA behaves and connects user input to the appropriate outcomes. The DM system oversees creating an interaction strategy that will direct the agents decision-making process as it decides how to respond to user inputs. Research has received lot of attention over the past 20 years. Starting a conversation is the job of the dialogue management system. a plan that will help the agent make judgements on its own. based on previously submitted user contributions. There are two distinct kinds of DM systems: taskoriented systems and non-task-oriented systems. Task-oriented DM systems are responsible for moving the user from one state of the discussion to another to successfully fulfil a defined or dynamically understood task. Common examples of task-oriented conversational agents used today include those developed for straightforward tasks like booking a movie ticket, setting up meetings, managing projects, and answering FAQs. Task-oriented conversational bots can also perform more complicated tasks including medical diagnosis, visual question answering, and open domain question responding. Non-Task Oriented Systems are those created for casual,</p>
</div>
<div class="markdown-body" style="--page-number: 18; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="18" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>unstructured, and human-like user interaction. Examples include chatbots that offer friendship rather than conducting jobs or transactions. (Kulkarni, P et al, 2019).</p>
<h2>2.3 Ethical Considerations Towards Conversational AI</h1>
<ol>
<li>Privacy: The interaction between people and CAs, as well as the sporadic use of virtual agents like always-on appliances in homes, creates several ethical and legal concerns regarding the information that is acquired, who has access to it, how long it is kept, and where and how it is used. A variety of privacy issues are raised by the collecting of user data, some of which have a legal foundation and are handled by regionally specific data protection legislation, such the GDPR (General Data Protection Regulation) in Europe. The nature of these moral quandaries varies significantly depending on the domain in which the agent is deployed and the degree of receptivity of the user group. As AI systems are employed to produce decisions that are more significant, extensive, and are deployed in more areas of society, user privacy is essential and becoming much more essential. As a result, privacy should be viewed as a social issue that affects the entire society rather than just the individual user. Therefore, when selecting how to think about and regulate privacy, it is critical to understand how society may be impacted by the development of conversational AI systems. With the support of this viewpoint, privacy can be rethought in a way that connects it to aims and challenges that are more general to society. (Ruane, E. et al, 2019).</li>
<li>Transparency and Trust: Giving users control over how they choose to communicate with an agent is an essential first step in prioritizing their wants and wellbeing. It is critical to be transparent about an agents status as automatic (non-human) and the limits of its capabilities, for example, to empower users to make informed choices and increase user confidence. Users may be better able to take charge of their own actions, particularly about information disclosure, if they are aware of whether they are conversing to an automated or human agent. This is especially important when sensitive user information, such that related to minors education or banking, is being discussed or exposed, or when the conversations implications and/or repercussions could have serious effects, including user health problems. Understanding user expectations of an agent is essential to preventing abuse of user confidence. It can be challenging to assess a systems behaviour in a way that allows us to verify whether the agent recommends goods based on true interests or requirements rather than unfairly categorising consumers based on factors like gender, race, age, or region. However, given the</li>
</ol>
</div>
<div class="markdown-body" style="--page-number: 19; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="19" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>potential degree of harm, it is crucial to constantly monitor and guarantee that users are not being profiled based on these delicate characteristics. In contrast to purchases of apparel or home goods, CAs that interact with users in a higher-risk situation, such as mental health services, have a greater social duty to their users and how the service may affect them. The user should always have assurance that the system will not exploit them and will act honestly when performing the advertised service. In order to achieve this, the agent must be evaluated to see how it is handling different sorts of users, and This calls for three things: (1) A thorough explanation of the agents intentions and behaviours that the target user group can understand; (2) An evaluation to see how the agent is handling various user types; and (3) a grasp of the users worries, expectations, and experience. (Ruane, E. et al, 2019).<br>
3. Agent Persona: The highlighted passage underscores the significance of agent persona and personality in the decision-making process for Conversational AI (CA) design. These agent persona expressions encompass factors like gender, age, race, cultural background, and socioeconomic class, all of which can inform specific dialogue choices. The extent to which the agent embodies these characteristics can make them more or less evident in interactions. To determine whether the design of the agents persona and related dialogues encourage potentially harmful actions, it is imperative to consider how the agents persona may affect the kind of relationships users may wish to form with the agent. The design of agent personas can unintentionally perpetuate detrimental stereotypes, especially considering that many publicly available agents tend to present as female, which may align with market research but can reinforce socially ingrained gender biases. This gendering of CAs may result in female personas being used in submissive contexts while male personas are utilized in authoritative situations. In certain domains, there is a growing trend toward androgynous agent personas, as exemplified by the banking agent Kai. (Ruane, E. et al, 2019).<br>
4. Anthropomorphism and Sexualization: Machines are frequently anthropomorphized by humans. When users may have verbal conversations with a system, especially if it has been given personality and embodied through an avatar or another method, this type of anthropomorphism is accentuated. This has been observed throughout history, even when the creators themselves are against anthropomorphizing and exaggerating the capabilities of technology. For instance, ELIZAs founder Joseph Weizenbaum (196466) said unequivocally that ELIZA was unable to communicate with full understanding. Nevertheless, many users were persuaded by ELIZAs wit and compassion. Unwanted</p>
</div>
<div class="markdown-body" style="--page-number: 20; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="20" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>romantic interest in the agent may be a surprise facet of human-computer interaction. The well-known entertainment chatbot Mitsuku1, which has won the Loebner Prize four times, is a nice illustration of this. The developer and maintainer of Mitsuku, Steve Worswick, has talked about the kind of romantic attention she receives and even the letters he gets from users pleading for her release. (Ruane, E. et al, 2019)</p>
<h2>2.4 Role and Integration of conversational AI in Theatre</h1>
<p>Annabel Latham explained that conversational engines are supported by a cutting-edge conversational agent that employs natural language processing and dialogue management methods to preserve context throughout the conversation and to enable initiative interaction (i.e., Users can ask queries without following a predetermined sequence.) (Jackson, D., &amp; Latham, A. 2018).</p>
<p>Interactive fiction systems have been the focus of conversational agent (CA) development in the storytelling domain. At first, natural language processing models were used by early interactive fictions like Adventure to enable players to engage with the plot by responding to straightforward text commands like go north or take apple. To allow users to converse, agent-based storytelling experiences like Lyotard and Galetea implemented restricted fluency CAs using IF authoring frameworks. However, these systems relied on complex rules to simulate character responses, resulting in poor interactivity. Users often struggled to find specific word combinations that would prompt an output from the agent to progress the story. The primary application of CAs in storytelling has been within computer games, where players interact with non-playable characters (NPCs). Typically, these interactions are limited to multiple-choice dialogue options that affect gameplay decisions. The goals and challenges of these games extrinsically encourage the conversational style. As a result, if NPC interactions do not increase players chances of winning the game, they are unlikely to appreciate them. Commercial solutions that enable the development of Storytelling CAs (SCAs) as a component of digital media work have lately come into existence. Systems like Charisma.ai were created to make it possible for drama-based applications to break the fourth wall and communicate with users directly. These systems also incorporate extra AI features like emotion sensing to improve emotional connection to the storys characters. SCA usage has increased in areas involving cultural heritage as well for instance, the National Holocaust Centre in the UK offers people the chance to interact with digital recordings of Jewish Holocaust survivors. Using a microphone, users can ask the SCA questions, and the</p>
</div>
<div class="markdown-body" style="--page-number: 21; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="21" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>systems huge database of 800 to 1,200 questions and answers enables it to provide prompt and insightful answers. The Forever Project serves as an example of how SCA applications might help students and people or characters in historical and cultural contexts establish a natural and engaging relationship. (Kulkarni et al, 2020)</p>
</div>
<div class="markdown-body" style="--page-number: 22; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="22" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>Chapter Three - Theoretical Framework</h1>
<h4>3.1 Natural Language Processing</h3>
<p>The ability of computers to recognise and understand human text language is known as natural language processing. AIs goal is to process natural language, and the biggest difference between natural language and artificial language is that the former is founded on human thought. The study of making computers understand natural language is known as computational linguistics, which is situated at the intersection of language information processing and artificial intelligence. The secret to understanding natural language is this. It starts out as a machine gathering sound signals. The meaning of the text is translated from sound signals to text signals using natural language processing technologies. Then, a machine converts sounds into words and words into meanings. Once these two phases are complete, the machine can hear and comprehend. The algorithm in continuous learning is optimised by the machines speech recognition and semantic understanding technology so that it cannot only listen but also understand - and even grasp emotions. (Zhang &amp; Lu, 2021).</p>
<p>Users who do not have the time to learn new languages or to hone their current ones can benefit from natural language processing (NLP). The objective of NLP, a subfield of linguistics and AI, is to make it possible for computers to understand claims and words used in human languages. It was created to simplify the users task and to allow them to communicate with a computer in natural language. The two categories that advance the process of comprehending and generating the text are natural language generation and natural language understanding. Phonology, which studies sound, morphology, which studies word formation, syntax, which studies sentence structure, semantics, which studies syntax, and pragmatics, which studies understanding, are all included in the study of language Noah Chomsky, one of the first linguists of the twelfth century to establish syntactic theories, held a distinctive place in the realm of theoretical linguistics since he revolutionized the study of syntax (Chomsky, 1965). Natural language generation, or NLG, is the act of constructing meaningful words, phrases, and paragraphs from an internal representation. (Khurana, D. 2023)</p>
<p>The rationalist or symbolic approach assumes that a massive portion of knowledge in the human mind is fixed in advance, through genetic inheritance, rather than being acquired through the senses. The person who supported this strategy the most was Noam Chomsky. It was once thought that by providing some basic knowledge and reasoning capabilities, robots might be made to work similarly to the human brain. For example, it was thought that</p>
</div>
<div class="markdown-body" style="--page-number: 23; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="23" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>knowledge of languages is directly embodied in rules or other kinds of representation. This facilitates natural language processing on an automatic basis. Algorithm evolution is a key component of statistical and machine learning, which enables a programme to detect patterns. The fundamental algorithm of a given method, which is optimised by a numerical measure that characterises numerical parameters and learning phase, is characterised by an iterative process. The two main types of machine learning models are generative and discriminative methods. Generative methods focus on modelling probability distributions and can be used for generating artificial data. They are known for their ability to produce detailed models of data, including the underlying probability distribution. Discriminative methods, on the other hand, are more practical and are primarily concerned with distinguishing between different classes or categories based on observed features. Each type of model has its unique characteristics and use cases. Generative models can, for example, be utilized for identifying the language of an unknown speaker without extensive prior language knowledge, as they model the underlying data distribution. However, they may face challenges when dealing with many characteristics or features. Discriminative techniques, such as logistic regression and conditional random fields (CRFs), are better suited for tasks like language differentiation. They focus on identifying patterns that distinguish one class from another and are less knowledge-intensive than generative models. Examples of generative methods include Naive Bayes classifiers and hidden Markov models (HMMs), while logistic regression and conditional random fields (CRFs) are examples of discriminative methods.&quot; (Khurana et al., 2023)</p>
<h2>3.2 Foundation Models</h1>
<p>The most significant advancement in foundation models has occurred in NLP. We view foundation models as a universal paradigm of AI rather than being in any way specific to NLP, like how deep learning, which gained prominence in computer vision but applies to other fields, is viewed by many as a paradigm of AI. The NLP community was poised for another seismic upheaval by years end in 2018 that would usher in the era of foundation models. Technically speaking, foundation models as shown in figure 3.1 are made possible by scale and transfer learning. Transferring knowledge from one task-like object detection in photos-to another-like activity recognition in movies-is referred to as transfer learning. Pretraining, which involves training a model on a different task (often just till the finish) and then finetuning it to adapt to the desired downstream job, is the most widely used technique for transferring learning. Although scale is what gives foundation models their power, transfer learning makes them practical. The scale needed the next three components. The architecture</p>
</div>
<div class="markdown-body" style="--page-number: 24; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="24" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>of the Transformer model (Vaswani et al. 2017) was created to take use of the parallelism of the hardware and the availability of more training data to train models that are much more expressive than before. For instance, over the past four years, GPU throughput and memory have improved by a factor of one. the importance of having access to and using data. In contrast, the pretraining job in self-supervised learning is automatically created from unannotated data. For example, in the masked language modelling task that was used to train BERT (Devlin et al. 2019), participants were asked to guess the word that was missing from a sentence based on the context of the rest of the sentence (for instance, I like sprouts). Self-supervised tasks force the model to anticipate parts of the inputs, which makes it more complicated and potentially more useful than models trained on a narrower label space. As a result, they are not only more scalable because they simply need unlabelled data, but they also make the model more complex. Modern NLP models are now mostly descended from a few numbers of foundation models, including as BERT, BART, etc., which have led to a level of standardisation never seen. Although this homogenization has an incredibly high leverage (any modifications in the foundation models can immediately help all of NLP), a drawback is that all AI systems may acquire the same problematic biases from a small number of foundation models. Additionally, there is a trend towards uniformity throughout research communities. An unanticipated development that comes from size has also been facilitated by foundation models. For instance, GPT-3.5 (Brown et al. 2020) allows for in-context learning, where the language model can be adapted to a downstream task by giving it a prompt (a natural language description of the task), an emergent property that was neither specifically trained for nor anticipated to arise. GPT-3.5 has 175 billion parameters compared to GPT-2s 1.5 billion. (Bommasani et al, 2021)</p>
</div>
<div class="markdown-body" style="--page-number: 25; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="25" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p><img src="https://attachments.academia-assets.com/markdown/109184332/img-2.jpeg" alt="img-2.jpeg" data-image-width-px="1250" data-image-height-px="856" style="--image-width-px: 1250; --image-height-px: 856;"></p>
<p>Figure 3.1: foundation models showing all the data from various modalities.</p>
<h2>3.3 Large Language Models</h1>
<p>Vast language models (LLMs) often refer to Transformer language models, such as GPT-3, GPT-Neo, GPT-NeoX, GPT-J, PaLM, Galactica, and LLaMA, which are trained on vast amounts of text data and have hundreds of billions (or more) of parameters, which has given new meaning to the phrase unreasonable effectiveness of data&quot;. Figure 3.2 shows the recently developed large language models. (Zhao et al, 2023). The effectiveness of LLMs is unreasonable in three interrelated ways:</p>
<ul>
<li>First, there are qualitative leaps in capacity as the models scale, and</li>
<li>Second, the performance of LLMs on benchmarks scales with the size of the training set and model size.</li>
<li>Third, with a powerful model, many tasks that need intellect from people can be simplified to next token prediction.</li>
</ul>
<p>Large language models (LLMs) are generative mathematical models that analyse the statistical distribution of tokens in human-generated text, and they can be used to predict the words to follow a given sequence of text based on the statistical distribution of words in the public corpus. LLMs find application in conversational agents or AI assistants like ChatGPT,</p>
</div>
<div class="markdown-body" style="--page-number: 26; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="26" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>highlighting the importance of distinguishing between LLMs themselves and the systems they are embedded in for philosophical clarity. It is important to note that LLMs generate statistically likely sequences of words and do not possess knowledge, understanding, or consciousness. When evaluating the utility of LLMs, it is essential to consider the distinction between real-world facts and fictional information. Therefore, users and developers should be aware of what LLMs really do to avoid misleading descriptions of their capabilities. While LLMs can provide accurate responses based on statistical patterns in the public corpus, their answers may not always align with real-world truth. Hence, understanding the limitations and functions of LLMs is crucial when using or developing them. As LLMs become more capable of mimicking human language, it becomes increasingly tempting to anthropomorphise them (Shanahan, 2023)</p>
<p>We highlight the LLMs in yellow using publicly accessible model checkpoints. We only include the LLMs with review outcomes that have been made publicly available due to the space restrictions of the figure.<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-3.jpeg" alt="img-3.jpeg" data-image-width-px="1194" data-image-height-px="680" style="--image-width-px: 1194; --image-height-px: 680;"></p>
<p>Figure 3.2: a timeline of recently developed big language models (greater than 10B in size).<br>
In the context of large language models and machine learning there are learning approaches used to mitigate the challenges of training machine learning models when there is limited labelled data for a specific task. They include:</p>
</div>
<div class="markdown-body" style="--page-number: 27; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="27" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<ul>
<li>Few-shot learning describes a situation in which the model receives a limited number of task demonstrations at the time of inference, but no weight modifications are permitted. Few-shot learnings key benefits are a decreased demand for task-specific data and a decreased risk of learning an excessively narrow distribution from a large but limited fine-tuning dataset. (Brown et al, 2020)</li>
<li>One-shot learning only allows for one task demonstration and a natural language description as seen in figure 3.3, one-shot learning only allows for one task demonstration and a natural language description. (Brown et al, 2020)</li>
<li>Zero shot learning just requires a description of the job in natural language rather than any demonstrations. The most demanding situation is zero shot learning, which may be unfairly hard since it might be challenging for people to comprehend the structure of the job without prior instances. (Brown et al, 2020)</li>
</ul>
<p><img src="https://attachments.academia-assets.com/markdown/109184332/img-4.jpeg" alt="img-4.jpeg" data-image-width-px="1264" data-image-height-px="744" style="--image-width-px: 1264; --image-height-px: 744;"></p>
<p>Figure 3.3 - Zero shot, one shot and few shot learning on LLMs.</p>
<h2>3.2.1 Machine Learning and Deep Learning Processes</h1>
<p>The study of machine learning focuses on the creation of statistical models and algorithms that let computers conduct activities without having to be explicitly programmed. Many of the programs we use every day, like web search engines like Google that utilize a learning algorithm to rank web pages, use learning algorithms. Data mining, image processing, predictive analytics, and other processes all involve machine learning techniques. Most AI systems today are powered by machine learning, which develops predictive models using</p>
</div>
<div class="markdown-body" style="--page-number: 28; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="28" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>previous data and then applies those models to make predictions about the future. Machine learning, which first appeared in the 1990s and marked a substantial change in how AI systems were formed, contrasted with the way AI systems were previously built. A learning algorithm would infer how to perform a task based on data rather than providing instructions, so the how emerges from the dynamics of learning. Additionally, machine learning Because they allowed the use of a single generic learning technique, such as logistic regression, to power a variety of models, we referred to these models as foundation models to describe their unfinished but vital status. (Bommasani et al., 2021).</p>
<h2>3.2.2 Fine Tuning and Instruction Tuning</h1>
<p>Fine-tuning is a method of training a pre-existing model on a specific task by using a supervised dataset that is specific to that task. This method requires thousands to hundreds of thousands of labelled examples to achieve impressive performance on benchmarks. While finetuning has the advantage of achieving powerful performance on many benchmarks, it also has a disadvantage which is the potential for poor generalization out-of-distribution, which means that the model may not perform well on data that is different from the training data. Fine-tuning can also exploit spurious features of the training data, potentially resulting in an unfair comparison with human performance. (Brown et al, 2020)</p>
<p>Instruction tuning, which is closely related to fine-tuning and multi-task prompted training, is the process of optimising pre-trained LLMs on a set of structured examples in the form of natural language. We must first gather or create instruction-formatted instances to do instruction tuning. Using these structured instances, we next use supervised learning techniques (such training with the sequence-to-sequence loss) to improve LLMs. Even in a bilingual environment, LLMs can show higher generalisation skills after instruction tailoring.</p>
<h4>3.2.3 Prompt Engineering</h3>
<p>Prompt engineering is a new profession that concentrates on developing and optimizing prompts, with the goal of effectively using language models (LMs) for a wide range of applications and research topics. It is simpler to understand the promise and limitations of large language models (LLMs) if one has quick technical skills. Prompt engineering is a strategy used by developers to create reliable and efficient prompting methods that interface with LLMs and other tools. Not merely creating prompts is what prompt engineering entails. It includes a wide range of abilities and methods that are helpful for communicating and working with</p>
</div>
<div class="markdown-body" style="--page-number: 29; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="29" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>LLMs. The ability to communicate with, collaborate with, and comprehend LLM skills is crucial. (Saravia, 2022) Different ways to prompt a conversational agent or a LLM include:</p>
<ul>
<li>Think Step by Step</li>
</ul>
<p>Simply adding Think step by step at the end of a prompt is one of the most wellknown (and straightforward) prompt engineering approaches. The University of Tokyo and Google researchers discovered that including this sentence increased the accuracy of the GPT-3 (text-davinci-002 model) on several tests. On the MultiArith test, for instance, accuracy went from <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>17.7</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">17.7 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">17.7%</span></span></span></span> to <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>78.7</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">78.7 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">78.7%</span></span></span></span> (Kojima 2022). MultiArith problems are arithmetic problems that must be solved in several phases. (Gao, 2023) The effectiveness of think step by step was prompted using GPT 3.5 in figure 3.4 and gave the accurate output.</p>
<p>Yash has six dollars and apples cost fifteen cents. how many apples can yash buy? think step by step</p>
<p>To figure out how many apples Yash can buy with six dollars when each apple costs fifteen cents, you can follow these steps:</p>
<p>Step 1: Convert Yashs money to cents.<br>
Since there are 100 cents in a dollar, you need to multiply Yashs dollars by 100 to convert it to cents:<br>
6 dollars * 100 cents/dollar <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mn>600</mn></mrow><annotation encoding="application/x-tex">=600</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">600</span></span></span></span> cents</p>
<p>Now, Yash has 600 cents to spend.</p>
<p>Step 2: Determine the cost of one apple.<br>
Each apple costs fifteen cents, so the cost of one apple is 15 cents.</p>
<p>Step 3: Divide the total money by the cost of one apple.<br>
Now, you can calculate how many apples Yash can buy by dividing his total money ( 600 cents) by the cost of one apple ( 15 cents):<br>
600 cents / 15 cents/apple <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mn>40</mn></mrow><annotation encoding="application/x-tex">=40</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">40</span></span></span></span> apples</p>
<p>So, Yash can buy 40 apples with his six dollars.</p>
<p>Figure 3.4 - Think step by step using GPT 3.5 Turbo</p>
</div>
<div class="markdown-body" style="--page-number: 30; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="30" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>- Role Prompting</h1>
<p>Role prompting is another tactic that can be used to encourage LLMs to produce material in a particular creative style, such as an author. Some users claim that when they let Large Language Models (LLMs) know that they are subject-matter experts, the outcomes improve just as the prompt given to ChatGPT in figure 3.5. When the user requests code, this is accomplished by prepending a prompt to the LLM, such as You are a medical Assistant. As seen in figure 3.5. One explanation for this tactic is that it aids the LLM in concentrating and helps it decide which areas of its information to prioritise and place first. This is because, although having a great amount of knowledge, LLMs could not be aware of the portions that are pertinent to the users prompt. Knowing the users area of expertise will enable the LLM to produce more pertinent and precise responses. This is helpful when creating content for industries like medical, education, marketing, or art and entertainment where a particular tone or style is sought.</p>
<p>You are a medical assistant. write a step on how to identify breast cancer early</p>
<p>Identifying breast cancer early is crucial for successful treatment. Heres a step-by-step guide on how to do so:</p>
<ol>
<li>Breast Self-Examination (BSE):</li>
</ol>
<ul>
<li>Frequency: Perform a breast self-examination (BSE) regularly, preferably once a month.</li>
<li>Timing: The best time to perform a BSE is a few days after your menstrual period when the breasts are less tender and swollen. For post-menopausal women, choose a consistent date each month.</li>
<li>Visual Examination: Stand in front of a mirror with your hands on your hips and visually inspect your breasts for any changes in size, shape, or contour. Look for skin dimpling, puckering, or redness.</li>
<li>Raise Arms: Raise your arms and check for the same changes.</li>
<li>Breast Palpation: While lying down, use the pads of your fingers to gently palpate your entire breast, including the underarm area (axillary region). Use a circular motion, covering the entire breast, and apply different levels of pressure.</li>
<li>Nipple Examination: Gently squeeze each nipple to check for any discharge (other than breast milk) or changes in nipple position.</li>
</ul>
<p>Remember that most breast lumps are not cancerous, but its essential to report any changes or concerns to your healthcare provider promptly. Regular BSE, along with mammograms and clinical breast exams, can help detect breast cancer in its early stages when treatment is most effective. Consult your healthcare provider for personalized advice on breast cancer screening based on your age, risk factors, and medical history.</p>
<p>Figure 3.5 - Role Prompting using GPT 3.5 Turbo</p>
</div>
<div class="markdown-body" style="--page-number: 31; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="31" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<ul>
<li>Few-shot Learning.</li>
</ul>
<p>Few-shot learning involves providing examples of desired outputs to a language model, which helps it produce the desired outputs by constraining the potential output space. It is important to provide diverse and balanced examples to avoid bias and ensure coverage of all scenarios of interest. To avoid bias and ensure accuracy, it is important to provide diverse and balanced examples when training GPT for sentiment classification, covering all desired scenarios including neutral classification as seen in figure 3.6.<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-5.jpeg" alt="img-5.jpeg" data-image-width-px="1237" data-image-height-px="1324" style="--image-width-px: 1237; --image-height-px: 1324;"></p>
<p>Figure 3.6 - Few shots learning through sentiment analysis using GPT 3.5 Turbo</p>
</div>
<div class="markdown-body" style="--page-number: 32; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="32" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>3.4 Speech Recognition</h1>
<p>Speech recognition is a technology that has emerged in the twenty-first century and has become an integral part of our lives. The application of speech recognition has made our lives more comfortable and effective by enabling us to interact with machines using our natural voice. Speech recognition is a technique that allows machines to identify and understand human speech signals. This means that machines can interpret and respond to human speech, creating a communication link between humans and machines. The process involves the use of an acoustic and modelling algorithm which helps the machine to analyse and interpret the speech signals it receives. as seen in Figure 3.7 shows the acoustic algorithm which is responsible for converting the speech signals into digital format that can be processed by the machine. The modelling algorithm then uses statistical models to analyse the speech signals and identify the words and phrases being spoken. Once the words and phrases have been identified, the machine can then respond appropriately, either by providing information or conducting a specific task. (Ibrahim &amp; Varol, 2020)<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-6.jpeg" alt="img-6.jpeg" data-image-width-px="1213" data-image-height-px="475" style="--image-width-px: 1213; --image-height-px: 475;"></p>
<p>Figure 3.7: High level architecture for voice-based conversational AI agents<br>
The automatic speech recognition system (ASR) is a technology that aims to create a system that can understand human language and translate speech into a different medium for easy interpretation and understanding. The ASR system uses an acoustic model, modelling algorithm (language model) and decoder to execute its task of identifying the human voice through speech signals. The ASR system can convert speech into text, making it easier to interpret and understand, especially for people with hearing impairments. The development of ASR technology has been a significant achievement in the field of computer science, enabling machines to interact with humans in a more natural and intuitive way. (Ibrahim &amp; Varol, 2020)</p>
</div>
<div class="markdown-body" style="--page-number: 33; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="33" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>Chapter Four - Design and Methodology</h1>
<h4>4.1 Problem Definition and Target Audience</h3>
<h4>4.1.1 Problem Definition</h3>
<p>The issue at hand is the requirement for a novel conversational engine that makes use of the capabilities of AI, in particular GPT-style APIs, to enable imaginative and participatory storytelling. Traditional AI conversational systems can lack the nuance and originality necessary for compelling narratives and lively discussions. We want to create a software solution that not only engages users in on-the-spot chats but also expertly creates interactive stories to solve this. The specific challenges will want to overcome include:</p>
<ul>
<li>Speech-to-speech operation is difficult because it entails turning spoken language into text, processing that text, and producing intelligent speech responses.</li>
<li>The conversational engines performance should be able to store and analyse conversational interactions to be fine-tuned in the future, customised to meet the preferences of specific users, and improved overall.</li>
<li>Unavailability of Data: the chatbot will leverage on the latest Large Language Models which is the Generative Pre-trained Transformers 4 having over one trillion parameters.</li>
</ul>
<h4>4.1.2 Target Audience</h3>
<p>The target audience for this innovative conversational engine is diverse and comprises of individuals and professionals across various domains which include:</p>
<ul>
<li>Content Creators: writers, copywriters, and content creators can use this app in helping them to develop content ideas and refine their own content ideas into something much better.</li>
<li>Actors: actors can use this app to practice their scenes, research on a character, prepare for auditions and offer constructive feedback around their roles.</li>
<li>Film Directors: film directors can use this app to generate scripts, create monologues, analyse scenes, and give ideas around the film production.</li>
<li>Educators: Teachers in the fields of digital art, filming, theatre interested in enhanced learning experiences through AI content and storytelling will find this app of significant use.</li>
<li>General Users: Anyone who wants to converse with the app in a meaningful and enjoyable manner can use the app for companionship and read interesting stories they ask the app to share.</li>
</ul>
</div>
<div class="markdown-body" style="--page-number: 34; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="34" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<ul>
<li>Entertainment Industry: Game developers and entertainment businesses seeking AI driven interactive storytelling for games, virtual reality experiences, cartoons, animations will benefit from the app.</li>
</ul>
<h2>4.2 Programming Languages</h1>
<p>Programming languages serve as means of communication with computers to instruct them to conduct specific tasks. These languages encompass numerous functionalities that computers can comprehend and execute. Within this development context, two primary languages employed are Python and JavaScript.</p>
<p>Python is a widely recognized general-purpose programming language celebrated for its simplicity and readability, rendering it a highly suitable choice for application development. In the context of this project, Python was leveraged extensively to manage most of the backend codebase.</p>
<p>JavaScript, on the other hand, stands as a versatile programming language particularly wellsuited for web development. Its capabilities extend to crafting interactive and dynamic web pages, cementing its indispensability in frontend web development. Furthermore, TypeScript, an augmented subset of JavaScript, played a pivotal role in the frontend development phase. TypeScripts incorporation enhanced code maintainability and scalability, making it an instrumental addition to the development process.</p>
<h4>4.3 Software Development Process</h3>
<p>Software development is the ideation, specification, design, coding, documentation, testing, and bug-fixing processes involved in creating and maintaining applications, frameworks, or other software components. Software development, which typically involves a planned and methodical process and frequently overlaps with software engineering, broadly refers to all actions from the conception of the desired program to its eventual embodiment. The source code must be written and maintained. Software development also includes any other tasks that lead to the creation of software, such as prototype, modification, reuse, reengineering, and maintenance. Figure 4.1 displays the architecture of the development which encompasses both frontend and backend development. The application currently under development is an AI-powered Conversational Engine available as both a web and mobile application. This application takes both speech and text inputs and provides responses in the form of speech and text. The Conversational AI app is designed to create interactive stories and serve as an assistant in various fields, including healthcare.</p>
</div>
<div class="markdown-body" style="--page-number: 35; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="35" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p><img src="https://attachments.academia-assets.com/markdown/109184332/img-7.jpeg" alt="img-7.jpeg" data-image-width-px="1219" data-image-height-px="779" style="--image-width-px: 1219; --image-height-px: 779;"></p>
<p>Figure 4.1: System Architecture for Software Development</p>
<h2>4.4 Backend Development</h1>
<p>The Backend development is the backbone of the entire process.it manages the application architecture and sever-side scripting. It is responsible for building and maintaining the back end of the application.</p>
<p>In this app, the backend focused on developing the databases, back-end logic, application programming interface (APIs), architecture and servers. They utilize code that facilitates communication between browsers and databases, enabling the storage, comprehension, and removal of data.</p>
<h4>4.4.1 Application Programming Interface</h3>
<p>Application programming interfaces (APIs) allow two or more computer programs to communicate with one another. It is a type of software interface that gives other software programs a service. In contrast to a user interface, which links a computer to a human, an application programming interface (API) connects computers or pieces of software to one another. It is solely intended for usage by the computer programmer who is integrating it into the software, not by the end user. The many parts that make up an API for a programming language usually function as tools or services for programmers. When a program or</p>
</div>
<div class="markdown-body" style="--page-number: 36; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="36" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>programmer makes use of an API, that piece is referred to as being invoked. Calls also apply to the requests or endpoints that make up the API. A specification for an API defines these calls and explains how to utilize or implement them. (Wikipedia). The API used in this project is the latest OpenAI GPT 4. As seen in the code below, the function (text to text response) holds the OpenAI API which parses arguments like model (GPT4) that initiate the kind of model to use, the max tokens are set to two hundred (200) which is approximately about 175 words taken by the input. The temperature determines if the output will be random, it is used to adjust the probability distribution of the predicted output. Since we need to get more specific output and not just some random results, we use the lowest temperature which is set at 0.1 . the messages take the system and the user which can be in this format.</p>
<p>Character <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo></mrow><annotation encoding="application/x-tex">=</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span></span></span></span> You are a psychology Lecturer with a PhD in Psychology<br>
Prompt= How can I master emotional intelligence<br>
def text_to_text_response(text_input):<br>
system <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo><mo stretchy="false">{</mo></mrow><annotation encoding="application/x-tex">=\{</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">{</span></span></span></span> role: system, content: character <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mclose">}</span></span></span></span><br>
user = {role:user, content: prompt }<br>
try:<br>
response <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo></mrow><annotation encoding="application/x-tex">=</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span></span></span></span> openai. ChatCompletion.create(model=gpt-4, max_tokens=200, temperature=0.1, messages <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>=</mo></mrow><annotation encoding="application/x-tex">=</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel">=</span></span></span></span> {system, user <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mclose">}</span></span></span></span> )<br>
result = response <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mrow><mrow><mo fence="true">[</mo><msup><mrow></mrow><mtext>r</mtext></msup></mrow><mo fence="true">]</mo></mrow><mo></mo><mn>0</mn><mo fence="true">]</mo></mrow><mo fence="true">[</mo></mrow><annotation encoding="application/x-tex">\left.\left.\left[{ }^{\text {r }}\right.\right] \mid 0\right]\left[\right.</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen nulldelimiter"></span><span class="minner"><span class="mopen nulldelimiter"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">r</span></span></span></span></span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;">]</span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel"></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord">0</span><span class="mclose delimcenter" style="top:0em;">]</span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">[</span><span class="mclose nulldelimiter"></span></span></span></span></span> message <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mclose">}</span></span></span></span> [content] return result.<br>
except Exception as e:<br>
return (Failed to get text response from GPT4 API)</p>
<h2>4.4.2 OpenAI GPT</h1>
<p>The Generative Pre-Trained Transformers (GPT) is a state-of-the-art large language model developed. The GPT-4 was used for this development. The numerical values known as parameters control how a neural network processes input data and generates output data. They are encoded with the models knowledge and abilities and are learned from data during the training phase. A model can be more complicated and expressive as well as manage more data if it contains more parameters, (OpenGenus IQ,2023) The GPT 4 has about one trillion parameters, and it is the latest of the GPT Foundation models. Enhancing these models capacity to comprehend and produce natural language content, particularly in increasingly intricate and nuanced contexts, is one of the key objectives of their development. GPT-4</p>
</div>
<div class="markdown-body" style="--page-number: 37; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="37" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>outperforms existing large language models on a collection of NLP tasks, and exceeds the vast majority of reported state-of-the-art systems (which often include task-specific fine-tuning) (OpenAI, 2023)</p>
<h2>4.4.3 Fast API</h1>
<p>Fast API is an innovative web framework for creating Python RESTful APIs due to its simplicity, speed, and resilience. It was chosen for this development. IT is strong for production situations because it completely supports asynchronous programming and runs on Gunicorn and (Asynchronous Server Gateway Interface) ASGI servers like Uvicorn and hypercorn (FastAPI, 2023).</p>
<p>FastAPI made use of HTTP communication protocols which connected the backend to the frontend of the development such as GET (request information), POST (send information), PUT (update/append information), DELETE (remove information) which are used to create CRUD Operations. In this development, as seen in the code below the POST and GET methods were used to create route/text and/history for the frontend communication.</p>
<pre><code>@ app.post(&quot;/text&quot;) \leftarrow
async def post_text (email, textinput):
    message = text_to_text_response(textinput)
    return message.
@ app.get(&quot;/history/[email]&quot;) \leftarrow
async def get_chat_history(email):
    return {&quot;chat_history&quot;: chat_history }
</code></pre>
<p>You can interact with API endpoints right on your local machine without any external server. On running the command uvicorn main:app -reload</p>
<p>you should see a success message stating that the server has started as shown in figure 4.2 and the browser is fired up to take the URL http://127.0.0.1:8000/docs. The output that you will see will be the JSON response directly from the server which is displayed in figure 4.3. Appendix B4 shows the deployed version of the backend application.</p>
<pre><code>[venv]
[ogund@RichieDiamond MINOW64 ~/Downloads/thespain (main)
$ uvicorn main:app
INFO: Started server process [19824]
INFO: Waiting for application startup.
INFO: Application startup:complete.
INFO: Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
</code></pre>
<p>Figure 4.2: Uvicorn on Terminal</p>
</div>
<div class="markdown-body" style="--page-number: 38; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="38" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>FastAPI</h1>
<p>Figure 4.3: Uvicorn Interface</p>
<h4>4.4.4 OpenAI Whisper</h3>
<p>Whisper is an automated speech recognition (ASR) system that has been trained on 680,000 hours of supervised, multilingual, and multitask online data. We demonstrate how using a dataset this size and variety increases robustness against accents, background noise, and technical terminology. Additionally, it permits both translation into English from several languages as well as transcription in those languages. We are sharing our models and inference code to lay the groundwork for future research on robust speech processing as well as for the creation of useful applications. The encoder-decoder Transformer is how the Whisper architecture is implemented, which is a straightforward end-to-end strategy. An encoder receives input audio that has been divided into 30 -second segments and transformed into a logMel spectrogram. With the help of specific tokens that instruct the single model to conduct tasks like language identification, phrase-level timestamping, multilingual voice transcription, and to-English speech translation, a decoder is trained to anticipate the matching text caption. (OpenAI, 2023)</p>
<p>Whisper played a pivotal role in this development project by serving as the primary speech-to-text conversion tool. Its advanced speech recognition capabilities allowed for the seamless transformation of spoken language into textual data. By harnessing the power of Whisper, the project was able to transcribe verbal input accurately and efficiently, thus enabling enhanced data processing, analysis, and accessibility within the system. This integration of Whisper not only streamlined data input but also significantly improved the overall user experience by providing a robust and reliable mechanism for converting spoken content into a</p>
</div>
<div class="markdown-body" style="--page-number: 39; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="39" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>text format as seen in the code below where whisper is used to transcribe the audio/speech gotten from the frontend and returns the text of the speech.</p>
<pre><code>@ app.post(&quot;/speech&quot;)
async def post_speech (email, file: UploadFile= File(...)):
    with open (file. filename, &quot;wb&quot;) as buffer:
        buffer. write (file. file. read ())
    audio_input = open (file. filename, &quot;rb&quot;)
    transcript = openai. Audio.transcribe(&quot;whisper 1&quot;, audio_input)
    text_decoded = transcript[&quot;text&quot;]
</code></pre>
<h2>4.4.5 API Testing</h1>
<p>The API test was conducted using the Postman software found in appendix B1 which is used to evaluate routes and returned responses for each route using 200, 400,501 where:</p>
<h3>200 - Successful Status</h2>
<p>300 - Redirection Response<br>
400 - Client Error Response<br>
500 - Server error response<br>
Table 4.1 shows the endpoints and the request types that was used to link the backend to the frontend.</p>
<table>
<thead>
<tr>
<th style="text-align:left">ENDPOINT</th>
<th style="text-align:left">REQUEST TYPE</th>
<th style="text-align:left">DESCRIPTION</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">/Getstarted</td>
<td style="text-align:left">POST</td>
<td style="text-align:left">Used to login/Sign up into <br> the app</td>
</tr>
<tr>
<td style="text-align:left">/Text</td>
<td style="text-align:left">POST</td>
<td style="text-align:left">It takes the input of the user <br> and post back the output <br> from the API</td>
</tr>
<tr>
<td style="text-align:left">/Speech</td>
<td style="text-align:left">POST</td>
<td style="text-align:left">Takes the audio file from the <br> frontend as send it through <br> the speech route which <br> returns a text and is <br> converted back to speech in <br> the frontend</td>
</tr>
<tr>
<td style="text-align:left">/History</td>
<td style="text-align:left">GET</td>
<td style="text-align:left">It gets the chat history of the <br> user signed in and shows <br> previous conversation</td>
</tr>
</tbody>
</table>
<p>Table 4.1: Requests and Backend Routes</p>
</div>
<div class="markdown-body" style="--page-number: 40; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="40" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>4.5 Frontend Development</h1>
<p>The process of developing an applications graphical user interface using HTML, CSS, and JavaScript so that visitors can view and interact with it is known as front-end web development. Hypertext Markup Language (HTML) is the building block of any website construction process; without it, a web page would not exist. Writing with links, also referred to as hyperlinks, is referred to as hypertext. When a user clicks on a word or phrase containing a hyperlink, they are transferred to another online page. With the use of CSS, which controls how the app is displayed, you may give it a uniquely personalized look. This is achieved by storing style sheets that, when activated, sit on top of current style rules, and are triggered by inputs like the screen size and resolution of the device. JavaScript, an event-based imperative programming language, can convert an HTML page into a dynamic interface. JavaScript code can make use of the Document Object Model (DOM), which is made available by the HTML standard, to alter a web page in response to various events like user input. (Wikipedia, 2019)</p>
<h4>4.6 Integrated Development Environment</h3>
<p>The Visual Studio Code is a code editor with focus on enhancing the development and debugging experience for modern web and cloud applications. It was used to implement the whole development environment. It was suitable because it is open source and free to use with varieties of extensions and customizations for the framework. It also integrates Git version control which was used to commit changes in the code with a built-in bash terminal used to run commands and scripts directly within the editor.</p>
<h4>4.7 Mobile Application</h3>
<p>A framework called React Native was used to you to create the mobile applications using ReactNative offers a fundamental collection of native components, such as View, Text, and Image, Sound, Dropdown which correspond precisely to the platforms native UI building blocks. React Native is like React, except its building pieces are native components rather than web components. it enables developers to produce mobile applications for Android as seen in Figure 4.4.</p>
</div>
<div class="markdown-body" style="--page-number: 41; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="41" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p><img src="https://attachments.academia-assets.com/markdown/109184332/img-8.jpeg" alt="img-8.jpeg" data-image-width-px="1227" data-image-height-px="839" style="--image-width-px: 1227; --image-height-px: 839;"></p>
<p>Figure 4.4 - User Interface of the Mobile App Design</p>
<h2>4.8 Hosting Platform</h1>
<p>Render is a unified cloud platform for building and running websites. Render was connected to GitHub where the codes was pushed and then deploys the code from the GitHub account connected. It will automatically build the site once the render is connected to the repo. Render hosts the site on a global fast CDN which ensures a fast download time for all users across the globe. Appendix B4 shows the app already deployed to the free hosting server.</p>
<h4>4.9 Integration of Real-Time Conversations and Anecdote Sharing</h3>
<p>The integration of the conversations was done in the python code holding the function text_to_text_response(text_input) which processes the GPT 4API. The GPT 4 AP takes a text from the user and gives the system. The app is designed to work as a thespian with 20 years of experience in acting, script analysis, character development, collaboration, stage performance, character transformation, auditions, and research as seen in the code below.</p>
<p><sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup></p>
<hr class="footnotes-sep">
<section class="footnotes">
<ol class="footnotes-list">
<li id="fn1" class="footnote-item"><p>character = You are a thespian with over 20 years experience in acting, script analysis, character development, collaboration, performance, character transformation, auditions and research.<br>
def text_to_text_response(prompt):<br>
system = [role: system content: character]<br>
user = [role user content: prompt] <a href="#fnref1" class="footnote-backref"></a></p>
</li>
</ol>
</section>
</div>
<div class="markdown-body" style="--page-number: 42; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="42" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>Chapter Five - Implementation and Results</h1>
<h4>5.1 Software Testing</h3>
<p>The testing for this development was done using the Waterfall Methodology. A sequential development approach that resembles a waterfall is called waterfall methodology. It takes through the Requirements, Design, Implementation, Testing, Deployment and Maintenance. The testing performed on the app include:</p>
<ul>
<li>Functional Testing: A functionality test was conducted on the app to check if the app functioned correctly and performed its task and from the use cases in 5.4 the app has a polite conversation flow and accurately recognize user inputs and provides relevant outputs. At the backend, all errors were managed to be able to locate where an issue is from in cases there is failure.</li>
<li>Usability Testing: The user experience and navigation is easy to use, and the Table 5.1 shows that most users had an enjoyable experience and easy navigation with the app.</li>
<li>Integration Testing: this was successfully tested when connecting the backend to the GPT API and it interact seamlessly with it for data retrieval. An API key was generated to authenticate and authorize the use and access to data.</li>
<li>Acceptance Testing: this was conducted to ensure the app meet the compliance regulations by informing the users that their conversations will be saved for finetuning purposes before signing up into the app.</li>
</ul>
<h4>5.2 Performance evaluation and User Feedback</h3>
<p>The user evaluation, which encompassed thirty-three participants, produced insightful data in table 5.1 shows how well it functions and how users view it. The following are the main conclusions of the evaluation. Users appreciated the apps speed and reactivity, which helped to create a seamless and effective user experience. The software was well-received. It successfully converted spoken language into text (Text to Speech Result Accuracy) and converted text into spoken language (Speech to Text Accuracy) with a high degree of accuracy. There is potential for improvement in terms of user satisfaction, even if a sizable percentage of users reported pleasure with the apps overall performance. Most users thought the output quality was high, which suggests that there were thoughtful and well-thought-out exchanges. Interestingly, the app was perceived as distinct from existing similar applications (Similarity with Existing Apps), suggesting potential areas for differentiation and alignment with user expectations.</p>
</div>
<div class="markdown-body" style="--page-number: 43; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="43" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<table>
<thead>
<tr>
<th style="text-align:left">Users Evaluation Metrics</th>
<th style="text-align:left">Score</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Speed and Responsiveness</td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>77</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">77 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">77%</span></span></span></span></td>
</tr>
<tr>
<td style="text-align:left">Text to Speech Result Accuracy</td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>95</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">95 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">95%</span></span></span></span></td>
</tr>
<tr>
<td style="text-align:left">Speech to Text Accuracy</td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>90</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">90 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">90%</span></span></span></span></td>
</tr>
<tr>
<td style="text-align:left">User Satisfaction</td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>70</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">70 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">70%</span></span></span></span></td>
</tr>
<tr>
<td style="text-align:left">Likelihood of Future Use</td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>80</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">80 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">80%</span></span></span></span></td>
</tr>
<tr>
<td style="text-align:left">Output Quality</td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>78</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">78 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">78%</span></span></span></span></td>
</tr>
<tr>
<td style="text-align:left">Similarity with Existing Apps</td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>19.2</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">19.2 \%</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8056em;vertical-align:-0.0556em;"></span><span class="mord">19.2%</span></span></span></span></td>
</tr>
</tbody>
</table>
<p>Table 5.1: Performance of User Feedback</p>
<h2>5.3 Analysis of Results</h1>
<p>The essential goal of this project is to make the app perform features like analysing scripts to understanding characters, plots, and themes, create contents around theatre, ability to collaborate with users in acting and directing, assist with preparation of auditions, research, and trainings. Here are sample of use cases with interacting with the acting app.</p>
</div>
<div class="markdown-body" style="--page-number: 44; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="44" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>5.3.1 Use Case (1) - Storytelling</h1>
<p>Figure 5.1 shows how The application is able to tell interesting stories depending on the user prompt and the more specific the user is, the more accurate the results will be.<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-9.jpeg" alt="img-9.jpeg" data-image-width-px="839" data-image-height-px="1359" style="--image-width-px: 839; --image-height-px: 1359;"></p>
<p>Figure 5.1: storytelling prompt from user</p>
</div>
<div class="markdown-body" style="--page-number: 45; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="45" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>5.4.2 Use Case (2) - Script Writer</h1>
<p>The application does excellently with writing scripts based on the users preference as seen in Figure 5.2 below.<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-10.jpeg" alt="img-10.jpeg" data-image-width-px="1186" data-image-height-px="1670" style="--image-width-px: 1186; --image-height-px: 1670;"></p>
<p>Figure 5.2: Script generation from the application</p>
</div>
<div class="markdown-body" style="--page-number: 46; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="46" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>5.4.3 Use Case (3) - Content Creation</h1>
<p>The apps ability to generate contents around movies is amazing and can be used for social media awareness towards drama or art event. Figure 5.3 displays a content around a popular movie.<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-11.jpeg" alt="img-11.jpeg" data-image-width-px="705" data-image-height-px="664" style="--image-width-px: 705; --image-height-px: 664;"></p>
<p>Figure 5.3: content generation</p>
<h4>5.4.4 Use Case (4) - Tutor</h3>
<p>The app can serve as a great tutor and coach around topics in theatre, film making, drama, acting and other related talks to educators and professionals.<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-12.jpeg" alt="img-12.jpeg" data-image-width-px="865" data-image-height-px="704" style="--image-width-px: 865; --image-height-px: 704;"></p>
<p>Figure 5.4: Asking questions.</p>
</div>
<div class="markdown-body" style="--page-number: 47; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="47" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>Chapter Six - Conclusion and Recommendation</h1>
<h4>6.1 Conclusion</h3>
<p>Conversational AI is no doubt changing the world in a drastic way by providing general solutions to any area of life the impact of Conversational AI across a multitude of domains, attributing its widespread adoption to remarkable advancements in machine learning, natural language processing, and Generative AI The project started with a simple aim &quot;an app that has the ability to share interactive and conversational stories leveraging on the latest GPT- style. During implementation, Prompt engineering helped us to model the GPT 4 into a personalized AI-Powered Thespian app being connected to a mongo DB database as seen in Appendix B2 which can store the conversations which is one of the objectives of the project.</p>
<p>Through various compelling use cases, we illuminated the practical applications of our conversational agent, showcasing its adaptability and versatility. As to the fine tuning of the GPT model, it unable to finetune conversation data to it model yet which is why the objective was not fully met. this does not mean the aim cannot be achieved, they were just simply issues beyond control as large language models on its own requires more time and study to resolve with the fact that GPT 4 is a new LLM and in the future, it will allow finetuning. although the finetuning of the data was not fully met, there was more than enough evidence that the remaining aims and objectives were met, and it will be incorporated in the future work.</p>
<p>The project contributes greatly to the creative AI field as it becomes one the first conversational app to leverage on the largest language model GPT-4 and it chat responses were better more compared to other existing LLMs. It is my aspiration that the knowledge and insights shared here will serve as an invaluable resource for fellow researchers, developers, and enthusiasts who share our passion for the limitless potential of AI-powered conversations. As we move forward, the journey persists, and the future shines brightly for Conversational AI in the context of an MSc in Artificial Intelligence.</p>
<p>In conclusion, this project not only contributes to the burgeoning field of conversational AI but also underscores the transformative potential of AI-powered conversational agents in education, storytelling, and beyond. The journey has revealed that while the road to building advanced conversational engines is challenging, the destination holds immense promise for shaping the way we learn, tell stories, and interact with AI in the digital age.</p>
</div>
<div class="markdown-body" style="--page-number: 48; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="48" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>6.2 Recommendation</h1>
<p>Based on the conclusion, I recommend that:</p>
<ul>
<li>As the conversational engine gains more visibility, it needs to be able to manage more users. Ensuring that the system scales to handle several concurrent chats and maintain its performance can be a challenge that calls for optimisation. The future work demands that a large database system is used to save, train and finetune the model on any large language.</li>
<li>The backend development of the project can be used on a greater scale to develop a full sophisticated Mobile Assistant app with different prompts for different purposes not being restricted to storytelling or the work of a thespian alone. It can range from having medical assistant, education assistant, financial advisor, companion app as seen in the below figure 6.1.</li>
<li>As we look to the future, the project suggests promising avenues for expansion and enhancement. Further development could focus on improving the applications user interface based on valuable user suggestions. Additionally, efforts to enhance AI response time and refine the audio output quality could elevate the user experience to even greater heights.</li>
</ul>
<p><img src="https://attachments.academia-assets.com/markdown/109184332/img-13.jpeg" alt="img-13.jpeg" data-image-width-px="977" data-image-height-px="673" style="--image-width-px: 977; --image-height-px: 673;"></p>
<p>Figure 6.1: Future of the Mobile Application</p>
</div>
<div class="markdown-body" style="--page-number: 49; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="49" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>6.3 Limitation and Challenges</h1>
<p>Throughout the development process of the application, I encountered several limitations and challenges, each of which required a strategic approach for resolution:</p>
<p>Selection of Closed-Source Model: Originally, the intention was to utilize an open-source GPT model for the project execution. However, the project encountered a significant hurdleboth the extensive model parameters and the available computing resources (local and schoolbased) proved insufficient for seamless operation. Consequently, I made the decision just 21 days to the deadline to transition to a closed-source model, specifically GPT-4. This shift to a more powerful model was aimed at enhancing the applications speed and alleviating the performance issues associated with the initial open-source model. This decision stemmed from the limitation of executing the project on local machines and school resources, which struggled to accommodate the sheer volume of parameters in the open-source model.</p>
<p>Database Connection Challenges: The process of establishing a robust database connection for storing application conversations presented its own set of difficulties. Initially, MySQL or MongoDB was chosen as the database solution to store conversations users have with the application. However, complications arose when attempting to connect this database to the applications backend development environment. These challenges were caused by the university internet access restrictions imposed by the server. Consequently, the decision was made to transition use a personal internet server to host the database. This shift allowed for a more stable and accessible database connection, facilitating smoother data storage and retrieval processes.</p>
<p>Financial Considerations: While the hosting platform initially provided free access, it was essential to acknowledge that this free access would have a limited duration and contributes to the slow response of the app. This posed a potential financial challenge, as the eventual expiration of the free access would necessitate personal financial investment for continued platform usage.</p>
<p>Dependency on External API: The applications effectiveness was primarily reliant on an external API server. Although the application was functional and efficient, it was vulnerable to disruptions in API server performance. Any downtime or slowdown in the API server directly affected the applications performance. To mitigate this reliance on external servers, a potential solution involved developing a large language model from scratch. However, this endeavour</p>
</div>
<div class="markdown-body" style="--page-number: 50; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="50" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>would demand significant financial resources, large team of developers, thereby introducing a new challenge related to budget constraints.</p>
</div>
<div class="markdown-body" style="--page-number: 51; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="51" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>References</h1>
<p>Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., Arx, von, Bernstein, M. S., Bohg, J., Bosselut, A. and Brunskill, E. (2021) On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258.</p>
<p>Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G. and Askell, A. (2020) Language models are few-shot learners. Advances in neural information processing systems, 33 pp. 1877-1901.</p>
<p>Chen, J., Prasad, R., Stoyanchev, S., Selfridge, E., Bangalore, S. and Johnston, M. (2018) Corpus and annotation towards NLU for customer ordering dialogs. In IEEE, pp. 707-713.</p>
<p>Devlin, J., Chang, M.-W., Lee, K. and Toutanova, K. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv.org. [Online] [Date Accessed: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>20</mn><mtext>th</mtext></msup></mrow><annotation encoding="application/x-tex">20^{\text {th }}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord">2</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">th</span></span></span></span></span></span></span></span></span></span></span></span></span> September,2023]https://arxiv.org/abs/1810.04805.</p>
<p>Dong, X., Qian, L., Guan, Y., Huang, L., Yu, Q. and Yang, J. (2016) A multiclass classification method based on deep learning for named entity recognition in electronic medical records. In IEEE, pp. 1-10.</p>
<p>Gao, A. (2023) Prompt engineering for large language models. Available at SSRN 4504303.</p>
<p>Gatt Albert and Krahmer Emiel (2018) Survey of the state of the art in natural language generation. Journal of Artificial Intelligence Research. AI Access Foundation, January.</p>
<p>GPT-3.5 model architecture (2023a) OpenGenus IQ: Computing Expertise &amp; Legacy. [Online] [Accessed on 26th September 2023] https://iq.opengenus.org/gpt-3-5-model.</p>
<p>Ibrahim, H. and Varol, A. (2020) A study on automatic speech recognition systems, pp. 1-5.</p>
<p>Jackson, D. and Latham, A. (2022) Talk to The Ghost: The Storybox methodology for faster development of storytelling chatbots. Expert Systems with Applications. Elsevier, 190 p. 116223 .</p>
<p>Keneshloo, Y., Shi, T., Ramakrishnan, N. and Reddy, C. K. (2019) Deep reinforcement learning for sequence-to-sequence models. IEEE transactions on neural networks and learning systems. IEEE, 31 pp. 2469-2489.</p>
</div>
<div class="markdown-body" style="--page-number: 52; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="52" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>Khurana, D., Koli, A., Khatter, K. and Singh, S. (2023) Natural language processing: State of the art, current trends and challenges. Multimedia tools and applications. Springer, 82 pp. <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3713</mn><mo></mo><mn>3744</mn></mrow><annotation encoding="application/x-tex">3713-3744</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">3713</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin"></span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">3744</span></span></span></span>.</p>
<p>Kojima, T., Shixiang, S., Gu, Reid, M., Research, G., Matsuo, Y. and Iwasawa, Y. (2022) Large Language Models are Zero-Shot Reasoners.</p>
<p>Kulkarni, P., Mahabaleshwarkar, A., Kulkarni, M., Sirsikar, N. and Gadgil, K. (2019) 'Conversational AI: An overview of methodologies, applications &amp; future scope,'pp. 1-7.</p>
<p>Liu, J., Kong, X., Xia, F., Bai, X., Wang, L., Qing, Q. and Lee, I. (2018) Artificial intelligence in the 21st century. Ieee Access. IEEE, 6 pp. 34403-34421.</p>
<p>OpenAI (2023) GPT-4 Technical Report. arXiv:2303.08774 [cs], March.</p>
<p>OShea, J., Bandar, Z. and Crockett, K. (2011) Systems engineering and conversational agents. Intelligence-based systems engineering. Springer, pp. 201-232.</p>
<p>Prystawski, B. and Goodman, N. D. (2023) Why think step-by-step? Reasoning emerges from the locality of experience. arXiv preprint arXiv:2304.03843.</p>
<p>Ruane, E., Birhane, A. and Ventresque, A. (2019) Conversational AI: Social and ethical considerations., pp. 104-115.</p>
<p>Saravia, E. (2022) Prompt Engineering Guide. GitHub. [Online] [Date Accessed: 19th September,2023] https://github.com/dair-ai/Prompt-Engineering-Guide.</p>
<p>Shanahan, M. (2022) Talking about large language models. arXiv preprint arXiv:2212.03551.</p>
<p>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, . and Polosukhin, I. (2017) Attention is all you need. Advances in neural information processing systems, 30 .</p>
<p>Wikipedia Contributors (2019) Softmax function. Wikipedia. Wikimedia Foundation. [Online] [Date Accessed: 20 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mtext>th</mtext></msup></mrow><annotation encoding="application/x-tex">{ }^{\text {th }}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">th</span></span></span></span></span></span></span></span></span></span></span></span></span> September,2023] https://en.wikipedia.org/wiki/Softmax_function.</p>
<p>Xue, Z., Li, R. and Li, M. (2022) Recent progress in conversational AI. arXiv preprint arXiv:2204.09719.</p>
</div>
<div class="markdown-body" style="--page-number: 53; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="53" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>Zhang, C. and Lu, Y. (2021) Study on artificial intelligence: The state of the art and future prospects. Journal of Industrial Information Integration. Elsevier, 23 p. 100224.</p>
<p>Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang, B., Zhang, J., Dong, Z., Du, Y., Yang, C., Chen, Y., Chen, Z., Jiang, J., Ren, R., Li, Y., Tang, X., Liu, Z. and Liu, P. (2023) A Survey of Large Language Models. arXiv:2303.18223 [cs], March.</p>
</div>
<div class="markdown-body" style="--page-number: 54; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="54" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>Appendices</h1>
<p>Appendix A - Terms of Reference</p>
<table>
<thead>
<tr>
<th style="text-align:left">Department of Computing and Mathematics <br> Computing and Digital Technology Postgraduate Programmes <br> Terms of Reference Coversheet</th>
<th style="text-align:left"></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Student name:</td>
<td style="text-align:left">Richard Ademola Ogundele</td>
</tr>
<tr>
<td style="text-align:left">University I.D.:</td>
<td style="text-align:left">22539744</td>
</tr>
<tr>
<td style="text-align:left">Academic supervisor:</td>
<td style="text-align:left">Prog YongHong Peng, Dr David Jackson</td>
</tr>
<tr>
<td style="text-align:left">External collaborator (optional):</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Project title:</td>
<td style="text-align:left">Al-powered Thespian: developing an innovative conversational engine</td>
</tr>
<tr>
<td style="text-align:left">Degree title:</td>
<td style="text-align:left">MSc Artificial Intelligence</td>
</tr>
<tr>
<td style="text-align:left">Project unit code:</td>
<td style="text-align:left">6G7V0007_2223_9F</td>
</tr>
<tr>
<td style="text-align:left">Credit rating:</td>
<td style="text-align:left">60</td>
</tr>
<tr>
<td style="text-align:left">Start date:</td>
<td style="text-align:left">05/06/2023</td>
</tr>
<tr>
<td style="text-align:left">ToR date:</td>
<td style="text-align:left">26/06/2023</td>
</tr>
<tr>
<td style="text-align:left">Intended submission date:</td>
<td style="text-align:left">22/09/2023</td>
</tr>
<tr>
<td style="text-align:left">Signature and date student:</td>
<td style="text-align:left"></td>
</tr>
<tr>
<td style="text-align:left">Signature and date external <br> collaborator (if involved):</td>
<td style="text-align:left"></td>
</tr>
</tbody>
</table>
<p>This sheet should be attached to the front of the completed ToR and uploaded with it to Moodle.</p>
</div>
<div class="markdown-body" style="--page-number: 55; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="55" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>PROJECT TITLE:</h1>
<p>AI-powered Thespian: Developing an innovative conversational Engine.</p>
<h3>PROJECT BACKGROUND</h2>
<p>Software agents known as Conversational Engines enable users to have natural language conversations with computer systems (OShea, Bandar, &amp; Crockett, 2011). The term conversational engine has various meanings in the field of conversational agent research, with chatbots being defined as systems that can answer basic questions and are appropriate for question-and-answer scenarios (OShea, Bandar, &amp; Crockett, 2011). However, the engines can have in-depth conversations since they can mimic human communication. The advanced conversational agent engine that supports conversational agents makes use of natural language processing and dialogue management techniques to keep the context of the conversation consistent throughout the exchange and to support mixed-initiative dialogue, which lets users ask questions in any order (Jackson &amp; Latham., 2012).</p>
<p>The AI-powered Thespian refers to an artificial intelligence (AI) technology that can generate theatrical dialogue or monologues, often using natural language processing (NLP), natural language models (NLM) and machine learning (ML) algorithms by using large corpus of existing character and dialogues to generate new and unique stories and scripts. This is done by training the AI system to recognise and interpret nuances in language, such as sarcasm, humour, or emotion, and to generate appropriate responses that take these nuances into account. The development of this innovative conversational engine will be powered by an Application Programming Interface, and it will be used in other range of applications like health and social care, chatbots and could potentially revolutionize the way humans interact with technology. (Frackiewicz, 2023).</p>
<p>The AI thespian Conversational engine can take the text and speech as input and produce text and speech as output depending on how the user interacts with it. It operates on the text-to-speech process, speech-to-text process, and speech-to-speech process. The AI system will leverage on open-source Application Programming Interface (API) such as the latest GPT-API model.</p>
</div>
<div class="markdown-body" style="--page-number: 56; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="56" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>AIMS<br>
The Project Aim is to be able to:</p>
<ul>
<li>provide a platform to demonstrate a system for creative AI and storytelling.</li>
<li>Hold real-time conversations with users and create interactive stories.</li>
<li>Developing a software that leverages the latest GPT-style API.</li>
<li>To be used in a wide range of contexts and applications such as health &amp; social care and art &amp; entertainment.</li>
</ul>
<p>Product Aims is a Web based backend application that leverages the GPT API. It will be able to interact with users through text and speech to create interactive stories and dialogues.</p>
<h2>OBJECTIVES</h1>
<p>In order to achieve the aims identified various tasks need to be completed:</p>
<ul>
<li>Develop a software system that effectively manages the whole process of conversation process and can perform speech to speech operation.</li>
<li>Effective natural language prompts for GPT-3 that portrays character and narrative while also testing for effectiveness in terms of coherence and latency.</li>
<li>Ability to have the potential to store conversational exchanges for fine tuning of the system.</li>
</ul>
<h3>LEARNING OUTCOMES</h2>
<p>The learning outcomes set for this project were:</p>
<ul>
<li>The ability to choose, customise and combine suitable core techniques for solving the given AI problem.</li>
<li>Process and analyse, effectively and efficiently, data of varying scales and from heterogenous sources, formats, and systems, using a range of suitable languages, tools and environments.</li>
<li>Build AI solutions with good software practices such as in code reuse, separation of concerns, modularity, testing and documentation.</li>
</ul>
</div>
<div class="markdown-body" style="--page-number: 57; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="57" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>HARDWARE REQUIRED RESOURCES</h1>
<ul>
<li>Processor (CPU): A modern, high-performance CPU to run the necessary software components and handle computational workload. PC with i7 or i9 processor</li>
<li>Memory (RAM): sufficient RAM for handling large-scale language models and data processing. Aiming at least 16GB of RAM, but considering higher capacities like 32GB for running multiple tasks simultaneously</li>
<li>Graphics Card (GPU): to accelerate certain computations, such as training or fine-tuning AI models. Using a GPU AMD R5 M230</li>
<li>Operating System: Windows and Linux will be used for the AI development.</li>
</ul>
<h3>SOFTWARE REQUIRED RESOURCES</h2>
<ul>
<li>Programming Languages: Python Programming and JavaScript</li>
<li>Frontend Development: HTML, CSS, ReactJS, Bootstrap</li>
<li>Backend Development: Flask</li>
<li>Database Management: MySQL</li>
<li>Natural Language Processing Tools: NLTK, Spacy</li>
<li>Application Programming Interface (API): GPT-NeoX API, Text to Speech API (Google Text-to-Speech), Whisper API</li>
<li>Internet Connectivity: for downloading datasets, accessing cloud services, and interacting with APIs.</li>
<li>Integrated Development Environment (IDEs): for writing, testing, and debugging the code. Choices are Jupyter Notebook, Visual Studio Code.</li>
<li>Version Control: GitHub.</li>
<li>Deployment and Hosting: To deploy the app, Choices are Amazon Web Services (AWS) and Google Cloud Platform (GCP).</li>
<li>Testing and Quality Assurance: To ensure the quality and reliability of the app, Tools like Selenium and Pytest will assist in writing unit test, integration test and end-to-end tests.</li>
</ul>
</div>
<div class="markdown-body" style="--page-number: 58; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="58" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>EVALUATION PLAN<br>
Duration: <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>5</mn><mtext>th</mtext></msup></mrow><annotation encoding="application/x-tex">5^{\text {th }}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord"><span class="mord">5</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">th</span></span></span></span></span></span></span></span></span></span></span></span></span> June 2023 - <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>22</mn><mtext>nd</mtext></msup></mrow><annotation encoding="application/x-tex">22^{\text {nd }}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8491em;"></span><span class="mord">2</span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8491em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">nd</span></span></span></span></span></span></span></span></span></span></span></span></span> September 2023<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-14.jpeg" alt="img-14.jpeg" data-image-width-px="1221" data-image-height-px="360" style="--image-width-px: 1221; --image-height-px: 360;"><br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-15.jpeg" alt="img-15.jpeg" data-image-width-px="316" data-image-height-px="173" style="--image-width-px: 316; --image-height-px: 173;"></p>
<p>Signed:</p>
</div>
<div class="markdown-body" style="--page-number: 59; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="59" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>START HERE - Basic Information</h1>
<p>This form must be completed for all student projects.</p>
<h3>Before you proceed</h2>
<p>Some activities inherently involve increased risks or approval by external regulatory bodies, so a proportional ethics review is not recommended and a full ethical review may be required.</p>
<p>These may include:<br>
i. Approval from an external regulatory body (including, but not limited to: NHS (HRA), HMPPS etc.);<br>
ii. Misleading participants;<br>
iii. Research without the participants consent;<br>
iv. Clinical procedures with participants;<br>
v. The ingestion or administration of any substance to participants by any means of delivery;<br>
vi. The use of novel techniques, even where apparently non-invasive, whose safety may be open to question;<br>
vii. The use of ionising radiation or exposure to radioactive materials;<br>
viii. Engaging in, witnessing, or monitoring criminal activity;<br>
ix. Engaging with, or accessing terrorism related materials;<br>
x. A requirement for security clearance to access participants, data or materials;<br>
xi. Physical or psychological risk to the participants or researcher;<br>
xii. The project activity takes place in a country outside of the UK for which there is currently an active travel warning issued by the authorities (see info button);<br>
xiii. Animals, animal tissue, new or existing human tissue, or biological toxins and agents;<br>
xiv. The sharing of participant personal data with a third party, regardless of the form under which the data is presented.</p>
<p>If any of these activities are fundamental to your project, please contact your supervisor to determine if a full application is required.</p>
<p>This form must be completed for each research project which you undertake at the University. It must be approved by your supervisor (where relevant) PRIOR to the start of any data collection.</p>
<p>In completing this form, please consult the Universitys Research Ethics and Governance standards.</p>
<p>A1a Please confirm that you will abide by the Universitys Research Ethics and Governance standards in relation to this project.<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>14</mn></msup></mrow><annotation encoding="application/x-tex">{ }^{14}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">14</span></span></span></span></span></span></span></span></span></span></span></span> Yes<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mn>15</mn></msup><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi></mrow></mrow><annotation encoding="application/x-tex">{ }^{15} \mathrm{No}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">15</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathrm">No</span></span></span></span></span></p>
</div>
<div class="markdown-body" style="--page-number: 60; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="60" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>A1b Data Protection<br>
The University is responsible for complying with the UK General Data Protection Regulation whenever personal data is processed. Under the Data Protection Policy, all staff and students have a responsibility to comply with the regulation in their day-to-day activities. The first step you can take to understand these responsibilities is to review the Data Protection in<br>
Research guidance pages and complete the Universitys Mandatory Data Protection Training. Student training is available through Moodle (in the Skills Online section - please follow this link). To make sure your knowledge is up to date, all staff and students must complete the training every two years. If you have any issues in accessing the data protection training or have any questions about the training, please contact dataprotection@mmu.ac.uk.</p>
<p>Have you reviewed the Data Protection guidance pages and completed the Data Protection Training in the last two years?<br>
a Yes<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi><mrow><mtext></mtext><mi mathvariant="normal">N</mi></mrow></mrow><annotation encoding="application/x-tex">c \mathrm{~N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">c</span><span class="mord"><span class="mspace nobreak"></span><span class="mord mathrm">N</span></span></span></span></span><br>
A2 Are you submitting this application as a learning experience, for a unit which already has ethical approval? (please confirm with your supervisor)<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mtext>Yes</mtext></msub></mrow><annotation encoding="application/x-tex">c_{\text {Yes }}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Yes</span></span></span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><br>
a <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">b</mi></mrow><annotation encoding="application/x-tex">\mathrm{Nb}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord"><span class="mord mathrm">Nb</span></span></span></span></span></p>
<p>A3 Student details</p>
<table>
<thead>
<tr>
<th style="text-align:left">Title</th>
<th style="text-align:left">First Name</th>
<th style="text-align:left">Sumame</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"></td>
<td style="text-align:left">Richard Ademota</td>
<td style="text-align:left">Oguindele</td>
</tr>
<tr>
<td style="text-align:left">Email</td>
<td style="text-align:left"></td>
<td style="text-align:left">RICHARD.A.OGUNDELE@stu.mmu.ac.uk</td>
</tr>
</tbody>
</table>
<p>A3.1 Manchester Metropolitan University ID number<br>
22539744</p>
<p>A4 Supervisor<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-16.jpeg" alt="img-16.jpeg" data-image-width-px="1177" data-image-height-px="286" style="--image-width-px: 1177; --image-height-px: 286;"></p>
</div>
<div class="markdown-body" style="--page-number: 61; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="61" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>A5 Which Faculty is responsible for the project?</h1>
<p>Science and Engineering</p>
<h3>A6 Course title</h2>
<p>MSc Artificial Intelligence</p>
<h3>A7 Project title</h2>
<p>Al-powered Thespian: developing an innovative conversational engine</p>
<h3>A8 What is the proposed start date of your project?</h2>
<p>05/06/2023</p>
<h3>A9 When do you expect to complete your project?</h2>
<p>22/09/2023</p>
<p>A10 Please describe the overall aims of your project (3-4 sentences). Research questions should also be included here.</p>
<p>The Project Aim is to be able to:<br>
o provide a platform to demonstrate a system for creative AI and storytelling.<br>
o Hold real-time conversations with users and create interactive stories.<br>
o Developing a software that leverages the latest GPT-style API.<br>
o TO be used in a wide range of contexts and applications such as health &amp; social care and art &amp; entertainment.</p>
<h3>A11 Please describe the research activity</h2>
<p>In order to achieve the aims identified various tasks need to be completed:<br>
o Develop a software system that effectively manages the whole process of conversation process and can perform speech to speech operation.<br>
o Effective natural language prompts for GPT-3 that portrays character and narrative while also testing for effectiveness in terms of coherence and latency.<br>
o Ability to have the potential to store conversational exchanges for fine tuning of the system.</p>
</div>
<div class="markdown-body" style="--page-number: 62; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="62" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>A12 Please provide details of the participants you intend to involve (please include information relating to the number involved and their demographics; the inclusion and exclusion criteria)</p>
<p>None</p>
<p>A13 Please upload your project protocol</p>
<table>
<thead>
<tr>
<th style="text-align:left">Type</th>
<th style="text-align:left">Document Name</th>
<th style="text-align:left">File Name</th>
<th style="text-align:left">Version Date</th>
<th style="text-align:left">Version</th>
<th style="text-align:left">Size</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Project Protocol</td>
<td style="text-align:left">Terms of Reference</td>
<td style="text-align:left">Terms of Reference.pdf</td>
<td style="text-align:left">26/06/2023</td>
<td style="text-align:left">1</td>
<td style="text-align:left">234.1 KB</td>
</tr>
</tbody>
</table>
<h2>Project Activity</h1>
<p>B1 Are there any Health and Safety risks to the researcher and/or participants?<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Yes<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi></mrow></mrow><annotation encoding="application/x-tex">{ }^{(1)} \mathrm{No}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathrm">No</span></span></span></span></span></p>
<p>B2 Please select any of the following which apply to your project<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Aspects involving human participants (including, but not limited to interviews, questionnaires, images, artefacts and social media data)<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Aspects that the researcher or participants could find embarrassing or emotionally upsetting<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Aspects that include culturally sensitive issues (e.g. age, gender, ethnicity etc.)<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Aspects involving vulnerable groups (e.g. prisoners, pregnant women, children, elderly or disabled people, people experiencing mental health problems, victims of crime etc.), but does not require special approval from external bodies (NHS, security clearance, etc.)<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Project activity which will take place in a country outside of the UK<br>
D None of the above</p>
<p>B2.4 Is this project being undertaken as part of a larger research study for which a Manchester Metropolitan application for ethical approval has already been granted or submitted?<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Yes<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msup><mrow><mi mathvariant="normal">N</mi><mi mathvariant="normal">o</mi></mrow></mrow><annotation encoding="application/x-tex">{ }^{(1)} \mathrm{No}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.888em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.888em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mord"><span class="mord mathrm">No</span></span></span></span></span></p>
<p>Data</p>
<p>F1 How and where will data and documentation be stored?</p>
<p>Stored in a Cloud Database</p>
</div>
<div class="markdown-body" style="--page-number: 63; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="63" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>F2 Will you be using personal data? Personal data is anything than can be used to identify a living individual, directly or indirectly. Pseudonymised data is still personal data.<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Yes<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi></mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;"></span></span></span></span> No</p>
<h2>Insurance</h1>
<p>F3 Does your project involve:<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Pregnant persons as participants with procedures other than blood samples being taken from them? (see info button)<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi><mspace width="1em"/></mrow><annotation encoding="application/x-tex">\Gamma \quad</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span><span class="mspace" style="margin-right:1em;"></span></span></span></span> Children aged five or under with procedures other than blood samples being taken from them? (see info button)<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Activities being undertaken by the lead investigator or any other member of the study team in a country outside of the UK as indicated in the info button? If Yes, please refer to the Travel Insurance guidance on the info button<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Working with Hepatitis, Human T-Cell Lymphotropic Virus Type iii (HTLV iii), or Lymphadenopathy Associated Virus (LAV) or the mutants, derivatives or variations thereof or Acquired Immune Deficiency Syndrome (AIDS) or any syndrome or condition of a similar kind?<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Working with Transmissible Spongiform Encephalopathy (TSE), Creutzfeldt-Jakob Disease (CJD), variant Creutzfeldt-Jakob Disease (vCJD) or new variant Creutzfeldt-Jakob Disease (nvCJD)?<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Working in hazardous areas or high risk countries? (see info button)<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Working with hazardous substances outside of a controlled environment?<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Working with persons with a history of violence, substance abuse or a criminal record?<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi><mspace width="1em"/></mrow><annotation encoding="application/x-tex">\square \quad</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span><span class="mspace" style="margin-right:1em;"></span></span></span></span> None of the above</p>
<h3>Additional Information</h2>
<p>G1 Do you have any additional information or comments which have not been covered in this form?<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Yes<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi></mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;"></span></span></span></span> No</p>
<p>G2 Do you have any additional documentation which you want to upload?<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord"></span></span></span></span> Yes<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi></mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;"></span></span></span></span> No</p>
<p>Signatures</p>
<p>H1 I confirm that all information in this application is accurate and true. I will not start this project until I have received Ethical Approval.<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi></mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal" style="margin-right:0.0037em;"></span></span></span></span> I confirm</p>
</div>
<div class="markdown-body" style="--page-number: 64; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="64" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>H2 Please notify your supervisor that this application is complete and ready to be submitted by clicking Request below. Do not begin your project until you have received confirmation from your supervisor - it is your responsibility to ensure that they do this.</p>
<p>Signed: This form was signed by Yonghong Peng (Y.Peng@mmu.ac.uk) on 26/06/2023 7:54 AM</p>
<p>H3 Have you been instructed by your supervisor to request a second signature for this application?<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mi>a</mi></msup></mrow><annotation encoding="application/x-tex">{ }^{a}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6644em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">a</span></span></span></span></span></span></span></span></span></span></span></span> Yes<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mrow></mrow><mi>c</mi></msup></mrow><annotation encoding="application/x-tex">{ }^{c}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6644em;"></span><span class="mord"><span class="mord"></span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">c</span></span></span></span></span></span></span></span></span></span></span></span> No</p>
<p>H3.1 Please notify your second signatory that this application is complete and ready to be submitted by clicking Request below. Do not begin your project until you have received confirmation from your supervisor - it is your responsibility to ensure that they do this.</p>
<p>Signed: This form was signed by David Jackson (d.j.jackson@mmu.ac.uk) on 26/06/2023 7:52 AM</p>
<p>H4 By signing this application you are confirming that all details included in the form have been completed accurately and truthfully. You are also confirming that you will comply with all relevant UK data protection laws, and that that research data generated by the project will be securely archived in line with requirements specified by the University, unless specific legal, contractual, ethical or regulatory requirements apply.</p>
<p>Signed: This form was signed by Richard Ademola Ogundele (RICHARD.A.OGUNDELE@stu.mmu.ac.uk) on 26/06/2023 3:01 AM</p>
</div>
<div class="markdown-body" style="--page-number: 65; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="65" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>Appendix B - All Experimentation Code<br>
Appendix B1 - Postman API Testing<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-17.jpeg" alt="img-17.jpeg" data-image-width-px="1250" data-image-height-px="472" style="--image-width-px: 1250; --image-height-px: 472;"></p>
<p>Body <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo></mo></mrow><annotation encoding="application/x-tex">\vee</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5556em;"></span><span class="mord"></span></span></span></span><br>
(1) 200 OK 575 ms 365 B Save as Example <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo></mo><mo></mo></mrow><annotation encoding="application/x-tex">\rightarrow \rightarrow</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.3669em;"></span><span class="mrel"></span></span></span></span></p>
<table>
<thead>
<tr>
<th style="text-align:center">Pretty</th>
<th style="text-align:center">Raw</th>
<th style="text-align:center">Preview</th>
<th style="text-align:center">Visualize</th>
<th style="text-align:center">JSON</th>
<th style="text-align:center"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\checkmark</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6922em;"></span><span class="mord amsrm"></span></span></span></span></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">1</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">2</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">3</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<div class="markdown-body" style="--page-number: 66; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="66" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p><img src="https://attachments.academia-assets.com/markdown/109184332/img-18.jpeg" alt="img-18.jpeg" data-image-width-px="1264" data-image-height-px="1132" style="--image-width-px: 1264; --image-height-px: 1132;"></p>
</div>
<div class="markdown-body" style="--page-number: 67; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="67" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p><img src="https://attachments.academia-assets.com/markdown/109184332/img-19.jpeg" alt="img-19.jpeg" data-image-width-px="1269" data-image-height-px="849" style="--image-width-px: 1269; --image-height-px: 849;"></p>
<h2>Appendix B2 - MongoDB Database</h1>
<p><img src="https://attachments.academia-assets.com/markdown/109184332/img-20.jpeg" alt="img-20.jpeg" data-image-width-px="1269" data-image-height-px="777" style="--image-width-px: 1269; --image-height-px: 777;"></p>
</div>
<div class="markdown-body" style="--page-number: 68; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="68" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>Appendix B3 - Deployed Backend Codes<br>
https://thespain.onrender.com/docs<br>
FastAPI<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-21.jpeg" alt="img-21.jpeg" data-image-width-px="1234" data-image-height-px="779" style="--image-width-px: 1234; --image-height-px: 779;"></p>
<p>Appendix B4 - Render Hosting Platform<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-22.jpeg" alt="img-22.jpeg" data-image-width-px="1247" data-image-height-px="162" style="--image-width-px: 1247; --image-height-px: 162;"></p>
<h2>Overview</h1>
<p>(1) Search services<br>
<img src="https://attachments.academia-assets.com/markdown/109184332/img-23.jpeg" alt="img-23.jpeg" data-image-width-px="1234" data-image-height-px="307" style="--image-width-px: 1234; --image-height-px: 307;"></p>
</div>
<div class="markdown-body" style="--page-number: 69; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="69" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<h2>AI Powered App Development</h1>
<p>Performance evaluation and User Feedback</p>
<ul>
<li>Indicates required question</li>
</ul>
<ol>
<li>First Name *</li>
<li>Have you used any similar apps for the purpose of storytelling/theatre before?</li>
</ol>
<p>Mark only one oval.<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span> Yes<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span> No<br>
Maybe<br>
3. How would you rate the apps performance in terms of speed and responsiveness?</p>
<p>Mark only one oval.</p>
<table>
<thead>
<tr>
<th style="text-align:left">1</th>
<th style="text-align:left">2</th>
<th style="text-align:left">3</th>
<th style="text-align:left">4</th>
<th style="text-align:left">5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Slov</td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span></td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span></td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span></td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span></td>
</tr>
</tbody>
</table>
<ol start="4">
<li>Is the user interface intuitive and easy to navigate?</li>
</ol>
<p>Mark only one oval.</p>
<table>
<thead>
<tr>
<th style="text-align:left">1</th>
<th style="text-align:left">2</th>
<th style="text-align:left">3</th>
<th style="text-align:left">4</th>
<th style="text-align:left">5</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Inpu</td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span></td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span></td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span></td>
<td style="text-align:left"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span></td>
</tr>
</tbody>
</table>
<p>Output</p>
</div>
<div class="markdown-body" style="--page-number: 70; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="70" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<ol start="5">
<li>What type of activity did you use the app for&gt;</li>
</ol>
<p>Mark only one oval.<br>
Storytelling<br>
Scriptwriting/Analysis<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span> Audition Preparation<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span> Character/Plot Development<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span> Educational Purposes<br>
6. Kindly Provide any suggestions for improving the apps usability or features?<br>
7. How do you feel about interacting with an AI as if it were a character in a story?</p>
<p>Mark only one oval.<br>
Very Uncomfortable<br>
Uncomfortable<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span> Neutral<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span> Comfortable<br>
Very Comfortable<br>
8. How would you rate the quality of the content generated by the AI in terms of creativity and relevance to your needs?</p>
<p>Check all that apply.<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span> Low Quality<br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal"></mi></mrow><annotation encoding="application/x-tex">\square</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.675em;"></span><span class="mord amsrm"></span></span></span></span> Average Quality<br>
High Quality</p>
</div>
<div class="markdown-body" style="--page-number: 71; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="71" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<ol start="9">
<li>How likely are you to continue using this app in the future (on a scale from 1 to 5)?</li>
</ol>
<p>Mark only one oval.</p>
<p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.16em" columnalign="left left left left left" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>1</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>2</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>3</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>4</mn></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mn>5</mn></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{array}{lllll}
1 &amp; 2 &amp; 3 &amp; 4 &amp; 5
\end{array}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2em;vertical-align:-0.35em;"></span><span class="mord"><span class="mtable"><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">3</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">4</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span><span class="arraycolsep" style="width:0.5em;"></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.85em;"><span style="top:-3.01em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">5</span></span></span></span><span class="vlist-s"></span></span><span class="vlist-r"><span class="vlist" style="height:0.35em;"><span></span></span></span></span></span><span class="arraycolsep" style="width:0.5em;"></span></span></span></span></span></span></span></p>
<ol start="10">
<li>Additional Comments</li>
</ol>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mspace width="2em"/></mrow><annotation encoding="application/x-tex">\qquad</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0em;"></span><span class="mspace" style="margin-right:2em;"></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mspace width="2em"/></mrow><annotation encoding="application/x-tex">\qquad</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0em;"></span><span class="mspace" style="margin-right:2em;"></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mspace width="2em"/></mrow><annotation encoding="application/x-tex">\qquad</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0em;"></span><span class="mspace" style="margin-right:2em;"></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mspace width="2em"/></mrow><annotation encoding="application/x-tex">\qquad</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0em;"></span><span class="mspace" style="margin-right:2em;"></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mspace width="2em"/></mrow><annotation encoding="application/x-tex">\qquad</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0em;"></span><span class="mspace" style="margin-right:2em;"></span></span></span></span><br>
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mspace width="2em"/></mrow><annotation encoding="application/x-tex">\qquad</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0em;"></span><span class="mspace" style="margin-right:2em;"></span></span></span></span></p>
<p>This content is neither created nor endorsed by Google.</p>
<h2>Google Forms</h1>
</div>
<div class="markdown-body" style="--page-number: 72; --page-dpi: 200; --page-width-px: 1654; --page-height-px: 2339;" data-page-number="72" data-page-dpi="200" data-page-width-px="1654" data-page-height-px="2339">
<p>Appendix D - GitHub Codes</p>
<p>Frontend - https://github.com/richardogundele/AIPoweredApp</p>
<p>Backend - https://github.com/richardogundele/thespain</p>
</div>
</div></div></div><div class="references--container"><h2 class="references--heading" id="references">References (49)</h2><ol class="ordered-list"><li class="ordered-list--item ds2-5-body-md">Backend Development ................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">4.1 Application Programming Interface .....................................................................................</li><li class="ordered-list--item ds2-5-body-md">OpenAI GPT ........................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">Fast API ................................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">OpenAI Whisper ..................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">4.5 API Testing ...............................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">Frontend Development ................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">6 Integrated Development Environment ........................................................................................</li><li class="ordered-list--item ds2-5-body-md">7 Mobile Application .....................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">Hosting Platform .........................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">9 Integration of Real-Time Conversations and Anecdote Sharing .................................................</li><li class="ordered-list--item ds2-5-body-md">Chapter Five -Implementation and Results ..................................................................................... 5.1 Software Testing .........................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">2 Performance evaluation and User Feedback ...............................................................................</li><li class="ordered-list--item ds2-5-body-md">3 Analysis of Results ......................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">3.1 Use Case (1) -Storytelling ......................................................................................................</li><li class="ordered-list--item ds2-5-body-md">4.2 Use Case (2) -Script Writer ....................................................................................................</li><li class="ordered-list--item ds2-5-body-md">4.3 Use Case (3) -Content Creation ..............................................................................................</li><li class="ordered-list--item ds2-5-body-md">4.4 Use Case (4) -Tutor ................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">Chapter Six -Conclusion and Recommendation .............................................................................</li><li class="ordered-list--item ds2-5-body-md">1 Conclusion ..................................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">2 Recommendation ........................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">3 Limitation and Challenges ..........................................................................................................</li><li class="ordered-list--item ds2-5-body-md">References .............................................................................................................................................</li><li class="ordered-list--item ds2-5-body-md">Appendices ........................................................................................................................................... Appendix A -Terms of Reference .....................................................................................................</li><li class="ordered-list--item ds2-5-body-md">Appendix B -All Experimentation Code .........................................................................................</li><li class="ordered-list--item ds2-5-body-md">References Bommasani, R., Hudson, D. A., Adeli, E., Altman, R., Arora, S., Arx, von, Bernstein, M. S., Bohg, J., Bosselut, A. and Brunskill, E. (2021) On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258.</li><li class="ordered-list--item ds2-5-body-md">Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G. and Askell, A. (2020) &#39;Language models are few-shot learners.&#39; Advances in neural information processing systems, 33 pp. 1877-1901.</li><li class="ordered-list--item ds2-5-body-md">Chen, J., Prasad, R., Stoyanchev, S., Selfridge, E., Bangalore, S. and Johnston, M. (2018) &#39;Corpus and annotation towards NLU for customer ordering dialogs.&#39; In IEEE, pp. 707-713.</li><li class="ordered-list--item ds2-5-body-md">Devlin, J., Chang, M.-W., Lee, K. and Toutanova, K. (2018) BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. arXiv.org. [Online] [Date Accessed: 20 th September,2023]https://arxiv.org/abs/1810.04805.</li><li class="ordered-list--item ds2-5-body-md">Dong, X., Qian, L., Guan, Y., Huang, L., Yu, Q. and Yang, J. (2016) &#39;A multiclass classification method based on deep learning for named entity recognition in electronic medical records.&#39; In IEEE, pp. 1-10.</li><li class="ordered-list--item ds2-5-body-md">Gao, A. (2023) Prompt engineering for large language models. Available at SSRN 4504303.</li><li class="ordered-list--item ds2-5-body-md">Gatt Albert and Krahmer Emiel (2018) &#39;Survey of the state of the art in natural language generation.&#39; Journal of Artificial Intelligence Research. AI Access Foundation, January.</li><li class="ordered-list--item ds2-5-body-md">GPT-3.5 model architecture (2023a) OpenGenus IQ: Computing Expertise &amp; Legacy.</li><li class="ordered-list--item ds2-5-body-md">Ibrahim, H. and Varol, A. (2020) &#39;A study on automatic speech recognition systems,&#39; pp. 1-5.</li><li class="ordered-list--item ds2-5-body-md">Jackson, D. and Latham, A. (2022) &#39;Talk to The Ghost: The Storybox methodology for faster development of storytelling chatbots.&#39; Expert Systems with Applications. Elsevier, 190 p. 116223. Keneshloo, Y., Shi, T., Ramakrishnan, N. and Reddy, C. K. (2019) &#39;Deep reinforcement learning for sequence-to-sequence models.&#39; IEEE transactions on neural networks and learning systems. IEEE, 31 pp. 2469-2489.</li><li class="ordered-list--item ds2-5-body-md">Khurana, D., Koli, A., Khatter, K. and Singh, S. (2023) &#39;Natural language processing: State of the art, current trends and challenges.&#39; Multimedia tools and applications. Springer, 82 pp. 3713-3744.</li><li class="ordered-list--item ds2-5-body-md">Kojima, T., Shixiang, S., Gu, Reid, M., Research, G., Matsuo, Y. and Iwasawa, Y. (2022) Large Language Models are Zero-Shot Reasoners.</li><li class="ordered-list--item ds2-5-body-md">Kulkarni, P., Mahabaleshwarkar, A., Kulkarni, M., Sirsikar, N. and Gadgil, K. (2019) &#39;Conversational AI: An overview of methodologies, applications &amp; future scope,&#39;pp. 1-7.</li><li class="ordered-list--item ds2-5-body-md">Liu, J., Kong, X., Xia, F., Bai, X., Wang, L., Qing, Q. and Lee, I. (2018) &#39;Artificial intelligence in the 21st century.&#39; Ieee Access. IEEE, 6 pp. 34403-34421.</li><li class="ordered-list--item ds2-5-body-md">OpenAI (2023) &#39;GPT-4 Technical Report.&#39; arXiv:2303.08774 [cs], March.</li><li class="ordered-list--item ds2-5-body-md">O&#39;Shea, J., Bandar, Z. and Crockett, K. (2011) Systems engineering and conversational agents. Intelligence-based systems engineering. Springer, pp. 201-232.</li><li class="ordered-list--item ds2-5-body-md">Prystawski, B. and Goodman, N. D. (2023) Why think step-by-step? Reasoning emerges from the locality of experience. arXiv preprint arXiv:2304.03843.</li><li class="ordered-list--item ds2-5-body-md">Ruane, E., Birhane, A. and Ventresque, A. (2019) &#39;Conversational AI: Social and ethical considerations.,&#39; pp. 104-115.</li><li class="ordered-list--item ds2-5-body-md">Saravia, E. (2022) Prompt Engineering Guide. GitHub. [Online] [Date Accessed: 19 th September,2023] https://github.com/dair-ai/Prompt-Engineering-Guide.</li><li class="ordered-list--item ds2-5-body-md">Shanahan, M. (2022) Talking about large language models. arXiv preprint arXiv:2212.03551.</li><li class="ordered-list--item ds2-5-body-md">Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, . and Polosukhin, I. (2017) &#39;Attention is all you need.&#39; Advances in neural information processing systems, 30. Wikipedia Contributors (2019) Softmax function. Wikipedia. Wikimedia Foundation. [Online] [Date Accessed: 20 th September,2023] https://en.wikipedia.org/wiki/Softmax_function.</li><li class="ordered-list--item ds2-5-body-md">Xue, Z., Li, R. and Li, M. (2022) Recent progress in conversational AI. arXiv preprint arXiv:2204.09719.</li><li class="ordered-list--item ds2-5-body-md">Zhang, C. and Lu, Y. (2021) &#39;Study on artificial intelligence: The state of the art and future prospects.&#39; Journal of Industrial Information Integration. Elsevier, 23 p. 100224.</li><li class="ordered-list--item ds2-5-body-md">Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang, B., Zhang, J., Dong, Z., Du, Y., Yang, C., Chen, Y., Chen, Z., Jiang, J., Ren, R., Li, Y., Tang, X., Liu, Z. and Liu, P. (2023) &#39;A Survey of Large Language Models.&#39; arXiv:2303.18223 [cs], March.</li></ol><button class="ds2-5-button ds2-5-button--extra-small ds2-5-button--full-width js-tc-loswp--references-view-more references--view-more-link" onclick="this.parentElement.classList.add(&#39;references--show-all&#39;);">View more<span class="material-symbols-outlined" style="font-size: 20px" translate="no">arrow_downward</span></button><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--references-view-more"};
  const button = document.querySelector('.js-tc-loswp--references-view-more');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script></div></div><div class="right-rail--container"><div class="safe-right-rail--related-works"><h2 class="safe-related-content--heading">Related papers</h2><div class="safe-related-content--container" data-nosnippet=""><div class="ds-related-work--container js-related-work-sidebar-card js-safe-related-work-related-work " data-collection-position="0" data-entity-id="82171576" data-sort-order="default"><a class="ds-related-work--title js-related-work-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/82171576/Hey_Siri_tell_me_a_story_Digital_storytelling_and_AI_authorship">Hey Siri, tell me a story: Digital storytelling and AI authorship</a><div class="ds-related-work--metadata"><a class="js-related-work-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="267623" href="https://mun.academia.edu/SarahThorne">Sarah Thorne</a></div><p class="ds-related-work--metadata ds2-5-body-xs">Convergence: The International Journal of Research into New Media Technologies, 2020</p><p class="ds2-5-body-sm ds-related-work--abstract hide-on-large">Surveying narrative applications of artificial intelligence in film, games and interactive fiction, this article imagines the future of artificial intelligence (AI) authorship and explores trends that seek to replace human authors with algorithmically generated narrative. While experimental works that draw on text generation and natural language processing have a rich history, this article focuses on commercial applications of AI narrative and looks to future applications of this technology. Video games have incorporated AI and procedural generation for many years, but more recently, new applications of this technology have emerged in other media. Director Oscar Sharp and artist Ross Goodwin, for example, generated significant media buzz about two short films that they produced which were written by their AI screenwriter. Its No Game (2017), in particular, offers an apt commentary on the possibility of replacing striking screenwriters with AI authors. Increasingly, AI agents and vi...</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--565a9b3b"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":82171576,"extra":{"source_work_id":82171576}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--565a9b3b'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/82171576/Hey_Siri_tell_me_a_story_Digital_storytelling_and_AI_authorship","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":82171576,"extra":{"source_work_id":82171576}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":87962746}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-related-work-grid-card-view-pdf" href="https://www.academia.edu/82171576/Hey_Siri_tell_me_a_story_Digital_storytelling_and_AI_authorship"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-related-work-sidebar-card js-safe-related-work-related-work " data-collection-position="1" data-entity-id="120712056" data-sort-order="default"><a class="ds-related-work--title js-related-work-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/120712056/FROM_INSPIRATION_TO_INNOVATION_HOW_CONVERSATIONAL_AI_IS_TRANSFORMING_THE_CREATIVE_LANDSCAPE">FROM INSPIRATION TO INNOVATION: HOW CONVERSATIONAL AI IS TRANSFORMING THE CREATIVE LANDSCAPE</a><div class="ds-related-work--metadata"><a class="js-related-work-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="39122404" href="https://iaeme.academia.edu/publication">IAEME Publication</a></div><p class="ds-related-work--metadata ds2-5-body-xs">IAEME PUBALICATION</p><p class="ds2-5-body-sm ds-related-work--abstract hide-on-large">The emergence of conversational AI agents as active participants in creative processes represents a significant shift in how we approach innovation and creativity. This article delves into the concept of utilizing AI-powered conversational agents as active collaborators in various creative domains, including writing, music production, graphic design, and others. The ability to generate fresh ideas, enhance creative thinking, and expand the boundaries of conventional creative processes is demonstrated by examining the key attributes of these agents, including their advanced natural language processing abilities, specialized knowledge in specific domains, and capacity to adapt. This article explores the practical applications of conversational agents in different creative fields. This explores the utilization of these agents to enhance tasks such as plot development, composition, and design ideation. Furthermore, this text delves into the recent advancements in AI that have enabled the seamless integration of these agents into creative processes. The text also delves into the challenges and ethical considerations that arise when humans collaborate with AI in creative endeavors. This comprehensive analysis explores the transformative potential of conversational agents in reshaping the creative landscape and fostering a new era of human-machine synergy in creative endeavors</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--607f15b1"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":120712056,"extra":{"source_work_id":120712056}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--607f15b1'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/120712056/FROM_INSPIRATION_TO_INNOVATION_HOW_CONVERSATIONAL_AI_IS_TRANSFORMING_THE_CREATIVE_LANDSCAPE","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":120712056,"extra":{"source_work_id":120712056}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":115775391}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-related-work-grid-card-view-pdf" href="https://www.academia.edu/120712056/FROM_INSPIRATION_TO_INNOVATION_HOW_CONVERSATIONAL_AI_IS_TRANSFORMING_THE_CREATIVE_LANDSCAPE"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-related-work-sidebar-card js-safe-related-work-related-work " data-collection-position="2" data-entity-id="90810870" data-sort-order="default"><a class="ds-related-work--title js-related-work-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/90810870/Compulsory_Declaration">Compulsory Declaration</a><div class="ds-related-work--metadata"><a class="js-related-work-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="3156338" href="https://mukuba.academia.edu/AnnetteLombe">Annette Lombe</a></div><p class="ds-related-work--metadata ds2-5-body-xs">2016</p><p class="ds2-5-body-sm ds-related-work--abstract hide-on-large">degree. 2. This dissertation, titled Using podcasts to mediate reflective learning: a case of a postgraduate programme at a higher education institution, is my own work. 3. Each significant contribution to and quotation in this dissertation, titled Using podcasts to mediate reflective learning: a case of a postgraduate programme at a higher education institution, from the work(s) of other people has been attributed, and has been cited and referenced. I have used the APA convention for citation and referencing.</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--c55bc068"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":90810870,"extra":{"source_work_id":90810870}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--c55bc068'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/90810870/Compulsory_Declaration","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":90810870,"extra":{"source_work_id":90810870}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":94270882}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-related-work-grid-card-view-pdf" href="https://www.academia.edu/90810870/Compulsory_Declaration"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-related-work-sidebar-card js-safe-related-work-related-work " data-collection-position="3" data-entity-id="142916233" data-sort-order="default"><a class="ds-related-work--title js-related-work-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/142916233/A_STUDY_OF_AI_IN_CONTENT_CREATION_EXPLORING_THE_BENEFITS_AND_CHALLENGES_The_Dissertation_Submitted_For_The_Partial_Fulfilment_Of">A STUDY OF &quot;AI&quot; IN CONTENT CREATION: EXPLORING THE BENEFITS AND CHALLENGES The Dissertation Submitted For The Partial Fulfilment Of</a><div class="ds-related-work--metadata"><a class="js-related-work-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="199507711" href="https://independent.academia.edu/KapilMishra38">Kapil Mishra</a></div><p class="ds-related-work--metadata ds2-5-body-xs">AI in content strategy, 2025</p><p class="ds2-5-body-sm ds-related-work--abstract hide-on-large">The main issue this study attempts to answer is: How do both content creators and viewers regard AI technologies, and how much do they help or impede the process of creating content? Examining the usefulness of AI tools in real-world applications, the perceived worth of content produced by AI, and the possible repercussions of widespread AI adoption in creative industries are all part of this.</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--42914a06"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":142916233,"extra":{"source_work_id":142916233}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--42914a06'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/142916233/A_STUDY_OF_AI_IN_CONTENT_CREATION_EXPLORING_THE_BENEFITS_AND_CHALLENGES_The_Dissertation_Submitted_For_The_Partial_Fulfilment_Of","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":142916233,"extra":{"source_work_id":142916233}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":123797003}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-related-work-grid-card-view-pdf" href="https://www.academia.edu/142916233/A_STUDY_OF_AI_IN_CONTENT_CREATION_EXPLORING_THE_BENEFITS_AND_CHALLENGES_The_Dissertation_Submitted_For_The_Partial_Fulfilment_Of"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-related-work-sidebar-card js-safe-related-work-related-work " data-collection-position="4" data-entity-id="129452911" data-sort-order="default"><a class="ds-related-work--title js-related-work-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/129452911/Accessible_Co_Creativity_with_AI_through_Language_and_Voice_Input">Accessible Co-Creativity with AI through Language and Voice Input</a><div class="ds-related-work--metadata"><a class="js-related-work-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="3664216" href="https://unatc.academia.edu/AlexandruBerceanu">Alexandru Berceanu</a></div><p class="ds-related-work--metadata ds2-5-body-xs">Zenodo (CERN European Organization for Nuclear Research), 2023</p><p class="ds2-5-body-sm ds-related-work--abstract hide-on-large">This project introduces a set of tools for humans to co-create music with AI-based architectures. The aim is for human musicians or non-musicians to be able to augment their creative capabilities and guide neural architectures to understand language and musical nuances. This work is akin to learning a new instrument: the human learns how to co-create with the AI system for musical applications. One of the main goals of the project is accessibility. We want people with various abilities and disabilities to be empowered to explore music creation by interacting with machines and using language and/or their voice. The tools we propose can be used for composition, improvisation, and/or performance.</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--40a39040"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":129452911,"extra":{"source_work_id":129452911}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--40a39040'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/129452911/Accessible_Co_Creativity_with_AI_through_Language_and_Voice_Input","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":129452911,"extra":{"source_work_id":129452911}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":122874459}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-related-work-grid-card-view-pdf" href="https://www.academia.edu/129452911/Accessible_Co_Creativity_with_AI_through_Language_and_Voice_Input"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-related-work-sidebar-card js-safe-related-work-related-work hidden" data-collection-position="5" data-entity-id="114453219" data-sort-order="default"><a class="ds-related-work--title js-related-work-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/114453219/Artificial_Intelligence_and_Creativity_A_manifesto_for_collaboration">Artificial Intelligence &amp; Creativity: A manifesto for collaboration</a><div class="ds-related-work--metadata"><a class="js-related-work-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="63277882" href="https://independent.academia.edu/NBonnardel">Nathalie Bonnardel</a></div><p class="ds2-5-body-sm ds-related-work--abstract hide-on-large">Creativity is a phenomenon that emerges in the human-sociocultural and machine-artificial layers. With the advent of Artificial Intelligence (AI), the field of creativity faces new opportunities and challenges. This manifesto explores several scenarios of human-machine collaboration on creative tasks and proposes &amp;quot;fundamental laws of generative AI&amp;quot; to reinforce the responsible and ethical use of AI in the creativity field. Four scenarios are proposed and discussed: &amp;quot;Co-Cre-AI-tion&amp;quot;, &amp;quot;Organic&amp;quot;, &amp;quot;Plagiarism 3.0&amp;quot;, and Shut down, each illustrating different possible futures based on the collaboration between humans and machines. In addition, we have incorporated an AI-generated manifesto that also highlights important themes, ranging from accessibility and ethics to cultural sensitivity. The fundamental laws proposed aim to prevent AIs from generating harmful content and competing directly with humans. Creating labels and laws are also highlight...</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--d7ae86d0"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":114453219,"extra":{"source_work_id":114453219}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--d7ae86d0'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/114453219/Artificial_Intelligence_and_Creativity_A_manifesto_for_collaboration","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":114453219,"extra":{"source_work_id":114453219}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":111147427}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-related-work-grid-card-view-pdf" href="https://www.academia.edu/114453219/Artificial_Intelligence_and_Creativity_A_manifesto_for_collaboration"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><div class="ds-related-work--container js-related-work-sidebar-card js-safe-related-work-related-work hidden" data-collection-position="6" data-entity-id="4144691" data-sort-order="default"><a class="ds-related-work--title js-related-work-grid-card-title ds2-5-body-md ds2-5-body-link" href="https://www.academia.edu/4144691/Creativity_and_conducting_handle_in_the_CAIRA_project">Creativity and conducting: handle in the CAIRA project</a><div class="ds-related-work--metadata"><a class="js-related-work-grid-card-author ds2-5-body-sm ds2-5-body-link" data-author-id="5004589" href="https://rpi.academia.edu/JonasBraasch">Jonas Braasch</a></div><p class="ds-related-work--metadata ds2-5-body-xs">2011</p><p class="ds2-5-body-sm ds-related-work--abstract hide-on-large">The aim of this workshop is to bring together researchers from different fields of AI working on computational models for creativity, concept formation, concept discovery, idea generation, and their overall relation and role to general intelligence as well as researchers focusing on application areas, like computer-aided innovation.</p><div class="ds-related-work--ctas"><a class="ds2-5-text-link ds2-5-text-link--inline js-tc-loswp--wsj-grid-card-download-pdf-modal js-login-button--1b0d83ca"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">download</span><span class="ds2-5-text-link__content">Download free PDF</span></a><script>document.addEventListener('DOMContentLoaded', () => {
  const csrfToken = document.querySelector("[name='csrf-token']").content;
  const options = {"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":4144691,"extra":{"source_work_id":4144691}};
  const button = document.querySelector('.js-tc-loswp--wsj-grid-card-download-pdf-modal');
  button.addEventListener('click', () => {
    fetch('/v0/clicks?subdomain_param=api', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'X-CSRF-Token': csrfToken,
      },
      keepalive: true,
      mode: 'same-origin',
      body: JSON.stringify({
        ...options,
        occurred_at: new Date(),
        hit_id: window.Aedu?.hit_data?.id,
      }),
    });
  });
});</script><script>document.addEventListener('DOMContentLoaded', () => { const loginButton = document.querySelector('.js-login-button--1b0d83ca'); if (!loginButton) { throw new Error('Login button not found'); } const options = { detail: {"postLoginRedirectUrl":"https://www.academia.edu/4144691/Creativity_and_conducting_handle_in_the_CAIRA_project","clickTrackingContext":{"source":"loswp--wsj-grid-card-download-pdf-modal","bucket":"outline","entity_id":4144691,"extra":{"source_work_id":4144691}},"configuredText":{"buttonsPage":{"header":"Read your PDF for free"},"emailEntryPage":{"subheader":"Sign up or log in to continue reading."},"emailLoginPage":{"subheader":"Log in to continue reading."},"emailRegistrationPage":{"subheader":"Sign up to continue reading."}},"registrationParams":{"user_source":"download","doc_id":50016659}} }; loginButton.addEventListener('click', () => { document.dispatchEvent(new CustomEvent('open-login-modal', options)); }); });</script><a class="ds2-5-text-link ds2-5-text-link--inline js-related-work-grid-card-view-pdf" href="https://www.academia.edu/4144691/Creativity_and_conducting_handle_in_the_CAIRA_project"><span class="ds2-5-text-link__content">View PDF</span><span class="material-symbols-outlined" style="font-size: 18px" translate="no">chevron_right</span></a></div></div><button class="ds2-5-text-link ds2-5-text-link--inline safe-related-works--view-more-button js-safe-related-works-related-work--view-more-button"><span class="material-symbols-outlined" style="font-size: 18px" translate="no">keyboard_arrow_down</span><span class="ds2-5-text-link__content">View more papers</span></button></div></div></div></div><div id="js-react-on-rails-context" style="display:none" data-rails-context="{&quot;inMailer&quot;:false,&quot;i18nLocale&quot;:&quot;en&quot;,&quot;i18nDefaultLocale&quot;:&quot;en&quot;,&quot;href&quot;:&quot;https://www.academia.edu/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE&quot;,&quot;location&quot;:&quot;/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE&quot;,&quot;scheme&quot;:&quot;https&quot;,&quot;host&quot;:&quot;www.academia.edu&quot;,&quot;port&quot;:null,&quot;pathname&quot;:&quot;/111735900/AI_POWERED_THESPIAN_DEVELOPING_AN_INNOVATIVE_CONVERSATIONAL_ENGINE&quot;,&quot;search&quot;:null,&quot;httpAcceptLanguage&quot;:null,&quot;serverSide&quot;:false}"></div>
<div class="js-react-on-rails-component" style="display:none" data-component-name="LoginModalManager" data-props="{}" data-trace="false" data-dom-id="LoginModalManager-react-component-fd860326-ae6b-4a2d-b6e0-b91f65115c19"></div>
    <div id="LoginModalManager-react-component-fd860326-ae6b-4a2d-b6e0-b91f65115c19"></div>
    


      <div class="about-footer-container"><div class="footer-grid"><div class="links-row"><div class="text-column"><div class="academia-logo"><a href="https://www.academia.edu/?source=footer"><img alt="Academia" src="//a.academia-assets.com/images/design_system/academia_logo_short_white.svg" /></a></div></div><div class="responsive-two-column-container"><div class="inner-two-column-container"><ul class="single-column"><li class="header">Explore</li><li><a href="https://www.academia.edu/documents">Papers</a></li><li><a href="https://www.academia.edu/topics">Topics</a></li></ul><ul class="single-column"><li class="header">Features</li><li><a href="https://www.academia.edu/mentions">Mentions</a></li><li><a href="https://www.academia.edu/analytics">Analytics</a></li><li><a href="https://www.academia.edu/research">PDF Packages</a></li><li><a href="https://www.academia.edu/search/advanced">Advanced Search</a></li><li><a href="https://www.academia.edu/saved_searches">Search Alerts</a></li></ul></div><div class="inner-two-column-container"><ul class="single-column"><li class="header">Journals</li><li><a href="https://www.academia.edu/journals">Academia.edu Journals</a></li><li><a href="https://www.academia.edu/journals/submissions">My submissions</a></li><li><a href="https://www.academia.edu/journals/submissions#reviewer/invitations">Reviewer Hub</a></li><li><a href="https://www.academia.edu/journals/about/why-publish-with-us">Why publish with us</a></li><li><a href="https://www.academia.edu/journals/about/testimonials">Testimonials</a></li></ul><ul class="single-column"><li class="header">Company</li><li><a href="https://www.academia.edu/about">About</a></li><li><a href="https://www.academia.edu/careers">Careers</a></li><li><a href="https://www.academia.edu/press">Press</a></li><li><a href="https://support.academia.edu/hc/en-us">Help Center</a></li><li><a href="https://www.academia.edu/terms">Terms</a></li><li><a href="https://www.academia.edu/privacy">Privacy</a></li><li><a href="https://www.academia.edu/copyright">Copyright</a></li><li><a href="https://www.academia.edu/content_policy">Content Policy</a></li></ul></div></div></div><div class="subfooter-row"><div class="academia-logo"><a href="https://www.academia.edu/?source=footer"><img alt="Academia" src="//a.academia-assets.com/images/design_system/academia_logo_white.svg" /></a></div><div class="text"><div>580 California St., Suite 400</div><div>San Francisco, CA, 94104</div></div><div class="text"><div><a href="https://www.academia.edu/copyright"> 2025 Academia. All rights reserved</a></div></div></div></div></div>

  </body>
</html>
